{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been written to sanity_check.tsv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "hyps = []\n",
    "refs = []\n",
    "\n",
    "def extract_multiple_predictions_to_tsv(json_file_path, tsv_file_path):\n",
    "    \"\"\"\n",
    "    Reads a file containing multiple lines of JSON, each containing a prediction and a reference,\n",
    "    and writes these to a TSV file with 'hyp' and 'tgt' columns.\n",
    "\n",
    "    Args:\n",
    "    - json_file_path (str): The path of the file containing the JSON lines.\n",
    "    - tsv_file_path (str): The path where the TSV file will be saved.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    with open(json_file_path, 'r', encoding='utf-8') as json_file, \\\n",
    "         open(tsv_file_path, 'w', encoding='utf-8') as tsv_file:\n",
    "        # Write the headers to the TSV file\n",
    "        tsv_file.write(\"hyp\\ttgt\\n\")\n",
    "\n",
    "        for line in json_file:\n",
    "            data = json.loads(line)  \n",
    "\n",
    "            prediction = data[\"prediction\"]\n",
    "            reference = data[\"reference\"]\n",
    "\n",
    "            hyps.append(prediction)\n",
    "            refs.append(reference)\n",
    "\n",
    "            tsv_file.write(f\"{prediction}\\t{reference}\\n\")\n",
    "\n",
    "# Example usage:\n",
    "json_file_path = \"/mnt/taurus/data1/xixu/runs/sllama/wavlm_clean/stage2/checkpoint-1900/sanity_check/320ms-1001/instances.log\"  \n",
    "tsv_file_path = \"sanity_check.tsv\"  \n",
    "\n",
    "# Call the function with the paths\n",
    "extract_multiple_predictions_to_tsv(json_file_path, tsv_file_path)\n",
    "\n",
    "print(f\"Data has been written to {tsv_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 26.785563885367445\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import sacrebleu\n",
    "\n",
    "def calculate_bleu_from_tsv(tsv_file_path):\n",
    "    \"\"\"\n",
    "    Calculates the BLEU score for hypotheses and references contained in a TSV file.\n",
    "\n",
    "    Args:\n",
    "    - tsv_file_path (str): The path to the TSV file with 'hyp' and 'tgt' columns.\n",
    "\n",
    "    Returns:\n",
    "    - The BLEU score as a float.\n",
    "    \"\"\"\n",
    "\n",
    "    global hyps, refs\n",
    "\n",
    "    # hyps = []  # To store all hypotheses\n",
    "    # refs = []  # To store all references\n",
    "\n",
    "    # # Read the hypotheses and references from the TSV file\n",
    "    # with open(tsv_file_path, 'r', encoding='utf-8') as tsv_file:\n",
    "    #     reader = csv.DictReader(tsv_file, delimiter='\\t')\n",
    "    #     for row in reader:\n",
    "    #         hyps.append(row['hyp'])\n",
    "    #         refs.append('' if row['tgt'] is None else row['tgt'])  # Note: refs must be a list of lists\n",
    "\n",
    "    # Calculate the BLEU score\n",
    "    bleu_score = sacrebleu.corpus_bleu(hyps, [refs])\n",
    "\n",
    "    return bleu_score.score\n",
    "\n",
    "# Example usage:\n",
    "tsv_file_path = \"sanity_check.tsv\"  # The path to your TSV file\n",
    "bleu_score = calculate_bleu_from_tsv(tsv_file_path)\n",
    "\n",
    "print(f\"BLEU score: {bleu_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-04-11 15:58:39,998] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-11 15:58:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2024-04-11 15:58:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2024-04-11 15:58:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU = 28.10 61.8/35.5/22.8/15.2 (BP = 0.950 ratio = 0.952 hyp_len = 49110 ref_len = 51605)\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import subprocess\n",
    "from fairseq import scoring\n",
    "\n",
    "\n",
    "def prepare_data_for_fairseq(tsv_file_path, hyp_file_path, ref_file_path):\n",
    "    \"\"\"\n",
    "    Splits the TSV file into separate hypothesis and reference files for fairseq evaluation,\n",
    "    handling cases where the data might be missing.\n",
    "\n",
    "    Args:\n",
    "    - tsv_file_path (str): Path to the TSV file with 'hyp' and 'tgt' columns.\n",
    "    - hyp_file_path (str): Path to save the hypothesis file.\n",
    "    - ref_file_path (str): Path to save the reference file.\n",
    "    \"\"\"\n",
    "    with open(tsv_file_path, 'r', encoding='utf-8') as tsv_file, \\\n",
    "         open(hyp_file_path, 'w', encoding='utf-8') as hyp_file, \\\n",
    "         open(ref_file_path, 'w', encoding='utf-8') as ref_file:\n",
    "        reader = csv.DictReader(tsv_file, delimiter='\\t')\n",
    "        for row in reader:\n",
    "            # Ensure that 'hyp' and 'tgt' are treated as empty strings if they are None\n",
    "            hyp_text = row['hyp'] if row['hyp'] is not None else \"\"\n",
    "            tgt_text = row['tgt'] if row['tgt'] is not None else \"\"\n",
    "            hyp_file.write(hyp_text + '\\n')\n",
    "            ref_file.write(tgt_text + '\\n')\n",
    "\n",
    "\n",
    "def calculate_bleu_with_fairseq_python(hyp_file_path, ref_file_path):\n",
    "    \"\"\"\n",
    "    Calculates the BLEU score using Fairseq's Python API.\n",
    "\n",
    "    Args:\n",
    "    - hyp_file_path (str): Path to the hypothesis file.\n",
    "    - ref_file_path (str): Path to the reference file.\n",
    "\n",
    "    Returns:\n",
    "    - The BLEU score as a string.\n",
    "    \"\"\"\n",
    "    # Initialize the scorer\n",
    "    scorer = scoring.build_scorer(\"sacrebleu\", None)\n",
    "    \n",
    "    # Read hypotheses and references\n",
    "    with open(hyp_file_path, 'r', encoding='utf-8') as hyp_file, \\\n",
    "         open(ref_file_path, 'r', encoding='utf-8') as ref_file:\n",
    "        hyps = [line.strip() for line in hyp_file]\n",
    "        refs = [line.strip() for line in ref_file]\n",
    "    \n",
    "    for hyp, ref in zip(hyps, refs):\n",
    "        scorer.add_string(ref, hyp)\n",
    "    \n",
    "    return scorer.result_string()\n",
    "\n",
    "\n",
    "\n",
    "tsv_file_path = \"sanity_check.tsv\"\n",
    "hyp_file_path = \"hypotheses.txt\"\n",
    "ref_file_path = \"references.txt\"\n",
    "\n",
    "prepare_data_for_fairseq(tsv_file_path, hyp_file_path, ref_file_path)\n",
    "\n",
    "bleu_score_output = calculate_bleu_with_fairseq_python(hyp_file_path, ref_file_path)\n",
    "print(bleu_score_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a large language and speech assistant.You are able to understand the speech content that the user provides, and assist the user with a variety of tasks using natural language.Follow the instructions carefully and explain your answers in detail. USER:ASSISTANT:\n",
      "{'input_ids': [[1, 887, 526, 263, 2919, 4086, 322, 12032, 20255, 29889, 3492, 526, 2221, 304, 2274, 278, 12032, 2793, 393, 278, 1404, 8128, 29892, 322, 6985, 278, 1404, 411, 263, 12875, 310, 9595, 773, 5613, 4086, 29889, 29943, 2952, 278, 11994, 16112, 322, 5649, 596, 6089, 297, 9493, 29889, 3148, 1001, 29901, 22933, 9047, 13566, 29901]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
     ]
    }
   ],
   "source": [
    "import conversation as conversation_lib\n",
    "import transformers\n",
    "\n",
    "conv = conversation_lib.default_conversation.copy()\n",
    "conv.messages = []\n",
    "conv.append_message(conv.roles[0], None)\n",
    "conv.append_message(conv.roles[1], None)\n",
    "prompt_inputs = conv.get_prompt()\n",
    "print(prompt_inputs)\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "    '/mnt/data1/xixu/runs/sllama/wavlm_clean/stage2/checkpoint-1900',\n",
    "    padding_side=\"right\",\n",
    "    use_fast=False,\n",
    ")\n",
    "input_ids1 = tokenizer([prompt_inputs])\n",
    "input_ids = tokenizer(prompt_inputs, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "print(input_ids1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sllama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
