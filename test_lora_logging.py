#!/usr/bin/env python3
"""
æµ‹è¯•LoRAæ—¥å¿—åŠŸèƒ½çš„ç®€å•è„šæœ¬
ç”¨äºéªŒè¯LoRAå‚æ•°æ˜¯å¦æ­£ç¡®åº”ç”¨å’Œæ›´æ–°
"""

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), 'retriever', 'gigaspeech', 'modal'))

import torch
import numpy as np
from Qwen2_Audio_train import Qwen2AudioSpeechEncoder, Qwen2AudioTextEncoder, ContrastiveQwen2AudioModel

def test_lora_logging():
    """æµ‹è¯•LoRAæ—¥å¿—åŠŸèƒ½"""
    print("ğŸ§ª Testing LoRA Logging Functionality")
    print("=" * 60)
    
    # æ£€æŸ¥CUDAå¯ç”¨æ€§
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"Using device: {device}")
    
    try:
        # åˆå§‹åŒ–ç¼–ç å™¨
        print("\nğŸ”§ Initializing encoders...")
        speech_encoder = Qwen2AudioSpeechEncoder(device=device)
        shared_model = speech_encoder.get_shared_model()
        text_encoder = Qwen2AudioTextEncoder(device=device, shared_model=shared_model)
        
        # åˆå§‹åŒ–å¯¹æ¯”å­¦ä¹ æ¨¡å‹ï¼ˆè¿™é‡Œä¼šè‡ªåŠ¨æ‰“å°è¯¦ç»†çš„LoRAä¿¡æ¯ï¼‰
        print("\nğŸ”§ Initializing ContrastiveQwen2AudioModel...")
        model = ContrastiveQwen2AudioModel(
            speech_encoder=speech_encoder,
            text_encoder=text_encoder,
            proj_dim=512,
            lora_r=16,
            lora_alpha=32,
            lora_dropout=0.1
        )
        
        # è®¾ç½®è®­ç»ƒæ¨¡å¼
        model.train()
        
        # åˆ›å»ºè™šæ‹Ÿæ•°æ®è¿›è¡Œæµ‹è¯•
        print("\nğŸ¯ Creating dummy data for testing...")
        dummy_audio = torch.randn(16000, dtype=torch.float32)  # 1ç§’éŸ³é¢‘
        dummy_text = "This is a test sentence for LoRA verification."
        
        # ä¿å­˜è®­ç»ƒå‰çš„å‚æ•°çŠ¶æ€
        print("\nğŸ’¾ Saving parameter state before training...")
        before_state = model.print_parameter_stats_before_after()
        
        # åˆ›å»ºä¼˜åŒ–å™¨
        optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)
        
        # æ¨¡æ‹Ÿå‡ æ­¥è®­ç»ƒ
        print("\nğŸƒ Simulating training steps...")
        for step in range(3):
            print(f"\n--- Step {step + 1} ---")
            
            # å‰å‘ä¼ æ’­
            audio_emb = model.encode_audio([dummy_audio])
            text_emb = model.encode_text([dummy_text])
            
            # è®¡ç®—ç®€å•çš„å¯¹æ¯”æŸå¤±
            similarity = torch.mm(audio_emb, text_emb.T)
            labels = torch.arange(similarity.size(0), device=similarity.device)
            loss = torch.nn.CrossEntropyLoss()(similarity, labels)
            
            print(f"Loss: {loss.item():.6f}")
            
            # åå‘ä¼ æ’­
            loss.backward()
            
            # æ£€æŸ¥æ¢¯åº¦ï¼ˆæ¯æ­¥éƒ½æ£€æŸ¥ï¼‰
            model.check_lora_gradients(step=step + 1)
            
            # æ›´æ–°å‚æ•°
            optimizer.step()
            optimizer.zero_grad()
        
        # è®­ç»ƒç»“æŸåæ¯”è¾ƒå‚æ•°å˜åŒ–
        print("\nğŸ“Š Comparing parameter changes after training...")
        model.print_parameter_stats_before_after(before_state)
        
        print("\nâœ… LoRA logging test completed successfully!")
        
    except Exception as e:
        print(f"\nâŒ Error during testing: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    return True

if __name__ == "__main__":
    success = test_lora_logging()
    if success:
        print("\nğŸ‰ All tests passed!")
    else:
        print("\nğŸ’¥ Tests failed!")
        sys.exit(1)

