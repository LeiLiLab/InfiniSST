{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "import csv\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sacrebleu\n",
    "import soundfile as sf\n",
    "\n",
    "import copy\n",
    "import yaml\n",
    "import math\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from IPython.display import display, Audio\n",
    "\n",
    "def read_logs(path):\n",
    "    logs = []\n",
    "    with open(path, \"r\") as r:\n",
    "        for l in r.readlines():\n",
    "            l = l.strip()\n",
    "            if l != \"\":\n",
    "                logs.append(json.loads(l))\n",
    "    return logs\n",
    "\n",
    "def write_logs(logs, path):\n",
    "    with open(path, \"w\") as w:\n",
    "        for log in logs:\n",
    "            w.write(json.dumps(log) + \"\\n\")\n",
    "\n",
    "def read_wav(wav_path):\n",
    "    if ':' in wav_path:\n",
    "        wav_path, offset, duration = wav_path.split(':')\n",
    "        offset = int(offset)\n",
    "        duration = int(duration)\n",
    "    else:\n",
    "        offset = 0\n",
    "        duration = -1\n",
    "    source, rate = sf.read(wav_path, start=offset, frames=duration)\n",
    "    return source, rate\n",
    "\n",
    "def read_tsv(tsv_path):\n",
    "    import csv\n",
    "    with open(tsv_path) as f:\n",
    "        reader = csv.DictReader(\n",
    "            f,\n",
    "            delimiter=\"\\t\",\n",
    "            quotechar=None,\n",
    "            doublequote=False,\n",
    "            lineterminator=\"\\n\",\n",
    "            quoting=csv.QUOTE_NONE,\n",
    "        )\n",
    "        samples = [dict(e) for e in reader]\n",
    "    return samples\n",
    "\n",
    "def write_tsv(samples, tsv_path):\n",
    "    with open(tsv_path, \"w\") as w:\n",
    "        writer = csv.DictWriter(\n",
    "            w,\n",
    "            samples[0].keys(),\n",
    "            delimiter=\"\\t\",\n",
    "            quotechar=None,\n",
    "            doublequote=False,\n",
    "            lineterminator=\"\\n\",\n",
    "            quoting=csv.QUOTE_NONE,\n",
    "        )\n",
    "        writer.writeheader()\n",
    "        writer.writerows(samples)\n",
    "\n",
    "def play(audio_path):\n",
    "    display(Audio(read_wav(audio_path)[0], rate=16000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inconsistency between online and simuleval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "online_sources = []\n",
    "for i in range(16):\n",
    "    online_sources.append(np.load('/home/siqiouya/work/sllama/online_source_{}.npy'.format(i)))\n",
    "simuleval_sources = []\n",
    "for i in range(16):\n",
    "    simuleval_sources.append(np.load('/home/siqiouya/work/sllama/source_{}.npy'.format(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.        ,  0.        ,  0.        , ..., -0.11690447,\n",
       "        -0.09129377, -0.11185333], dtype=float32),\n",
       " array([ 0.        ,  0.        ,  0.        , ...,  0.03414917,\n",
       "         0.00436401, -0.05111694]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "online_sources[0], simuleval_sources[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(211)\n",
    "plt.plot(online_sources[11])\n",
    "plt.title('Online Source')\n",
    "plt.subplot(212) \n",
    "plt.plot(simuleval_sources[11])\n",
    "plt.title('Simuleval Source')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SacreBLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sacrebleu\n",
    "scorer = sacrebleu.BLEU()\n",
    "scorer.get_signature()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tst-COMMON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_paths = []\n",
    "with open(\"/compute/babel-14-5/siqiouya/en-zh/tst-COMMON_full.source\") as f:\n",
    "    for line in f:\n",
    "        wav_paths.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "infos = []\n",
    "for wav_path in wav_paths:\n",
    "    info = sf.info(wav_path)\n",
    "    infos.append(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "durations = []\n",
    "for info in infos:\n",
    "    durations.append(info.duration / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "durations = np.array(durations)\n",
    "(durations > 10).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.683580208333336"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "durations.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "294.6705166666667"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "durations.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in range(1, 5):\n",
    "    seg_size = m * 960\n",
    "    path = \"/compute/babel-5-23/siqiouya/runs/en-zh/8B-traj-s2-v3.5_llama3/last.ckpt/simul-results-full-betterfilterbadwords/cache1000_seg{}_beam4_ms0_nrnl100_nrns5/instances.log\".format(seg_size)\n",
    "    logs = read_logs(path)\n",
    "    logs_less10 = [log for log in logs if log['source_length'] / 1000 / 60 < 10]\n",
    "    logs_more10 = [log for log in logs if log['source_length'] / 1000 / 60 >= 10]\n",
    "    write_logs(logs_less10, path.replace(\".log\", \"_less10.log\"))\n",
    "    write_logs(logs_more10, path.replace(\".log\", \"_more10.log\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 11)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(logs_less10), len(logs_more10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# absolute position embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinusoidal_positional_embedding(offset, length, d_model):\n",
    "    half_dim = d_model // 2\n",
    "    emb = math.log(10000) / (half_dim - 1)\n",
    "    emb = torch.exp(torch.arange(half_dim, dtype=torch.float) * -emb)\n",
    "    emb = torch.arange(offset, offset + length, dtype=torch.float).unsqueeze(\n",
    "        1\n",
    "    ) * emb.unsqueeze(0)\n",
    "    emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=1).view(\n",
    "        length, -1\n",
    "    )\n",
    "    if d_model % 2 == 1:\n",
    "        # zero pad\n",
    "        emb = torch.cat([emb, torch.zeros(length, 1)], dim=1)\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 9.0930e-01,  1.9867e-01,  1.9999e-02,  2.0000e-03,  2.0000e-04,\n",
       "         -4.1615e-01,  9.8007e-01,  9.9980e-01,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.4112e-01,  2.9552e-01,  2.9995e-02,  3.0000e-03,  3.0000e-04,\n",
       "         -9.8999e-01,  9.5534e-01,  9.9955e-01,  1.0000e+00,  1.0000e+00],\n",
       "        [-7.5680e-01,  3.8942e-01,  3.9989e-02,  4.0000e-03,  4.0000e-04,\n",
       "         -6.5364e-01,  9.2106e-01,  9.9920e-01,  9.9999e-01,  1.0000e+00],\n",
       "        [-9.5892e-01,  4.7943e-01,  4.9979e-02,  5.0000e-03,  5.0000e-04,\n",
       "          2.8366e-01,  8.7758e-01,  9.9875e-01,  9.9999e-01,  1.0000e+00],\n",
       "        [-2.7942e-01,  5.6464e-01,  5.9964e-02,  6.0000e-03,  6.0000e-04,\n",
       "          9.6017e-01,  8.2534e-01,  9.9820e-01,  9.9998e-01,  1.0000e+00],\n",
       "        [ 6.5699e-01,  6.4422e-01,  6.9943e-02,  6.9999e-03,  7.0000e-04,\n",
       "          7.5390e-01,  7.6484e-01,  9.9755e-01,  9.9998e-01,  1.0000e+00],\n",
       "        [ 9.8936e-01,  7.1736e-01,  7.9915e-02,  7.9999e-03,  8.0000e-04,\n",
       "         -1.4550e-01,  6.9671e-01,  9.9680e-01,  9.9997e-01,  1.0000e+00],\n",
       "        [ 4.1212e-01,  7.8333e-01,  8.9879e-02,  8.9999e-03,  9.0000e-04,\n",
       "         -9.1113e-01,  6.2161e-01,  9.9595e-01,  9.9996e-01,  1.0000e+00],\n",
       "        [-5.4402e-01,  8.4147e-01,  9.9833e-02,  9.9998e-03,  1.0000e-03,\n",
       "         -8.3907e-01,  5.4030e-01,  9.9500e-01,  9.9995e-01,  1.0000e+00],\n",
       "        [-9.9999e-01,  8.9121e-01,  1.0978e-01,  1.1000e-02,  1.1000e-03,\n",
       "          4.4257e-03,  4.5360e-01,  9.9396e-01,  9.9994e-01,  1.0000e+00]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sinusoidal_positional_embedding(2, 10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairseq.modules.sinusoidal_positional_embedding import SinusoidalPositionalEmbedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mix data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = 'es'\n",
    "split = 'dev'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_full = f\"{split}_st_{lang}{'_ft' if lang == 'zh' and split == 'train' else ''}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev_st_es\n"
     ]
    }
   ],
   "source": [
    "print(split_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_30 = read_tsv(f\"/compute/babel-14-5/siqiouya/en-{lang}/{split_full}_nospeaker_traj_30_filtered.tsv\")\n",
    "samples = read_tsv(f\"/compute/babel-14-5/siqiouya/en-{lang}/{split_full}_nospeaker_traj.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(454, 1183)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(samples_30), len(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in samples:\n",
    "    if 'src_phoneme' in x:\n",
    "        x.pop('src_phoneme')\n",
    "    if 'src_segments' in x:\n",
    "        x.pop('src_segments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = [x for x in samples if type(eval(x['trajectory'])) == list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1183"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/siqiouya/work/sllama\")\n",
    "from train.dataset import PromptSpeechToTextDatasetCreator\n",
    "dataset_mix = PromptSpeechToTextDatasetCreator.from_tsv(\n",
    "    root=f\"/compute/babel-14-5/siqiouya/en-{lang}/\",\n",
    "    split=f\"dev_st_es_nospeaker_traj_30mix_filtered\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8931a02e43bc48c6999d2e279c72878b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in tqdm(range(len(dataset_mix))):\n",
    "    if dataset_mix.trajectories[i] is None:\n",
    "        print(dataset_mix[i])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_samples = samples_30 + samples\n",
    "write_tsv(new_samples, f\"/compute/babel-14-5/siqiouya/en-{lang}/{split_full}_nospeaker_traj_30mix_filtered.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/compute/babel-14-5/siqiouya/en-es/dev_st_es_nospeaker_traj_30mix_filtered.tsv'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"/compute/babel-14-5/siqiouya/en-{lang}/{split_full}_nospeaker_traj_30mix_filtered.tsv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RTF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seg 960 RTF: 0.434\n",
      "seg 1920 RTF: 0.311\n",
      "seg 2880 RTF: 0.258\n",
      "seg 3840 RTF: 0.240\n",
      "[0.43420646638745586, 0.3105447250020244, 0.2577829749858482, 0.2402853461595036]\n"
     ]
    }
   ],
   "source": [
    "suffices = ['']\n",
    "\n",
    "rtfs = []\n",
    "for seg_size in range(960, 4000, 960):\n",
    "    instances = read_logs(\"/compute/babel-5-23/siqiouya/runs/en-zh/8B-traj-s2-v3.6/last.ckpt/simul-results-full-betterfilterbadwords/cache1000_seg{}_beam4_ms0_nrnl100_nrns5/instances.log\".format(seg_size))\n",
    "\n",
    "    sum_audio_len = 0\n",
    "    sum_comp_len = 0\n",
    "    for inst in instances:\n",
    "        audio_len = inst['delays'][-1]\n",
    "        comp_len = inst['elapsed'][-1] - audio_len\n",
    "        sum_audio_len += audio_len\n",
    "        sum_comp_len += comp_len\n",
    "    print(\"seg {} RTF: {:.3f}\".format(seg_size, sum_comp_len / sum_audio_len))\n",
    "    rtfs.append(sum_comp_len / sum_audio_len)\n",
    "print(rtfs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fn 1 RTF: 0.627\n",
      "fn 2 RTF: 0.660\n",
      "fn 3 RTF: 0.749\n",
      "fn 4 RTF: 0.863\n",
      "fn 5 RTF: 0.865\n",
      "fn 6 RTF: 0.963\n",
      "fn 7 RTF: 0.902\n",
      "[0.6272766492708965, 0.6602332743256539, 0.7490266849020142, 0.8632729736505114, 0.8652987829525057, 0.9626827018304407, 0.9023871640602232]\n"
     ]
    }
   ],
   "source": [
    "# StreamAtt\n",
    "suffices = ['']\n",
    "\n",
    "rtfs = []\n",
    "for fn in range(1, 8):\n",
    "    instances = read_logs(\"/compute/babel-5-23/siqiouya/runs/en-es/8B-s2-bi-v3.5.2/last.ckpt/streamatt/bsz1_layer14_t40_d10_fn{}/instances.log\".format(fn))\n",
    "\n",
    "    sum_audio_len = 0\n",
    "    sum_comp_len = 0\n",
    "    for inst in instances:\n",
    "        audio_len = inst['delays'][-1]\n",
    "        comp_len = inst['elapsed'][-1] - audio_len\n",
    "        sum_audio_len += audio_len\n",
    "        sum_comp_len += comp_len\n",
    "    \n",
    "    try:\n",
    "        print(\"fn {} RTF: {:.3f}\".format(fn, sum_comp_len / sum_audio_len))\n",
    "        rtfs.append(sum_comp_len / sum_audio_len)\n",
    "    except:\n",
    "        pass\n",
    "print(rtfs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# filter speaker information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "\n",
    "def extract_names_and_ted_talks(samples):\n",
    "    ted_talk_dict = defaultdict(set)\n",
    "    \n",
    "    # Regex for extracting names: matches 'Firstname Lastname:' and initials like 'CA:' or 'RSW:'\n",
    "    name_regex = re.compile(r'\\b(?<!\\\")(Audience|Narrator|Video|Man|Woman|Bono|Voice|Announcer|Rives|George W\\. Bush|Broadcasting|Boy|Professor|Engineer|Interviewer|Shereen El-Feki|Tina|Girl|Dad|Voice):|[A-Z][a-z]+(?:\\s[A-Z][a-z]+)*:|[A-Z]{1,3}:')\n",
    "\n",
    "    error_samples = []\n",
    "    cleaned_samples = []\n",
    "        \n",
    "    for sample in samples:\n",
    "        ted_id = sample['id'].split('_')[1]\n",
    "        names = name_regex.findall(sample['src_text'])\n",
    "        cleaned_names = {name.strip(':').strip() for name in names}\n",
    "\n",
    "        if len(cleaned_names) > 0:\n",
    "            ted_talk_dict[ted_id].update(cleaned_names)\n",
    "            error_samples.append(sample)\n",
    "        else:\n",
    "            cleaned_samples.append(sample)\n",
    "\n",
    "    return ted_talk_dict, error_samples, cleaned_samples\n",
    "\n",
    "# New product from Coke Japan: water salad. | New product from Coke Japan, water salad.\n",
    "# Consider this: Make a decision to live a carbon-neutral life.\n",
    "# Video: Don Blankenship: Let me be clear about it. | Let me be clear about it.\n",
    "# Richard Koshalek: [Unclear] starts from 2004. | THANK YOU. # (2400 frames) delete short utterance\n",
    "# DP: Wow.\t| David Perry: Wow. | Wow. \n",
    "# DNA: \n",
    "# Stephen Pink's Girlfriend: | Stephen Pinks Freundin:\n",
    "# Audience|Narrator|Video|Man|Woman|Bono|Voice|Announcer|Rives|George W. Bush|Broadcasting|Boy|Professor|Engineer|Interviewer|Shereen El-Feki|Tina|Girl|Dad|Voice\n",
    "# Then: working concentrated, without being frazzled.\tDann: konzentriert arbeiten, ohne genervt zu werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('labse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/compute/babel-14-5/siqiouya/en-es/train_st_es.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = read_tsv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_len = len(samples)\n",
    "while True:\n",
    "    ted_talk_data, error_samples, cleaned_samples = extract_names_and_ted_talks(samples)\n",
    "\n",
    "    if len(error_samples) == 0:\n",
    "        break\n",
    "\n",
    "    srcs = []\n",
    "    tgts = []\n",
    "    for x in error_samples:\n",
    "        src = x['src_text']\n",
    "        tgt = x['tgt_text']\n",
    "\n",
    "        src = src[:src.find(':')]\n",
    "        if ':' in tgt:\n",
    "            tgt = tgt[:tgt.find(':')]\n",
    "        elif '：' in tgt:\n",
    "            tgt = tgt[:tgt.find('：')]\n",
    "        else:\n",
    "            tgt = \"\"\n",
    "\n",
    "        srcs.append(src)\n",
    "        tgts.append(tgt)\n",
    "\n",
    "    src_embeddings = model.encode(srcs)\n",
    "    tgt_embeddings = model.encode(tgts)\n",
    "\n",
    "    sims = []\n",
    "    for i in range(len(src_embeddings)):\n",
    "        cosine_similarity = model.similarity(src_embeddings[i], tgt_embeddings[i]).item()\n",
    "        sims.append(cosine_similarity)\n",
    "    sims = np.array(sims)\n",
    "    src_lens = [len(src.split(' ')) for src in srcs]\n",
    "    tgt_lens = [len(tgt) if 'zh' in file_path else len(tgt.split(' ')) for tgt in tgts]\n",
    "    corrected_samples = []\n",
    "    \n",
    "    for i in range(len(sims)):\n",
    "        if re.search(r'One|Two|Three|Four|Five|Six|Seven|Eight|Nine|Ten|LG', srcs[i]):\n",
    "            continue\n",
    "        if srcs[i] != \"\" and tgts[i] != \"\" and src_lens[i] <= 3 and (tgt_lens[i] <= 3 or sims[i] > 0.5):\n",
    "            # print(error_samples[i]['src_text'], error_samples[i]['tgt_text'], sims[i], sep='\\n', end='\\n\\n')\n",
    "            x = copy.deepcopy(error_samples[i])\n",
    "            x['src_text'] = x['src_text'][len(srcs[i]) + 1:].strip()\n",
    "            x['tgt_text'] = x['tgt_text'][len(tgts[i]) + 1:].strip()\n",
    "            corrected_samples.append(x)\n",
    "\n",
    "    samples = cleaned_samples + corrected_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ted_talk_data, error_samples, cleaned_samples = extract_names_and_ted_talks(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_tsv(samples, file_path.replace('.tsv', '_nospeaker.tsv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = read_tsv(\"/compute/babel-14-5/siqiouya/en-es/train_st_es.tsv\")\n",
    "samples_ns = read_tsv(\"/compute/babel-14-5/siqiouya/en-es/train_st_es_nospeaker.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_ns_f = []\n",
    "for x in samples_ns:\n",
    "    if ':' in x['src_text']:\n",
    "        samples_ns_f.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_f = []\n",
    "for x in samples:\n",
    "    if ':' in x['src_text']:\n",
    "        samples_f.append(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# llama attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d7e01166b9b4ad390615e3ee86a5523",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, how are you? I hope you're doing well. I'm here to talk about something that's been on my mind\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/compute/babel-4-1/siqiouya/llama-3.1-8b-instruct-hf/\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"/compute/babel-4-1/siqiouya/llama-3.1-8b-instruct-hf/\")\n",
    "\n",
    "text = \"Hello, how are you?\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "outputs = model.generate(**inputs)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.\n"
     ]
    }
   ],
   "source": [
    "outputs = model.generate(**inputs, return_dict_in_generate=True, output_attentions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 7, 7])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs['attentions'][0][0].size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inspect es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = read_tsv(\"/compute/babel-14-5/siqiouya/en-es/train_st_es_traj_30_filtered.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', 'Es ', 'maravilloso estar ', 'aquí para ', 'hablar de mi ', 'travesía, ', 'hablar sobre mi silla de ', 'ruedas y sobre la ', 'libertad que ', 'me ha dado.  ', 'Empecé ', 'a usar silla de ', ' ', 'ruedas a los 16 años cuando una ', ' ', 'enfermedad prolongada ', 'cambió mi forma ', 'de acceder al ']\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x['trajectory']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in samples:\n",
    "    try:\n",
    "        type(eval(x['trajectory'])[0])\n",
    "    except:\n",
    "        assert int(x['n_frames']) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = read_tsv(\"/compute/babel-14-5/siqiouya/en-zh/train_st_zh_ft_traj_30_filtered.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(samples[4]['src_text'], samples[4]['tgt_text'], sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = read_logs(\"/compute/babel-5-23/siqiouya/runs/8B-traj-s2-v3.3/last.ckpt/greedy_train_chunk30_po10k/cache4000_seg960_beam1_ms0_nrnl100_nrns3/0/instances.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = logs[19]\n",
    "print(log['prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_frame = int(log['source_length'] * 16)\n",
    "stepsize = int(0.96 * 16000)\n",
    "idx = -1\n",
    "new_traj = []\n",
    "for offset in range(0, n_frame, stepsize):\n",
    "    text = \"\"\n",
    "    while idx + 1 < len(log['delays']) and int(log['delays'][idx + 1]) * 16 < offset + stepsize:\n",
    "        idx += 1\n",
    "        text += log['prediction'][idx]\n",
    "    new_traj.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(samples[19]['tgt_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav, sr = read_wav(log['source'][0])\n",
    "trajectory = new_traj\n",
    "\n",
    "step = int(sr * 0.96)\n",
    "for i, action in zip(range(0, len(wav), step), trajectory):\n",
    "    display(Audio(wav[i : i + step], rate=sr, autoplay=False))\n",
    "    print(i // step, \"[T_START]\", action, \"[T_END]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav, sr = read_wav(log['source'][0])\n",
    "trajectory = new_traj\n",
    "\n",
    "step = int(sr * 0.96)\n",
    "for i, action in zip(range(0, len(wav), step), trajectory):\n",
    "    if i // step >= 231 - 10 and i // step <= 231 + 10:\n",
    "        display(Audio(wav[i : i + step], rate=sr, autoplay=False))\n",
    "        print(i // step, \"[T_START]\", action, \"[T_END]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect Training po10k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = read_tsv(\"/compute/babel-14-5/siqiouya/en-zh/train_st_zh_ft_traj_30_filtered_po10k_gpt-4o-mini-2024-07-18_fa_traj.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_samples = read_tsv(\"/compute/babel-14-5/siqiouya/en-zh/train_st_zh_ft_traj_30_filtered.tsv\")\n",
    "id2samples = {x['id']: x for x in all_samples}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('source:', samples[100]['src_text'], end='\\n\\n')\n",
    "print('target-gpt-4o-mini:', samples[100]['tgt_text'], end='\\n\\n')\n",
    "print('target-original:', id2samples[samples[100]['id']]['tgt_text'], end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter by ASR WER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "# Path to the ASR files\n",
    "base_path = \"/home/siqiouya/work/sllama/data\"\n",
    "\n",
    "# Get all asr.* files\n",
    "\n",
    "# Read and concatenate all ASR results\n",
    "all_asrs = []\n",
    "for i in range(8):\n",
    "    with open(os.path.join(base_path, f\"asr.{i}\")) as f:\n",
    "        asrs = [line.strip() for line in f.readlines() if line.strip() != \"\"]\n",
    "        all_asrs.extend(asrs)\n",
    "\n",
    "print(f\"Total ASR transcriptions: {len(all_asrs)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = read_tsv(\"/compute/babel-14-5/siqiouya/en-de/dev_st_de_traj_30.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "wer_scorer = load(\"wer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_asrs = np.array(all_asrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wers = []\n",
    "for i in tqdm(range(len(samples))):\n",
    "    asr_orig = samples[i]['src_text'].replace('\"', '').lower()\n",
    "    asr_whisper = all_asrs[i].lower()\n",
    "    wer = wer_scorer.compute(predictions=[asr_orig], references=[asr_whisper])\n",
    "    wers.append(wer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "wers = np.array(wers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = np.array(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(wers > 0.4).sum(), len(wers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(wers > 0.4).nonzero()[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_samples = samples[wers > 0.4]\n",
    "err_asrs = all_asrs[wers > 0.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = list(range(len(err_samples)))\n",
    "np.random.shuffle(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = indices[1]\n",
    "sample = err_samples[idx]\n",
    "asr_whisper = err_asrs[idx]\n",
    "print(sample['src_text'], end='\\n\\n')\n",
    "print(sample['tgt_text'], end='\\n\\n')\n",
    "print(asr_whisper)\n",
    "play(sample['audio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# special case 1\n",
    "special_words = [\n",
    "    \"(Music)\", \n",
    "    \"(Laughter)\", \n",
    "    \"(Applause)\", \n",
    "]\n",
    "# special case 2\n",
    "## silence or music\n",
    "## usually src_text is empty and asr is shorter than 3 words\n",
    "\n",
    "# special case 3\n",
    "## zero length audio\n",
    "\n",
    "# special case 4 \n",
    "## whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_mask = wers > 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(samples)):\n",
    "    if remove_mask[i]:\n",
    "        if len(all_asrs[i].split(' ')) <= 3:\n",
    "            if any(w in samples[i]['src_text'] for w in special_words) or samples[i]['src_text'] == \"\":\n",
    "                remove_mask[i] = False\n",
    "                # print(samples[i]['src_text'], end='\\n\\n')\n",
    "                # print(samples[i]['tgt_text'], end='\\n\\n')\n",
    "                # print(all_asrs[i])\n",
    "                # play(samples[i]['audio'])\n",
    "                # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_samples = samples[~remove_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = list(range(len(filtered_samples)))\n",
    "np.random.shuffle(indices)\n",
    "for i in indices[:10]:\n",
    "    print(filtered_samples[i]['src_text'], end='\\n\\n')\n",
    "    print(filtered_samples[i]['tgt_text'], end='\\n\\n')\n",
    "    print(all_asrs[~remove_mask][i])\n",
    "    try:\n",
    "        play(filtered_samples[i]['audio'])\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_tsv(filtered_samples, \"/compute/babey arel-14-5/siqiouya/en-de/dev_st_de_traj_30_filtered.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = read_tsv(\"/compute/babel-14-5/siqiouya/en-de/dev_st_de_traj_30.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "wer_scorer = load(\"wer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_asrs = np.array(all_asrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wers = []\n",
    "for i in tqdm(range(len(samples))):\n",
    "    asr_orig = samples[i]['src_text'].replace('\"', '').lower()\n",
    "    asr_whisper = all_asrs[i].lower()\n",
    "    wer = wer_scorer.compute(predictions=[asr_orig], references=[asr_whisper])\n",
    "    wers.append(wer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wers = np.array(wers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = np.array(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(wers > 0.4).sum(), len(wers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(wers > 0.4).nonzero()[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_samples = samples[wers > 0.4]\n",
    "err_asrs = all_asrs[wers > 0.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = list(range(len(err_samples)))\n",
    "np.random.shuffle(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = indices[1]\n",
    "sample = err_samples[idx]\n",
    "asr_whisper = err_asrs[idx]\n",
    "print(sample['src_text'], end='\\n\\n')\n",
    "print(sample['tgt_text'], end='\\n\\n')\n",
    "print(asr_whisper)\n",
    "play(sample['audio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# special case 1\n",
    "special_words = [\n",
    "    \"(Music)\", \n",
    "    \"(Laughter)\", \n",
    "    \"(Applause)\", \n",
    "]\n",
    "# special case 2\n",
    "## silence or music\n",
    "## usually src_text is empty and asr is shorter than 3 words\n",
    "\n",
    "# special case 3\n",
    "## zero length audio\n",
    "\n",
    "# special case 4 \n",
    "## whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_mask = wers > 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(samples)):\n",
    "    if remove_mask[i]:\n",
    "        if len(all_asrs[i].split(' ')) <= 3:\n",
    "            if any(w in samples[i]['src_text'] for w in special_words) or samples[i]['src_text'] == \"\":\n",
    "                remove_mask[i] = False\n",
    "                # print(samples[i]['src_text'], end='\\n\\n')\n",
    "                # print(samples[i]['tgt_text'], end='\\n\\n')\n",
    "                # print(all_asrs[i])\n",
    "                # play(samples[i]['audio'])\n",
    "                # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_samples = samples[~remove_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = list(range(len(filtered_samples)))\n",
    "np.random.shuffle(indices)\n",
    "for i in indices[:10]:\n",
    "    print(filtered_samples[i]['src_text'], end='\\n\\n')\n",
    "    print(filtered_samples[i]['tgt_text'], end='\\n\\n')\n",
    "    print(all_asrs[~remove_mask][i])\n",
    "    try:\n",
    "        play(filtered_samples[i]['audio'])\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_tsv(filtered_samples, \"/compute/babel-14-5/siqiouya/en-de/dev_st_de_traj_30_filtered.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whisper ASR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whisper ASR\n",
    "import torch\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "from datasets import load_dataset\n",
    "\n",
    "# load model and processor\n",
    "# model_id = \"openai/whisper-large-v3-turbo\"\n",
    "model_id = \"openai/whisper-large-v3\"\n",
    "# model_id = \"openai/whisper-medium.en\"\n",
    "torch_dtype = torch.float16\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True\n",
    ")\n",
    "model.to('cuda')\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "forced_decoder_ids = processor.get_decoder_prompt_ids(language=\"english\", task=\"transcribe\")\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    chunk_length_s=30,\n",
    "    batch_size=16,  # batch size for inference - set based on your device\n",
    "    torch_dtype=torch_dtype,\n",
    "    device='cuda',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = read_tsv(\"/compute/babel-14-5/siqiouya/en-zh/train_st_zh_ft_traj_45.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asrs = []\n",
    "for i in tqdm(range(5197, 5197 + 1, 16)):\n",
    "    batch = err_samples[i:i + 16]\n",
    "    wav_paths = [x['audio'] for x in batch]\n",
    "    offsets = [int(x.split(':')[1]) for x in wav_paths]\n",
    "    durations = [int(x.split(':')[2]) for x in wav_paths]\n",
    "    sources, rates = zip(*[read_wav(x) for x in wav_paths])\n",
    "    \n",
    "    # Find max length in batch\n",
    "    max_len = max(len(x) for x in sources)\n",
    "\n",
    "    # Pad each source with zeros to match max length\n",
    "    padded_sources = []\n",
    "    for source in sources:\n",
    "        padding = np.zeros(max_len - len(source))\n",
    "        padded = np.concatenate([source, padding])\n",
    "        padded_sources.append(padded)\n",
    "\n",
    "    transcriptions = [\n",
    "        t['text'] \n",
    "        for t in pipe(padded_sources, generate_kwargs={\"forced_decoder_ids\": forced_decoder_ids})\n",
    "    ]\n",
    "\n",
    "    # # Stack into batch\n",
    "    # sources = np.stack(padded_sources)\n",
    "\n",
    "    # input_features = processor(\n",
    "    #     sources, \n",
    "    #     truncation=False, \n",
    "    #     padding=\"longest\",\n",
    "    #     sampling_rate=16000, \n",
    "    #     return_attention_mask=True,\n",
    "    #     return_tensors=\"pt\", \n",
    "    #     language=\"english\",\n",
    "    # )\n",
    "    # input_features = input_features.to(\"cuda\", torch.float16)\n",
    "    # # generate token ids\n",
    "    # predicted_ids = model.generate(**input_features, num_beams=4, return_timestamps=True)\n",
    "    # # decode token ids to text\n",
    "    # transcriptions = processor.batch_decode(predicted_ids, skip_special_tokens=True)\n",
    "    asrs.extend([t.strip() for t in transcriptions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(asrs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overlap between 45 chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = read_tsv(\"/compute/babel-14-5/siqiouya/en-zh/comet_0.50_traj_45.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlaps = []\n",
    "for i in range(len(samples) - 1):\n",
    "    wav_path, offset, duration = samples[i]['audio'].split(':')\n",
    "    wav_path_next, offset_next, duration_next = samples[i + 1]['audio'].split(':')\n",
    "    if wav_path == wav_path_next:\n",
    "        offset = int(offset)\n",
    "        duration = int(duration)\n",
    "        offset_next = int(offset_next)\n",
    "        duration_next = int(duration_next)\n",
    "        overlap = max(0, offset + duration - offset_next)\n",
    "        overlaps.append(overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlaps = np.array(overlaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlaps.mean() / 16000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = read_logs(\"/compute/babel-5-23/siqiouya/runs/en-zh/8B-traj-s2-v3.5_sc30/last.ckpt/simul-results-full-betterfilterbadwords/cache1000_seg2880_beam4_ms0_nrnl100_nrns5/instances.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyps = [x['prediction'] for x in logs]\n",
    "refs = [x['reference'] for x in logs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU = 17.33 57.4/25.4/11.1/5.6 (BP = 1.000 ratio = 1.264 hyp_len = 1028 ref_len = 813)\n",
      "BLEU = 29.95 78.6/43.9/25.0/15.1 (BP = 0.887 ratio = 0.893 hyp_len = 1475 ref_len = 1652)\n",
      "BLEU = 31.35 77.3/43.2/24.3/15.2 (BP = 0.941 ratio = 0.943 hyp_len = 1083 ref_len = 1149)\n",
      "BLEU = 21.71 77.5/39.3/18.5/9.3 (BP = 0.807 ratio = 0.824 hyp_len = 4756 ref_len = 5773)\n",
      "BLEU = 36.32 79.3/47.9/28.5/17.4 (BP = 0.981 ratio = 0.981 hyp_len = 2297 ref_len = 2341)\n",
      "BLEU = 36.53 83.9/51.0/28.3/16.8 (BP = 0.967 ratio = 0.967 hyp_len = 3802 ref_len = 3931)\n",
      "BLEU = 33.31 80.6/46.6/24.7/13.8 (BP = 0.990 ratio = 0.990 hyp_len = 3823 ref_len = 3860)\n",
      "BLEU = 29.82 71.0/39.6/21.9/12.9 (BP = 1.000 ratio = 1.092 hyp_len = 1598 ref_len = 1463)\n",
      "BLEU = 36.35 80.7/48.4/27.8/16.9 (BP = 0.988 ratio = 0.989 hyp_len = 2157 ref_len = 2182)\n",
      "BLEU = 33.94 77.3/42.8/25.3/15.9 (BP = 0.999 ratio = 0.999 hyp_len = 1221 ref_len = 1222)\n",
      "BLEU = 32.52 77.3/43.5/24.0/13.9 (BP = 1.000 ratio = 1.010 hyp_len = 2362 ref_len = 2338)\n",
      "BLEU = 32.44 80.8/47.5/24.6/12.9 (BP = 0.976 ratio = 0.977 hyp_len = 5840 ref_len = 5980)\n",
      "BLEU = 34.64 81.7/48.4/29.3/18.4 (BP = 0.906 ratio = 0.910 hyp_len = 660 ref_len = 725)\n",
      "BLEU = 25.61 68.5/35.8/18.0/9.7 (BP = 1.000 ratio = 1.039 hyp_len = 752 ref_len = 724)\n",
      "BLEU = 34.88 75.6/45.5/26.6/16.2 (BP = 1.000 ratio = 1.074 hyp_len = 1996 ref_len = 1858)\n",
      "BLEU = 34.91 80.8/48.0/26.3/15.0 (BP = 0.992 ratio = 0.992 hyp_len = 4113 ref_len = 4147)\n",
      "BLEU = 31.11 83.7/48.0/25.4/13.9 (BP = 0.903 ratio = 0.907 hyp_len = 5118 ref_len = 5643)\n",
      "BLEU = 33.16 76.9/46.8/24.9/13.5 (BP = 1.000 ratio = 1.075 hyp_len = 5065 ref_len = 4713)\n",
      "BLEU = 27.81 76.6/41.3/20.4/10.8 (BP = 0.964 ratio = 0.965 hyp_len = 1416 ref_len = 1468)\n",
      "BLEU = 22.10 63.1/31.2/14.9/8.2 (BP = 1.000 ratio = 1.085 hyp_len = 1328 ref_len = 1224)\n",
      "BLEU = 33.88 75.0/43.7/25.6/15.7 (BP = 1.000 ratio = 1.024 hyp_len = 1758 ref_len = 1717)\n",
      "BLEU = 26.85 72.5/38.0/18.6/10.2 (BP = 1.000 ratio = 1.100 hyp_len = 2750 ref_len = 2500)\n",
      "BLEU = 25.22 72.5/37.0/17.6/9.7 (BP = 0.970 ratio = 0.970 hyp_len = 1573 ref_len = 1621)\n",
      "BLEU = 34.61 80.6/47.3/26.4/15.8 (BP = 0.974 ratio = 0.974 hyp_len = 3890 ref_len = 3994)\n",
      "BLEU = 28.01 74.2/40.6/19.9/10.3 (BP = 1.000 ratio = 1.088 hyp_len = 6975 ref_len = 6412)\n",
      "BLEU = 34.49 81.1/47.6/26.3/14.7 (BP = 0.986 ratio = 0.987 hyp_len = 3448 ref_len = 3495)\n",
      "BLEU = 33.75 74.1/44.6/25.4/15.5 (BP = 1.000 ratio = 1.006 hyp_len = 1399 ref_len = 1390)\n"
     ]
    }
   ],
   "source": [
    "for hyp, ref in zip(hyps, refs):\n",
    "    print(sacrebleu.corpus_bleu([hyp], [[ref]], tokenize=\"zh\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "接下来我要想象一个能给你超人能力的机器人或者是另一个能让威尔士人站立和行走的机器人我们在伯克利邦尼克斯称之为骨骼机器人这些仅仅是你早上穿上的东西它们会给你额外的力量加快你的速度帮助你比如说，帮助你保持平衡事实上，这才是真正的整合人和机器的结合不仅如此它还能整合你和宇宙以及其他的设备这不仅仅是蓝天般的想象而是我们正在做的工作通过谈论美国士兵他们平均携带100磅的装备他们被要求携带更多的设备显然，这会导致复杂的后果包括背部损伤百分之三十的士兵患有慢性背部损伤我们想，我们可以看待这个挑战并创造一个外骨骼来解决这个问题我现在要向你们介绍Hark或者说人类通用负载器(笑声)在崎岖不平的路上走了很长时间。它灵活的设计可以让它保持俯卧、爬行和高敏捷性运动。它可以感知我想做什么，去哪里，然后增强我的力量和耐力。我们已经准备好了。与我们的战略合作伙伴一起，我们推出了这个设备，这个新的外骨骼。这是真实的。现在，让我们把我们的目光转向用户，特别是某些人，他们对此非常感兴趣。有6800万人被估计在世界各地的轮椅上。这大约是总人口的百分之一。这实际上是一个保守的估计。我们在这里谈论的是很年轻的人，他们患有脊髓损伤，在生命的黄金时期，20岁、30岁、40岁时，他们遭遇了一场灾难。轮椅是唯一的选择，但它也是人口数量不断增长的第18个群体。唯一的选择是中风或其他并发症，这就是轮椅。这实际上是过去500年来，因为它的引入非常成功，我必须说。所以我们认为我们可以开始编写一款全新的流动性章节。让我现在介绍给你们Elex，它是阿曼达·博克斯特尔（AmandaBoxtel）穿着的，她是一位19岁的脊髓损伤患者，这使她无法行走。19年来，直到现在，她都无法行走。(掌声)阿曼达穿着我们的Elex。它有传感器。它是完全无创的。脊椎中的传感器会发送信号回去，这些信号会传送到后面坐着的电脑。它们有电池，这些电池会驱动在臀部后面的电机，以及膝盖的电机，这些电机会以一种很顺畅，非常自然的步伐前进。它已经24岁了，在我游戏的顶峰时期，一个怪物在丹·赫尔斯基滑雪时瘫痪了我，在那一瞬间，我失去了所有的感觉，以及我下半身的运动能力。不久之后，一个医生走进了我的病房，他对我说，“阿曼达，你再也不会走路了。”那是19年前的事了。他夺走了我生命中的一分一毫的希望。适应技术已经让我学会了如何再次滑雪，如何攀岩，甚至如何骑单车。但迄今为止，没有任何发明能够让我再次行走。如你所见，我们有技术，我们有平台，我们可以坐下来和你们讨论。在我们的掌握之中，我们拥有所有的潜力去改变生活，去改变未来的一代人，不仅仅是为了士兵，也不仅仅是为了阿曼达和其他使用者，而是为了每一个人。谢谢。\n"
     ]
    }
   ],
   "source": [
    "print(hyps[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diff two samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/compute/babel-14-5/siqiouya/en-zh\"\n",
    "train_path = os.path.join(root, \"train.tsv\")\n",
    "train_st_zh_path = os.path.join(root, \"train_st_zh.tsv\")\n",
    "extra_ft_path = os.path.join(root, \"output.tsv\")\n",
    "comet_ft_path = os.path.join(root, \"comet_0.50_complement_tower.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = read_tsv(train_path)\n",
    "train_st_zh_samples = read_tsv(train_st_zh_path)\n",
    "extra_ft_samples = read_tsv(extra_ft_path)\n",
    "comet_ft_samples = read_tsv(comet_ft_path)\n",
    "len(train_samples), len(extra_ft_samples), len(comet_ft_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comet_ft_samples[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_samples) - len(train_st_zh_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in train_st_zh_samples:\n",
    "    if x['audio'].startswith(\"en-zh/data/train/wav\"):\n",
    "        x['audio'] = \"/compute/babel-14-5/siqiouya/\" + x['audio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_tsv(train_st_zh_samples, train_st_zh_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_st_zh_audio = set(x['audio'] for x in train_st_zh_samples)\n",
    "train_audio = set(x['audio'] for x in train_samples)\n",
    "extra_samples = []\n",
    "for x in train_samples:\n",
    "    if x['audio'] not in train_st_zh_audio:\n",
    "        extra_samples.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_tsv(extra_samples, os.path.join(root, \"train_extra.tsv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio2tgtext = {}\n",
    "for x in extra_ft_samples:\n",
    "    audio2tgtext[x['audio']] = x['translation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "for x in train_samples:\n",
    "    if x['audio'] in audio2tgtext:\n",
    "        x['tgt_text'] = audio2tgtext[x['audio']]\n",
    "        cnt += 1\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_train_samples = read_tsv(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "for x1, x2 in zip(orig_train_samples, train_samples):\n",
    "    if x1['tgt_text'] != x2['tgt_text']:\n",
    "        cnt += 1\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2sample = {}\n",
    "for x in train_st_zh_samples:\n",
    "    id2sample[x['id']] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "comet_ft_samples_full = []\n",
    "for x in comet_ft_samples:\n",
    "    if x['id'] in id2sample:\n",
    "        comet_ft_samples_full.append((id2sample[x['id']]['audio'], x['translation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(comet_ft_samples_full)):\n",
    "    comet_ft_samples_full[i] = [comet_ft_samples_full[i][0], comet_ft_samples_full[i][1]]\n",
    "    if comet_ft_samples_full[i][0].startswith(\"en-zh/data/train/wav\"):\n",
    "        comet_ft_samples_full[i][0] = \"/compute/babel-14-5/siqiouya/\" + comet_ft_samples_full[i][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "Audio(read_wav(\"/compute/babel-14-5/siqiouya/en-zh//data/train/wav/ted_2005.wav:19080960:138559\")[0], rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio2tgtext2 = {}\n",
    "for x in comet_ft_samples_full:\n",
    "    audio2tgtext2[x[0]] = x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "train_audio_set = set()\n",
    "for x in train_samples:\n",
    "    x['audio'] = x['audio'].replace('//', '/')\n",
    "    if x['audio'] in audio2tgtext2:\n",
    "        x['tgt_text'] = audio2tgtext2[x['audio']]\n",
    "        cnt += 1\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "for x1, x2 in zip(orig_train_samples, train_samples):\n",
    "    if x1['tgt_text'] != x2['tgt_text']:\n",
    "        # print(x1['src_text'], x1['tgt_text'], x2['tgt_text'], sep='\\n', end='\\n\\n')\n",
    "        cnt += 1\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_tsv(train_samples, os.path.join(root, \"train_ft.tsv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from comet import download_model, load_from_checkpoint\n",
    "model_path = download_model(\"Unbabel/XCOMET-XL\", saving_directory=\"/data/user_data/siqiouya/runs/pretrained/XCOMET-XL\")\n",
    "model = load_from_checkpoint(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = read_tsv(\"/compute/babel-14-5/siqiouya/en-zh/dev_fa_traj_45.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/compute/babel-5-23/siqiouya/runs/8B-traj-s2-v3.0/last.ckpt/sampling_dev_for_qe/cache4000_seg960_beam1_ms0_topp1.0_topk0_epsilon0.1_temp1.0/{}/instances.log\"\n",
    "logs_per_seed = []\n",
    "for i in range(16):\n",
    "    logs_per_seed.append(read_logs(path.format(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qe_scores_per_seed = []\n",
    "for i in range(16):\n",
    "    data = [\n",
    "        {\n",
    "            \"src\": samples[j]['src_text'],\n",
    "            \"ref\": samples[j]['tgt_text'],\n",
    "            \"mt\": logs_per_seed[i][j]['prediction']\n",
    "        }\n",
    "        for j in range(len(logs_per_seed[i]))\n",
    "    ]\n",
    "    qe_output = model.predict(data, batch_size=4, gpus=1)\n",
    "    qe_scores_per_seed.append(qe_output.scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greedy_log_path = \"/compute/babel-5-23/siqiouya/runs/8B-traj-s2-v3.0/last.ckpt/greedy_dev_for_qe/cache4000_seg960_beam1_ms0/instances.log\"\n",
    "greedy_logs = read_logs(greedy_log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    {\n",
    "        \"src\": samples[j]['src_text'],\n",
    "        \"ref\": samples[j]['tgt_text'],\n",
    "        \"mt\": greedy_logs[j]['prediction']\n",
    "    }\n",
    "    for j in range(len(samples))\n",
    "]\n",
    "qe_output = model.predict(data, batch_size=4, gpus=1)\n",
    "qe_scores_greedy = qe_output.scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    {\n",
    "        \"src\": samples[j]['src_text'],\n",
    "        \"ref\": samples[j]['tgt_text'],\n",
    "        \"mt\": samples[j]['tgt_text']\n",
    "    }\n",
    "    for j in range(len(samples))\n",
    "]\n",
    "qe_output = model.predict(data, batch_size=4, gpus=1)\n",
    "qe_scores_ref = qe_output.scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "qe_scores_per_seed = np.array(qe_scores_per_seed)\n",
    "qe_scores_ref = np.array(qe_scores_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qe_scores_per_seed[:, 0].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(samples[:10])):\n",
    "    max_log_idx = qe_scores_per_seed[:, idx].argmax()\n",
    "    print(samples[idx]['src_text'], end='\\n\\n')\n",
    "    print(qe_scores_per_seed[max_log_idx, idx], logs_per_seed[max_log_idx][idx]['prediction'], end='\\n\\n')\n",
    "    print(qe_scores_ref[idx], samples[idx]['tgt_text'], end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert sampled trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/compute/babel-14-5/siqiouya/en-zh/\"\n",
    "ckpt_root = \"/compute/babel-5-23/siqiouya/runs/8B-traj-s2-v3.0/last.ckpt\"\n",
    "split = \"train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = read_tsv(os.path.join(root, f\"{split}_fa_traj_45.tsv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_size = 1000\n",
    "n_partition = 20 # (len(samples) + partition_size - 1) // partition_size\n",
    "for i in tqdm(range(n_partition)):\n",
    "    partition_samples = samples[i * partition_size:(i + 1) * partition_size]\n",
    "    logs = read_logs(os.path.join(ckpt_root, f\"sampling_{split}/cache4000_seg960_beam1_ms0/{i}/instances.log\"))\n",
    "    for sample, log in zip(partition_samples, logs):\n",
    "        n_frame = int(sample['n_frames'])\n",
    "        stepsize = int(0.96 * 16000)\n",
    "        idx = -1\n",
    "        new_traj = []\n",
    "        for offset in range(0, n_frame, stepsize):\n",
    "            text = \"\"\n",
    "            while idx + 1 < len(log['delays']) and int(log['delays'][idx + 1]) * 16 < offset + stepsize:\n",
    "                idx += 1\n",
    "                text += log['prediction'][idx]\n",
    "            new_traj.append(text)\n",
    "        sample['sampling'] = new_traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 2\n",
    "print(samples[idx]['trajectory'], samples[idx]['sampling'], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_tsv(samples, os.path.join(root, f\"{split}_fa_traj_45_sampling.tsv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_tsv(samples[:n_partition * partition_size], os.path.join(root, f\"{split}_fa_traj_45_sampling_{n_partition}k.tsv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build source target for sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "root = \"/compute/babel-14-5/siqiouya/en-zh/\"\n",
    "base_split = \"train\"\n",
    "split = \"train_fa_traj_45\"\n",
    "split_wav_root = os.path.join(root, \"data\", base_split, f\"{split}_wav\")\n",
    "os.makedirs(split_wav_root, exist_ok=True)\n",
    "samples = read_tsv(os.path.join(root, f\"{split}.tsv\"))\n",
    "for x in tqdm(samples):\n",
    "    wav, sr = read_wav(x['audio'])\n",
    "    sf.write(os.path.join(split_wav_root, x['id'] + \".wav\"), wav, sr)\n",
    "def write_source_target(samples, split_wav_root, split_source_path, split_target_path):\n",
    "    with open(split_source_path, \"w\") as w:\n",
    "        for x in samples:\n",
    "            w.write(os.path.join(split_wav_root, x['id'] + \".wav\") + \"\\n\")\n",
    "    with open(split_target_path, \"w\") as w:\n",
    "        for x in samples:\n",
    "            w.write(x['tgt_text'] + \"\\n\")\n",
    "write_source_target(samples, split_wav_root, os.path.join(root, f\"{split}.source\"), os.path.join(root, f\"{split}.target\"))\n",
    "partition_size = 1000\n",
    "for i in range(0, len(samples), partition_size):\n",
    "    partition_samples = samples[i:i+partition_size]\n",
    "    write_source_target(partition_samples, split_wav_root, os.path.join(root, f\"{split}.source.{i//partition_size}\"), os.path.join(root, f\"{split}.target.{i//partition_size}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rebuild the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/compute/babel-14-5/siqiouya/en-zh/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls $root/data/$split/txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_lang = 'en'\n",
    "tgt_lang = 'zh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{root}/data/{split}/txt/{split}.yaml\") as f:\n",
    "    manifests = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{root}/data/{split}/txt/{split}.{src_lang}\", \"r\") as r:\n",
    "    src_texts = [l.strip() for l in r.readlines() if l.strip() != '']\n",
    "with open(f\"{root}/data/{split}/txt/{split}.{tgt_lang}\", \"r\") as r:\n",
    "    tgt_texts = [l.strip() for l in r.readlines() if l.strip() != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_texts[0], tgt_texts[0], len(src_texts), len(tgt_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifests[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id\taudio\tn_frames\tspeaker\tsrc_text\ttgt_text\tsrc_lang\ttgt_lang\n",
    "samples = []\n",
    "ted_id = \"\"\n",
    "id_in_ted = 0\n",
    "for i, manifest in enumerate(manifests):\n",
    "    cur_ted_id = manifest['wav'].split('.')[0]\n",
    "    if cur_ted_id != ted_id:\n",
    "        ted_id = cur_ted_id\n",
    "        id_in_ted = 0\n",
    "    else:\n",
    "        id_in_ted += 1\n",
    "\n",
    "    segment_id = f\"{ted_id}_{id_in_ted}\"\n",
    "\n",
    "    offset = int(manifest['offset'] * 16000)\n",
    "    duration = int(manifest['duration'] * 16000)\n",
    "    segment_path = f\"{root}/data/{split}/wav/{manifest['wav']}:{offset}:{duration}\"\n",
    "\n",
    "    samples.append({\n",
    "        \"id\": segment_id,\n",
    "        \"audio\": segment_path,\n",
    "        \"n_frames\": duration,\n",
    "        \"speaker\": manifest['speaker_id'],\n",
    "        \"src_text\": src_texts[i],\n",
    "        \"tgt_text\": tgt_texts[i],\n",
    "        \"src_lang\": src_lang,\n",
    "        \"tgt_lang\": tgt_lang,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_tsv(samples, f\"{root}/{split}.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## re-segment so that each utterance is shorter than 43.2 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "with open(\"/home/siqiouya/.api_keys/openai\", \"r\") as r:\n",
    "    api_key = r.read().strip()\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = 'He was at Radcliffe Infirmary in Oxford, and fortunately for him, a small team of doctors led by a Dr. Howard Florey had managed to synthesize a very small amount of penicillin, a drug that had been discovered 12 years before by Alexander Fleming but had never actually been  used to treat a human, and indeed no one even  knew if the drug would work, if it was full of impurities  that would kill the patient, but Florey and his team figured if they had to use it,  they might as well use it on someone who was going to die anyway.'\n",
    "tgt = \"他在牛津市的Radcliffe Infirmary 医院接受治疗， 幸运的是， 由霍华德·弗洛里医生 （译注：澳洲药理学家） 带头的一个医疗小组 成功的合成了 少量的盘尼西林， 一种被亚历山大·弗莱明 （译注：苏格兰药学家） 在12年前发现的药物， 但它从来没有被用来给人治病， 事实上甚至没有人知道 这种药是否有效， 如果这种药不纯净是否会致死， 但是弗洛里和他的团队觉得 如果他们需要使用这种药，不妨干脆在 已无药可救的患者身上试试看。\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"Here are the source text in English and translation in Chinese. \n",
    "English: {src}\n",
    "Chinese: {tgt}\n",
    "\n",
    "Segment the source text and the translation by sentence boundary (. ? !) and form a one-to-one mapping between source sentences and translation sentences. Output results with the following JSON format. Do not include any other text.\n",
    "[\n",
    "    {{\n",
    "        \"English\": \"...\",\n",
    "        \"Chinese\": \"...\"\n",
    "    }},\n",
    "    ...\n",
    "]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"developer\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt\n",
    "        }\n",
    "    ],\n",
    "    temperature=0.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "pairs = json.loads('\\n'.join(completion.choices[0].message.content.split('\\n')[1:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_1 = ' '.join([p['English'] for p in pairs])\n",
    "tgt_1 = ' '.join([p['Chinese'] for p in pairs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(src_1), len(tgt_1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(src), len(tgt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine the forward translation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = read_tsv(\"/compute/babel-14-5/siqiouya/en-zh/train_ft_traj_45.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 4\n",
    "samples[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "Audio(read_wav(samples[idx]['audio'])[0], rate=16000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine the DPO training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = read_tsv(\"/compute/babel-6-13/xixu/train.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_format(raw_str):\n",
    "    # Remove the outer quotes\n",
    "    cleaned_str = raw_str.strip('\"')\n",
    "\n",
    "    # Remove the extra quotes around the array\n",
    "    if cleaned_str.startswith('['):\n",
    "        cleaned_str = cleaned_str[1:-1]\n",
    "\n",
    "    # Split on '\", \"' to get individual elements\n",
    "    elements = cleaned_str.split('\", \"')\n",
    "\n",
    "    # Clean up each element\n",
    "    elements = [e.strip('\"').encode().decode('unicode_escape') for e in elements]\n",
    "\n",
    "    return elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(samples[0]['trajectory'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fix_format(samples[0]['sampling']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in samples:\n",
    "    x['sampling'] = fix_format(x['sampling'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_tsv(samples, \"/compute/babel-6-13/xixu/train__formated.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update training set with forward translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = read_tsv(\"/compute/babel-14-5/siqiouya/en-zh/train.tsv\")\n",
    "complement_samples = read_tsv(\"/compute/babel-14-5/siqiouya/en-zh/comet_0.50_complement_tower.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(samples), len(complement_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples[0], complement_samples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_indices = set()\n",
    "for x in complement_samples:\n",
    "    id = x['id'].strip()\n",
    "    if id in comp_indices:\n",
    "        print(x)\n",
    "    comp_indices.add(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2pair = {}\n",
    "for x in complement_samples:\n",
    "    id2pair[x['id'].strip()] = (x['src_text'].strip(), x['translation'].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = set(x['id'].strip() for x in samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_indices = set(x['id'].strip() for x in complement_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(comp_indices & indices), len(comp_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "for x in samples:\n",
    "    if x['id'].strip() in id2pair:\n",
    "        cnt += 1\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "Audio(read_wav('/compute/babel-14-5/siqiouya/en-zh/data/train/wav/ted_423.wav:1704960:691200')[0], rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in samples:\n",
    "    id = x['id'].strip()\n",
    "    if id in comp_indices:\n",
    "        x['src_text'] = id2pair[id][0]\n",
    "        x['tgt_text'] = id2pair[id][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_tsv(samples, \"/compute/babel-14-5/siqiouya/en-zh/train_ft.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLEU on MWERSEGMENT Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root = \"/compute/babel-5-23/siqiouya/runs/8B-traj-s2-v3.0/last.ckpt/simul-results-full/seg3840_beam1_ms0/tmp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_doc = len(os.listdir(root)) // 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyps = []\n",
    "refs = []\n",
    "hyps_full = []\n",
    "refs_full = []\n",
    "for i in range(n_doc):\n",
    "    with open(os.path.join(root, 'hyp.{}.seg'.format(i)), 'r') as r:\n",
    "        hyps_doc = r.read().strip().split('\\n')\n",
    "    with open(os.path.join(root, 'ref.{}'.format(i)), 'r') as r:\n",
    "        refs_doc = r.read().strip().split('\\n')\n",
    "    hyps_doc = [''.join(h.split(' ')) for h in hyps_doc]\n",
    "    refs_doc = [''.join(r.split(' ')) for r in refs_doc]\n",
    "    hyps.extend(hyps_doc)\n",
    "    refs.extend(refs_doc)\n",
    "\n",
    "    hyps_full.append(' '.join(hyps_doc))\n",
    "    refs_full.append(' '.join(refs_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sacrebleu.corpus_bleu(hyps, [refs], tokenize='zh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyps[10], refs[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hyps_full[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(refs_full[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sacrebleu.corpus_bleu(hyps_full, [refs_full], tokenize='zh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples = read_logs(\"/compute/babel-5-23/siqiouya/runs/8B-traj-s2-v3.0/last.ckpt/simul-results-full/cache4000_seg960_beam1_ms0/instances.log.corrected\")\n",
    "samples = read_logs(\"/compute/babel-5-23/siqiouya/runs/8B-traj-s2-v3.0/last.ckpt/sampling_dev/cache4000_seg960_beam1_ms0/0/instances.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "delays = np.array(samples[idx]['delays'])\n",
    "elapsed = np.array(samples[idx]['elapsed'])\n",
    "plt.plot(delays / 1000 / 60, label='Delays')\n",
    "plt.plot(elapsed / 1000 / 60, label='Elapsed time') \n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delays_diff = delays[1:] - delays[:-1]\n",
    "elapsed_diff = elapsed[1:] - elapsed[:-1]\n",
    "delays_diff = delays_diff[delays_diff > 0]\n",
    "elapsed_diff = elapsed_diff[elapsed_diff > 0]\n",
    "\n",
    "plt.plot(elapsed_diff - delays_diff)\n",
    "plt.ylim(0, 5000)\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Per step generation cost (ms)')\n",
    "# plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_token = []\n",
    "cnt = 0\n",
    "for i in range(1, len(elapsed)):\n",
    "    if elapsed[i] == elapsed[i - 1]:\n",
    "        cnt += 1\n",
    "    else:\n",
    "        n_token.append(cnt)\n",
    "        cnt = 1\n",
    "sum(n_token)\n",
    "\n",
    "nocache_n_token = []\n",
    "cnt = 0\n",
    "for i in range(1, len(nocache_elapsed)):\n",
    "    if nocache_elapsed[i] == nocache_elapsed[i - 1]:\n",
    "        cnt += 1\n",
    "    else:\n",
    "        nocache_n_token.append(cnt)\n",
    "        cnt = 1\n",
    "sum(nocache_n_token)\n",
    "\n",
    "running_avg = np.convolve(n_token, np.ones(10)/10, mode='valid')\n",
    "nocache_running_avg = np.convolve(nocache_n_token, np.ones(10)/10, mode='valid')\n",
    "plt.plot(running_avg)\n",
    "# plt.plot(nocache_running_avg, label='No cache')\n",
    "plt.legend()\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Running average # of tokens generated per step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/compute/babel-5-23/siqiouya/runs/8B-s2-v2.0-bi/last.ckpt/offline_beam1/tst-COMMON/hyp\", \"r\") as r:\n",
    "    hyps = r.read().strip().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyps = [(int(h.split(\"\\t\")[0]), h.split(\"\\t\")[1]) for h in hyps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyps = sorted(hyps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmented_samples = read_tsv(\"/compute/babel-14-5/siqiouya/en-zh/tst-COMMON.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(segmented_samples)):\n",
    "    segmented_samples[i]['idx'] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmented_samples = sorted(segmented_samples, key=lambda x: (int(x['id'].split('_')[1]), int(x['audio'].split(':')[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ted_id = int(segmented_samples[0]['id'].split('_')[1])\n",
    "full_hyps = []\n",
    "full_refs = []\n",
    "full_hyp = \"\"\n",
    "full_ref = \"\"\n",
    "for i, s in enumerate(segmented_samples):\n",
    "    cur_ted_id = int(s['id'].split('_')[1])\n",
    "    if cur_ted_id != ted_id:\n",
    "        full_hyps.append(full_hyp)\n",
    "        full_refs.append(full_ref)\n",
    "        full_hyp = \"\"\n",
    "        full_ref = \"\"\n",
    "        ted_id = cur_ted_id        \n",
    "    full_hyp += hyps[s['idx']][1] + '\\n'\n",
    "    full_ref += s['tgt_text'] + '\\n'\n",
    "full_hyps.append(full_hyp)\n",
    "full_refs.append(full_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(full_refs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu = sacrebleu.BLEU(tokenize='zh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyps = full_hyps[0].split(\"\\n\")\n",
    "refs = full_refs[0].split(\"\\n\")\n",
    "sacrebleu.corpus_bleu(\n",
    "    hyps, [refs], tokenize='zh'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyps = full_hyps[:1]\n",
    "refs = full_refs[:1]\n",
    "sacrebleu.corpus_bleu(\n",
    "    hyps, [refs], tokenize='zh'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Full TED tst-COMMON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def read_tsv(tsv_path):\n",
    "    import csv\n",
    "    with open(tsv_path) as f:\n",
    "        reader = csv.DictReader(\n",
    "            f,\n",
    "            delimiter=\"\\t\",\n",
    "            quotechar=None,\n",
    "            doublequote=False,\n",
    "            lineterminator=\"\\n\",\n",
    "            quoting=csv.QUOTE_NONE,\n",
    "        )\n",
    "        samples = [dict(e) for e in reader]\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/compute/babel-14-5/siqiouya/en-zh/'\n",
    "split = 'tst-COMMON'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = read_tsv(os.path.join(root, split + '.tsv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def key_func(x):\n",
    "    _, offset, _ = x['audio'].split(':')\n",
    "    offset = int(offset)\n",
    "\n",
    "    ted_id = int(x['id'].split('_')[1])\n",
    "\n",
    "    return (ted_id, offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_samples = sorted(\n",
    "    samples, \n",
    "    key=key_func\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ted_id = -1\n",
    "document = \"\"\n",
    "documents = []\n",
    "for x in sorted_samples:\n",
    "    cur_ted_id = int(x['id'].split('_')[1])\n",
    "    if cur_ted_id != ted_id:\n",
    "        documents.append((ted_id, document))\n",
    "        ted_id = cur_ted_id\n",
    "        document = x['tgt_text']\n",
    "    else:\n",
    "        document += ' ' + x['tgt_text']\n",
    "documents.append((ted_id, document))\n",
    "documents = documents[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(root, split + '_full.source'), 'w') as w_source, open(os.path.join(root, split + '_full.target'), 'w') as w_target:\n",
    "    for ted_id, document in documents:\n",
    "        w_source.write(os.path.join(\"/compute/babel-14-5/siqiouya/en-zh/data/tst-COMMON/wav/\", f\"ted_{ted_id}.wav\") + '\\n')\n",
    "        w_target.write(document + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug Beam Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse, os, sys, time, json\n",
    "sys.path.append(\"/home/siqiouya/work/sllama\")\n",
    "from collections import Counter\n",
    "\n",
    "from typing import Optional\n",
    "from simuleval.agents.states import AgentStates\n",
    "from simuleval.utils import entrypoint\n",
    "from simuleval.data.segments import SpeechSegment\n",
    "from simuleval.agents import SpeechToTextAgent\n",
    "from simuleval.agents.actions import WriteAction, ReadAction\n",
    "from simuleval.agents.states import AgentStates\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import transformers\n",
    "import soundfile as sf\n",
    "\n",
    "import conversation as conversation_lib\n",
    "from conversation import SeparatorStyle\n",
    "from eval.utils import disable_torch_init\n",
    "from model.model_new import SpeechLlamaForCausalLM\n",
    "from model.utils import SpaceStoppingCriteria, KeywordsStoppingCriteria\n",
    "# from train.uni_wav2vec_monkey_patch import replace_uni_train\n",
    "from fairseq.data.audio.speech_to_text_dataset import _collate_frames\n",
    "\n",
    "from train.options import (\n",
    "    add_speech_encoder_args,\n",
    "    add_simuleval_args,\n",
    "    add_gen_args\n",
    ")\n",
    "from model.speech_encoder import (\n",
    "    SpeechEncoderHuBERTRope,\n",
    "    SpeechEncoderW2V2RoPE,\n",
    "    SpeechEncoderW2VBERT2\n",
    ")\n",
    "from train.dataset import (\n",
    "    DEFAULT_SPEECH_PATCH_TOKEN,\n",
    "    DEFAULT_SPEECH_START_TOKEN,\n",
    "    DEFAULT_SPEECH_END_TOKEN\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "    \"/compute/babel-4-1/siqiouya/llama-3.1-8b-instruct-hf\",\n",
    "    padding_side=\"right\",\n",
    "    use_fast=False,\n",
    ")\n",
    "tokenizer.pad_token = \"<|finetune_right_pad_id|>\"\n",
    "\n",
    "model = SpeechLlamaForCausalLM.from_pretrained(\n",
    "    \"/compute/babel-4-1/siqiouya/llama-3.1-8b-instruct-hf\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map='cuda',\n",
    ").eval()\n",
    "\n",
    "speech_encoder_args = [\n",
    "    \"/data/user_data/siqiouya/runs/pretrained/wav2_vec_vox_960h_pl.pt\",\n",
    "    True,\n",
    "    \"[(1024,2,2)] * 2\",\n",
    "    \n",
    "    48,\n",
    "    500,\n",
    "    model.model.embed_tokens.embedding_dim,\n",
    "    None,\n",
    "    False,\n",
    "]\n",
    "speech_encoder = SpeechEncoderW2V2RoPE(*speech_encoder_args).eval()\n",
    "speech_encoder.to(dtype=model.dtype, device=model.device)\n",
    "\n",
    "length_shrink_func = speech_encoder._get_feat_extract_output_lengths\n",
    "\n",
    "model.model.speech_encoder = speech_encoder\n",
    "model.preprocess(tokenizer=tokenizer)\n",
    "\n",
    "state_dict = torch.load(\"/compute/babel-5-23/siqiouya/runs/8B-traj-s2-v2.2/last.ckpt/pytorch_model.bin\", map_location='cpu', weights_only=True)\n",
    "model.load_state_dict(state_dict)\n",
    "model.model.inference = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "source, rate = sf.read(\"/compute/babel-14-5/siqiouya/en-zh/data/tst-COMMON/wav_split/ted_1096_11.wav\")\n",
    "segment_size = 960 * 16 * 2\n",
    "source = source[:segment_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "Audio(source, rate=rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = torch.tensor(source)\n",
    "sp_seg_frame = int(48 // 4 * 0.08 * 16000)\n",
    "if source.size(0) % sp_seg_frame != 0:\n",
    "    n_pad = sp_seg_frame - source.size(0) % sp_seg_frame\n",
    "    source = torch.cat([source, torch.zeros(n_pad).to(source)], dim=0)\n",
    "offset = torch.zeros(79 + 320).to(source)\n",
    "source = torch.cat([offset, source], dim=0)        \n",
    "# old_src_len = states.src_len\n",
    "# states.src_len = source.size(0)\n",
    "# source = source[old_src_len:]\n",
    "\n",
    "speech_batch = source.unsqueeze(0).to(device=model.device, dtype=model.dtype)\n",
    "n_frames = torch.tensor([source.size(0)], dtype=torch.long).to(model.device)\n",
    "speech_lens = length_shrink_func(n_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_batch.size(), n_frames, speech_lens  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "messages.append(\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": f\"Translate the following speech from English to Chinese.\"\n",
    "        }\n",
    "    )\n",
    "messages.append(\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": 12 * DEFAULT_SPEECH_PATCH_TOKEN\n",
    "    }\n",
    ")\n",
    "messages.append(\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"在我\",\n",
    "    }\n",
    ")\n",
    "messages.append(\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": 12 * DEFAULT_SPEECH_PATCH_TOKEN\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "messages.append(\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer.apply_chat_template(\n",
    "    [messages],\n",
    "    return_tensors='pt',\n",
    "    padding=True, \n",
    "    truncation=False, \n",
    "    add_special_tokens=False\n",
    ")[:, :-1].cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model.speech_features_extracted = False\n",
    "outputs = model.generate(\n",
    "    attention_mask=None,\n",
    "    input_ids=input_ids,\n",
    "    speech_batch=speech_batch,\n",
    "    src_lengths=n_frames,\n",
    "    after_lens=speech_lens,\n",
    "    do_sample=False,\n",
    "    top_p=1.0,\n",
    "    temperature=1.0,\n",
    "    num_beams=4,\n",
    "    max_new_tokens=100,\n",
    "    no_repeat_ngram_size=3,\n",
    "    repetition_penalty=1.2,\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    "    return_dict_in_generate=True,\n",
    "    return_legacy_cache=False,\n",
    "    output_scores=True,\n",
    "    use_cache=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.decode(outputs.sequences[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids[0, :57 + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.past_key_values[0][0][0, 0][56]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_batch = speech_batch.float()\n",
    "speech_encoder.encode_speech(\n",
    "    speech_batch, n_frames\n",
    ")[0][:, :12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_encoder.encode_speech(\n",
    "    speech_batch[:, :15759], n_frames * 0 + 15759\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sacrebleu import BLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirname = \"/compute/babel-5-23/siqiouya/runs/8B-s2-v2.0/last.ckpt/offline_beam4/tst-COMMON/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(dirname, 'hyp'), 'r') as f:\n",
    "    hyps = [l.split('\\t')[1].strip() for l in f.readlines() if len(l.split('\\t')) > 1]\n",
    "with open(os.path.join(dirname, 'ref'), 'r') as f:\n",
    "    refs = [l.split('\\t')[1].strip() for l in f.readlines() if len(l.split('\\t')) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyps = np.array(hyps)\n",
    "refs = np.array(refs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = BLEU(tokenize='zh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens = [(len(r), i) for i, r in enumerate(refs)]\n",
    "sorted_lens = sorted(lens, key=lambda x: x[0])\n",
    "sorted_indices = [si[1] for si in sorted_lens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer.corpus_score(\n",
    "    hyps[sorted_indices[-1000:]].tolist(),\n",
    "    [refs[sorted_indices[-1000:]].tolist()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tsv(tsv_path):\n",
    "    import csv\n",
    "    with open(tsv_path) as f:\n",
    "        reader = csv.DictReader(\n",
    "            f,\n",
    "            delimiter=\"\\t\",\n",
    "            quotechar=None,\n",
    "            doublequote=False,\n",
    "            lineterminator=\"\\n\",\n",
    "            quoting=csv.QUOTE_NONE,\n",
    "        )\n",
    "        samples = [dict(e) for e in reader]\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsv_path = \"/compute/babel-6-17/xixu/datasets/must-c-v2.0/en-zh/{}.tsv\".format(\"train\")\n",
    "full_samples = read_tsv(tsv_path)\n",
    "tsv_path = \"/compute/babel-6-17/xixu/datasets/must-c-v2.0/en-zh/{}.tsv\".format(\"comet_0.50\")\n",
    "half_samples = read_tsv(tsv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(full_samples), len(half_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_duration = np.array([s[\"n_frames\"] for s in full_samples], dtype=np.int32) / 16000\n",
    "half_duration = np.array([s[\"n_frames\"] for s in half_samples], dtype=np.int32) / 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(full_duration, bins=50, alpha=0.5, label='Full Duration')\n",
    "plt.hist(half_duration, bins=50, alpha=0.5, label='Half Duration')\n",
    "plt.xlim(20)\n",
    "plt.ylim(0, 1000)\n",
    "plt.xlabel('Duration (seconds)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Histogram of Full Duration and Half Duration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_refs = np.array([len(s[\"tgt_text\"]) for s in full_samples])\n",
    "half_refs = np.array([len(s[\"tgt_text\"]) for s in half_samples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(full_refs > 100).sum(), (half_refs > 100).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(full_refs, bins=50, alpha=0.5, label='Full Refs')\n",
    "plt.hist(half_refs, bins=50, alpha=0.5, label='Half Refs')\n",
    "plt.xlabel('# of characters')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Histogram of Full Refs and Half Refs')\n",
    "plt.xlim(100)\n",
    "plt.ylim(0, 1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_samples = read_tsv(\"/compute/babel-6-17/xixu/datasets/must-c-v1.0/en-de/train.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_refs = np.array([len(s[\"tgt_text\"].split(' ')) for s in de_samples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_refs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(de_refs, bins=50, alpha=0.5, label='De Refs')\n",
    "plt.xlabel('# of words')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Histogram of Full Refs and Half Refs')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Llama 3.1 Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-02-10 16:02:22,158] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "Warning: The cache directory for DeepSpeed Triton autotune, /home/siqiouya/.triton/autotune, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/siqiouya/anaconda3/envs/speechllama/compiler_compat/ld: warning: librt.so.1, needed by /usr/local/cuda/lib64/libcufile.so, not found (try using -rpath or -rpath-link)\n",
      "/home/siqiouya/anaconda3/envs/speechllama/compiler_compat/ld: warning: libpthread.so.0, needed by /usr/local/cuda/lib64/libcufile.so, not found (try using -rpath or -rpath-link)\n",
      "/home/siqiouya/anaconda3/envs/speechllama/compiler_compat/ld: warning: libm.so.6, needed by /usr/local/cuda/lib64/libcufile.so, not found (try using -rpath or -rpath-link)\n",
      "/home/siqiouya/anaconda3/envs/speechllama/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `log2f@GLIBC_2.2.5'\n",
      "/home/siqiouya/anaconda3/envs/speechllama/compiler_compat/ld: /home/siqiouya/anaconda3/envs/sllama_lightning/lib//libstdc++.so.6: undefined reference to `fesetround@GLIBC_2.2.5'\n",
      "/home/siqiouya/anaconda3/envs/speechllama/compiler_compat/ld: /home/siqiouya/anaconda3/envs/sllama_lightning/lib//libstdc++.so.6: undefined reference to `fegetround@GLIBC_2.2.5'\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    }
   ],
   "source": [
    "import argparse, os, sys, time, json\n",
    "sys.path.append(\"/home/siqiouya/work/sllama\")\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "from collections import Counter\n",
    "\n",
    "from IPython.display import Audio\n",
    "\n",
    "from typing import Optional\n",
    "from simuleval.agents.states import AgentStates\n",
    "from simuleval.utils import entrypoint\n",
    "from simuleval.data.segments import SpeechSegment\n",
    "from simuleval.agents import SpeechToTextAgent\n",
    "from simuleval.agents.actions import WriteAction, ReadAction\n",
    "from simuleval.agents.states import AgentStates\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import transformers\n",
    "\n",
    "import conversation as conversation_lib\n",
    "from conversation import SeparatorStyle\n",
    "from eval.utils import disable_torch_init\n",
    "from model.model_new import SpeechLlamaForCausalLM\n",
    "from model.utils import SpaceStoppingCriteria, KeywordsStoppingCriteria\n",
    "# from train.uni_wav2vec_monkey_patch import replace_uni_train\n",
    "from fairseq.data.audio.speech_to_text_dataset import _collate_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bos_token': '<|begin_of_text|>',\n",
       " 'eos_token': '<|eot_id|>',\n",
       " 'pad_token': '<|finetune_right_pad_id|>'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.special_tokens_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "    # \"/compute/babel-4-1/siqiouya/llama-3.1-8b-instruct-hf\",\n",
    "    \"/compute/babel-4-1/siqiouya/llama-3-8b-instruct-hf\",\n",
    "    padding_side=\"right\",\n",
    "    use_fast=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad_token is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'NoneType' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 12\u001b[0m\n\u001b[1;32m      7\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39mpad_token \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<|finetune_right_pad_id|>\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m messages \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      9\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are a pirate chatbot who always responds in pirate speak!\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m     10\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWho are you?\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m     11\u001b[0m ]\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28mprint\u001b[39m(tokenizer\u001b[38;5;241m.\u001b[39mbatch_decode(\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_chat_template\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m)\u001b[49m)[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/speechllama/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1706\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.apply_chat_template\u001b[0;34m(self, conversation, tools, documents, chat_template, add_generation_prompt, continue_final_message, tokenize, padding, truncation, max_length, return_tensors, return_dict, return_assistant_tokens_mask, tokenizer_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     rendered \u001b[38;5;241m=\u001b[39m rendered[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tokenize:\n\u001b[0;32m-> 1706\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrendered\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1708\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1709\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1710\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1711\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1712\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1713\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtokenizer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1714\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1715\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m return_dict:\n\u001b[1;32m   1716\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m return_assistant_tokens_mask:\n",
      "File \u001b[0;32m~/anaconda3/envs/speechllama/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2860\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2858\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_target_context_manager:\n\u001b[1;32m   2859\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_input_mode()\n\u001b[0;32m-> 2860\u001b[0m     encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mall_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2861\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2862\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_target_mode()\n",
      "File \u001b[0;32m~/anaconda3/envs/speechllama/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2970\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m   2948\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_encode_plus(\n\u001b[1;32m   2949\u001b[0m         batch_text_or_text_pairs\u001b[38;5;241m=\u001b[39mbatch_text_or_text_pairs,\n\u001b[1;32m   2950\u001b[0m         add_special_tokens\u001b[38;5;241m=\u001b[39madd_special_tokens,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2967\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   2968\u001b[0m     )\n\u001b[1;32m   2969\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2970\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2973\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2976\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2977\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2978\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2979\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2980\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2981\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2982\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2983\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2984\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2985\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2986\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2987\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2988\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2989\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2990\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2991\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/speechllama/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:3037\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   3016\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3017\u001b[0m \u001b[38;5;124;03mTokenize and prepare for the model a sequence or a pair of sequences.\u001b[39;00m\n\u001b[1;32m   3018\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3033\u001b[0m \u001b[38;5;124;03m        method).\u001b[39;00m\n\u001b[1;32m   3034\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3036\u001b[0m \u001b[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[0;32m-> 3037\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_padding_truncation_strategies\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3038\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3039\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3040\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3041\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3042\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3043\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3044\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3046\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encode_plus(\n\u001b[1;32m   3047\u001b[0m     text\u001b[38;5;241m=\u001b[39mtext,\n\u001b[1;32m   3048\u001b[0m     text_pair\u001b[38;5;241m=\u001b[39mtext_pair,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3066\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3067\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/speechllama/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2761\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._get_padding_truncation_strategies\u001b[0;34m(self, padding, truncation, max_length, pad_to_multiple_of, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2758\u001b[0m             max_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_max_length\n\u001b[1;32m   2760\u001b[0m \u001b[38;5;66;03m# Test if we have a padding token\u001b[39;00m\n\u001b[0;32m-> 2761\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m padding_strategy \u001b[38;5;241m!=\u001b[39m PaddingStrategy\u001b[38;5;241m.\u001b[39mDO_NOT_PAD \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpad_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m):\n\u001b[1;32m   2762\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2763\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsking to pad but the tokenizer does not have a padding token. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2764\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2765\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor add a new pad token via `tokenizer.add_special_tokens(\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpad_token\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[PAD]\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m})`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2766\u001b[0m     )\n\u001b[1;32m   2768\u001b[0m \u001b[38;5;66;03m# Check that we will truncate to a multiple of pad_to_multiple_of if both are provided\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'NoneType' and 'int'"
     ]
    }
   ],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "    # \"/compute/babel-4-1/siqiouya/llama-3.1-8b-instruct-hf\",\n",
    "    \"/compute/babel-4-1/siqiouya/llama-3-8b-instruct-hf\",\n",
    "    padding_side=\"right\",\n",
    "    use_fast=False,\n",
    ")\n",
    "tokenizer.pad_token = \"<|finetune_right_pad_id|>\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a pirate chatbot who always responds in pirate speak!\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
    "]\n",
    "print(tokenizer.batch_decode(tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    padding=True, \n",
    "    truncation=False, \n",
    "    add_special_tokens=False,\n",
    "    return_tensors='pt',\n",
    "))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are a pirate chatbot who always responds in pirate speak!<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Who are you?<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "    \"/compute/babel-4-1/siqiouya/llama-3.1-8b-instruct-hf\",\n",
    "    # \"/compute/babel-4-1/siqiouya/llama-3-8b-instruct-hf\",\n",
    "    padding_side=\"right\",\n",
    "    use_fast=False,\n",
    ")\n",
    "tokenizer.pad_token = \"<|finetune_right_pad_id|>\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a pirate chatbot who always responds in pirate speak!\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
    "]\n",
    "print(tokenizer.batch_decode(tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    return_tensors='pt',\n",
    "))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SpeechLlamaForCausalLM.from_pretrained(\n",
    "    \"/compute/babel-4-1/siqiouya/llama-3.1-8b-instruct-hf\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map='cuda',\n",
    ").eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a pirate chatbot who always responds in pirate speak!\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"\"}\n",
    "]\n",
    "m2 = [\n",
    "    {\"role\": \"system\", \"content\": \"Translate the following speech from English to Chinese.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.apply_chat_template(\n",
    "    [m1, m2], \n",
    "    return_tensors='pt',\n",
    "    padding=True, \n",
    "    truncation=False, \n",
    "    add_special_tokens=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.convert_ids_to_tokens([128009])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse, os, sys, time, json\n",
    "sys.path.append(\"/home/siqiouya/work/sllama\")\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "from collections import Counter\n",
    "\n",
    "from IPython.display import Audio\n",
    "\n",
    "from typing import Optional\n",
    "from simuleval.agents.states import AgentStates\n",
    "from simuleval.utils import entrypoint\n",
    "from simuleval.data.segments import SpeechSegment\n",
    "from simuleval.agents import SpeechToTextAgent\n",
    "from simuleval.agents.actions import WriteAction, ReadAction\n",
    "from simuleval.agents.states import AgentStates\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import transformers\n",
    "\n",
    "import conversation as conversation_lib\n",
    "from conversation import SeparatorStyle\n",
    "from eval.utils import disable_torch_init\n",
    "from model.model_new import SpeechLlamaForCausalLM\n",
    "from model.utils import SpaceStoppingCriteria, KeywordsStoppingCriteria\n",
    "# from train.uni_wav2vec_monkey_patch import replace_uni_train\n",
    "from fairseq.data.audio.speech_to_text_dataset import _collate_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train.options import (\n",
    "    add_speech_encoder_args,\n",
    "    add_simuleval_args,\n",
    "    add_gen_args\n",
    ")\n",
    "from model.speech_encoder import (\n",
    "    SpeechEncoderHuBERTRope,\n",
    "    SpeechEncoderW2V2RoPE,\n",
    "    SpeechEncoderW2VBERT2\n",
    ")\n",
    "from train.dataset import (\n",
    "    DEFAULT_SPEECH_PATCH_TOKEN,\n",
    "    DEFAULT_SPEECH_START_TOKEN,\n",
    "    DEFAULT_SPEECH_END_TOKEN\n",
    ")\n",
    "from train.dataset import (\n",
    "    SpeechSampler, \n",
    "    PromptSpeechToTextDatasetCreator, \n",
    "    SpeechToTextDatasetItem,\n",
    "    DataCollatorForSupervisedDataset,\n",
    "    DataCollatorForTrajectoryDataset,\n",
    "    DataCollatorForTrajectoryInstructDataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "    \"/compute/babel-4-1/siqiouya/llama-3.1-8b-instruct-hf\",\n",
    "    padding_side=\"right\",\n",
    "    use_fast=False,\n",
    ")\n",
    "tokenizer.pad_token = \"<|finetune_right_pad_id|>\"\n",
    "\n",
    "model = SpeechLlamaForCausalLM.from_pretrained(\n",
    "    \"/compute/babel-4-1/siqiouya/llama-3.1-8b-instruct-hf\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map='cuda',\n",
    ").eval()\n",
    "\n",
    "speech_encoder_args = [\n",
    "    \"/data/user_data/siqiouya/runs/pretrained/wav2_vec_vox_960h_pl.pt\",\n",
    "    True,\n",
    "    \"[(1024,2,2)] * 2\",    \n",
    "    48,\n",
    "    500,\n",
    "    model.model.embed_tokens.embedding_dim,\n",
    "    None,\n",
    "    False,\n",
    "]\n",
    "speech_encoder = SpeechEncoderW2V2RoPE(*speech_encoder_args)\n",
    "\n",
    "speech_encoder.to(dtype=model.dtype, device=model.device)\n",
    "length_shrink_func = speech_encoder._get_feat_extract_output_lengths\n",
    "\n",
    "model.model.speech_encoder = speech_encoder\n",
    "model.preprocess(tokenizer=tokenizer)\n",
    "\n",
    "# state_dict = torch.load(\n",
    "#     \"/compute/babel-5-23/siqiouya/runs/8B-traj-s2-v1.2/epoch=0-step=1213.ckpt/pytorch_model.bin\", \n",
    "#     map_location='cpu', \n",
    "#     weights_only=True\n",
    "# )\n",
    "# model.load_state_dict(state_dict)\n",
    "# model.model.inference = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_speech(states):\n",
    "    source = torch.tensor(states.source)\n",
    "    sp_seg_frame = int(12 * 0.08 * 16000)\n",
    "    if source.size(0) % sp_seg_frame != 0:\n",
    "        n_pad = sp_seg_frame - source.size(0) % sp_seg_frame\n",
    "        source = torch.cat([source, torch.zeros(n_pad).to(source)], dim=0)\n",
    "    offset = torch.zeros(79 + 320).to(source)\n",
    "    source = torch.cat([offset, source], dim=0)\n",
    "    old_src_len = states.src_len\n",
    "    states.src_len = source.size(0)\n",
    "    source = source[old_src_len:]\n",
    "\n",
    "    speech_batch = source.unsqueeze(0).to(device='cuda', dtype=torch.bfloat16)\n",
    "    n_frames = torch.tensor([source.size(0)], dtype=torch.long).to('cuda')\n",
    "    speech_lens = length_shrink_func(n_frames)\n",
    "    return speech_batch, n_frames, speech_lens\n",
    "def prepare_inputs(states, speech_lens):\n",
    "    prompt = \"\"\n",
    "    if states.speech_cache is None:\n",
    "        prompt += f\"Translate the following speech from English to Chinese: \"\n",
    "    sp_tokens = DEFAULT_SPEECH_START_TOKEN + \\\n",
    "        speech_lens[0] * DEFAULT_SPEECH_PATCH_TOKEN + \\\n",
    "        DEFAULT_SPEECH_END_TOKEN\n",
    "    prompt += sp_tokens\n",
    "\n",
    "    inputs = tokenizer(\n",
    "        [prompt],\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=False,\n",
    "        add_special_tokens=False,\n",
    "    )\n",
    "    input_ids = inputs.input_ids.cuda()\n",
    "    return input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"MASTER_ADDR\"] = \"0.0.0.0\"\n",
    "os.environ[\"MASTER_PORT\"] = \"9105\"\n",
    "torch.distributed.init_process_group(\n",
    "    rank=0, world_size=1, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train_dataset = PromptSpeechToTextDatasetCreator.from_tsv(\n",
    "    \"/compute/babel-6-17/xixu/datasets/must-c-v2.0/en-zh\",\n",
    "    \"comet_0.50_traj\",\n",
    ")\n",
    "data_collator = DataCollatorForTrajectoryInstructDataset(\n",
    "    tokenizer, \n",
    "    length_shrink_func, \n",
    "    \"English\",\n",
    "    \"Chinese\",\n",
    "    block_size=48,\n",
    ")\n",
    "\n",
    "train_sampler = SpeechSampler(\n",
    "    train_dataset, \n",
    "    shuffle=True, \n",
    "    batch_size=800000, \n",
    "    batch_size_sent=20,\n",
    "    min_ms=320,\n",
    "    multiplier=32,\n",
    "    filter=True,\n",
    "    target_lang=\"Chinese\"\n",
    ")\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_sampler=train_sampler, \n",
    "    collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.convert_tokens_to_ids('<|start_header_id|>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = list(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = batches[-4]\n",
    "print(tokenizer.batch_decode(batch['input_ids']))\n",
    "\n",
    "sp_end_id = tokenizer.convert_tokens_to_ids(DEFAULT_SPEECH_END_TOKEN)\n",
    "sp_end_indices = (batch['input_ids'] == sp_end_id).nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx += 1\n",
    "partial_input_ids = batch[\"input_ids\"][:, :sp_end_indices[idx, 1] + 1]\n",
    "print(tokenizer.batch_decode(partial_input_ids))\n",
    "\n",
    "partial_speech_batch = batch[\"speech_batch\"][:, :79 + 320 + 48 * 320 * (idx + 1)]\n",
    "display(Audio(partial_speech_batch, rate=16000))\n",
    "partial_n_frames = torch.tensor([partial_speech_batch.size(1)], dtype=torch.long)\n",
    "partial_speech_lens = length_shrink_func(partial_n_frames)\n",
    "stop_str = \"<|end_of_text|>\"\n",
    "keywords = [stop_str]\n",
    "stopping_criteria = KeywordsStoppingCriteria(\n",
    "    keywords, tokenizer, partial_input_ids.clone()\n",
    ")\n",
    "model.model.speech_features_extracted = False\n",
    "outputs = model.generate(\n",
    "    attention_mask=None,\n",
    "    input_ids=partial_input_ids.to(model.device),\n",
    "    speech_batch=partial_speech_batch.to(model.device, model.dtype),\n",
    "    src_lengths=partial_n_frames.to(model.device),\n",
    "    after_lens=partial_speech_lens.to(model.device),\n",
    "    do_sample=False,\n",
    "    num_beams=1,\n",
    "    max_new_tokens=100,\n",
    "    no_repeat_ngram_size=3,\n",
    "    repetition_penalty=1.2,\n",
    "    temperature=1.0,\n",
    "    top_p=1.0,\n",
    "    stopping_criteria=[stopping_criteria],\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    "    return_dict_in_generate=True,\n",
    "    use_cache=True,\n",
    "    # past_key_values=states.past_key_values,\n",
    "    # states=states,\n",
    ")\n",
    "print(tokenizer.batch_decode(outputs.sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval.agents.streamllama import S2TAgentStates\n",
    "states = S2TAgentStates(0, None, None, [])\n",
    "idx = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx += 1\n",
    "states.source = list(batch[\"speech_batch\"][0, :48 * 320 * (idx + 1)])\n",
    "speech_batch, n_frames, speech_lens = prepare_speech(states)\n",
    "input_ids = prepare_inputs(states, speech_lens)\n",
    "\n",
    "max_number_of_tokens = 100\n",
    "\n",
    "stop_str = \"<|end_of_text|>\"\n",
    "keywords = [stop_str]\n",
    "stopping_criteria = KeywordsStoppingCriteria(\n",
    "    keywords, tokenizer, torch.tensor(input_ids)\n",
    ")\n",
    "\n",
    "model.model.speech_features_extracted = False\n",
    "outputs = model.generate(\n",
    "    attention_mask=None,\n",
    "    input_ids=input_ids,\n",
    "    speech_batch=speech_batch,\n",
    "    src_lengths=n_frames,\n",
    "    after_lens=speech_lens,\n",
    "    do_sample=False,\n",
    "    num_beams=1,\n",
    "    max_new_tokens=max(1, max_number_of_tokens - len(states.target_ids)),\n",
    "    no_repeat_ngram_size=3,\n",
    "    repetition_penalty=1.2,\n",
    "    temperature=1.0,\n",
    "    top_p=1.0,\n",
    "    stopping_criteria=[stopping_criteria],\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    "    return_dict_in_generate=True,\n",
    "    use_cache=True,\n",
    "    past_key_values=states.past_key_values,\n",
    "    states=states,\n",
    ")\n",
    "\n",
    "states.past_key_values = outputs.past_key_values\n",
    "print(tokenizer.batch_decode(outputs.sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states.src_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_input_ids, input_ids, speech_lens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare data for simuleval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import soundfile as sf\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_split = 'train'\n",
    "split = 'train_st_zh_ft_traj_30_filtered_po10k_gpt-4o-mini-2024-07-18_fa_traj'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsv_path = \"/compute/babel-14-5/siqiouya/en-zh/{}.tsv\".format(split)\n",
    "with open(tsv_path, encoding='utf-8') as f:\n",
    "    reader = csv.DictReader(\n",
    "        f,\n",
    "        delimiter=\"\\t\",\n",
    "        quotechar=None,\n",
    "        doublequote=False,\n",
    "        lineterminator=\"\\n\",\n",
    "        quoting=csv.QUOTE_NONE,\n",
    "    )\n",
    "    samples = [dict(e) for e in reader]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"/compute/babel-14-5/siqiouya/en-zh/data/{}/wav_split_30/\".format(base_split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in tqdm(samples):\n",
    "    path, offset, n_frame = x['audio'].split(':')\n",
    "    wav, sr = sf.read(path, frames=int(n_frame), start=int(offset))\n",
    "    sf.write(f\"/compute/babel-14-5/siqiouya/en-zh/data/{base_split}/wav_split_30/{x['id']}.wav\", wav, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_partition = 8\n",
    "partition_size = (len(samples) + n_partition - 1) // n_partition\n",
    "for idx in range(8):\n",
    "    with open(f\"/compute/babel-14-5/siqiouya/en-zh/{split}.source.{idx}\", \"w\") as w_src, \\\n",
    "         open(f\"/compute/babel-14-5/siqiouya/en-zh/{split}.target.{idx}\", \"w\") as w_tgt:\n",
    "        for x in samples[idx * partition_size:(idx + 1) * partition_size]:  # Split samples into 8 parts\n",
    "            w_src.write(f\"/compute/babel-14-5/siqiouya/en-zh/data/{base_split}/wav_split_30/{x['id']}.wav\" + \"\\n\")\n",
    "            w_tgt.write(x[\"tgt_text\"] + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# filter tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsv_path = \"/compute/babel-6-17/xixu/datasets/must-c-v2.0/en-zh/dev_traj.tsv\"\n",
    "with open(tsv_path) as f:\n",
    "    reader = csv.DictReader(\n",
    "        f,\n",
    "        delimiter=\"\\t\",\n",
    "        quotechar=None,\n",
    "        doublequote=False,\n",
    "        lineterminator=\"\\n\",\n",
    "        quoting=csv.QUOTE_NONE,\n",
    "    )\n",
    "    samples = [dict(e) for e in reader]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(samples))\n",
    "samples = [s for s in samples if s[\"trajectory\"] != \"\"]\n",
    "print(len(samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(tsv_path, \"w\") as w:\n",
    "    writer = csv.DictWriter(\n",
    "        w,\n",
    "        reader.fieldnames + ['trajectory'],\n",
    "        delimiter=\"\\t\",\n",
    "        quotechar=None,\n",
    "        doublequote=False,\n",
    "        lineterminator=\"\\n\",\n",
    "        quoting=csv.QUOTE_NONE,\n",
    "    )\n",
    "    writer.writeheader()\n",
    "    writer.writerows(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load w2v2-conformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoFeatureExtractor, Wav2Vec2BertModel, Wav2Vec2BertConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\"/data/user_data/siqiouya/runs/pretrained/w2v-bert-2.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = torch.rand(300000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = feature_extractor(audio[:320 + 79 + 320 * 1], sampling_rate=16000, return_tensors=\"pt\", do_normalize_per_mel_bins=False)\n",
    "f2 = feature_extractor(audio[:320 + 79 + 320 * 2], sampling_rate=16000, return_tensors=\"pt\", do_normalize_per_mel_bins=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = Wav2Vec2BertConfig.from_pretrained(\"/data/user_data/siqiouya/runs/pretrained/w2v-bert-2.0\")\n",
    "model_config.layerdrop = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Wav2Vec2BertModel.from_pretrained(\n",
    "    \"/data/user_data/siqiouya/runs/pretrained/w2v-bert-2.0\",\n",
    "    config=model_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/siqiouya/work/sllama\")\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "from eval.utils import disable_torch_init\n",
    "from model.model_new import SpeechLlamaForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/compute/babel-7-1/siqiouya/runs/3.1-8B-s1-english-german-w2v2-rope/checkpoint-3400/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "disable_torch_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "    path,\n",
    "    padding_side=\"left\",\n",
    "    use_fast=False,\n",
    ")\n",
    "tokenizer.pad_token = \"<|finetune_right_pad_id|>\"\n",
    "\n",
    "config = json.load(open(os.path.join(path, 'config.json')))\n",
    "config['large_model'] = True\n",
    "update_config = os.path.join(path, 'config_large.json')\n",
    "if not os.path.exists(update_config):\n",
    "    json.dump(config, open(update_config, 'w'), indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SpeechLlamaForCausalLM.from_pretrained(\n",
    "    path,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map='auto',\n",
    "    config=update_config\n",
    ").eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "ckpt = torch.load(\"/compute/babel-7-1/siqiouya/runs/3.1-8B-s1-english-german-w2v2-rope/checkpoint-3400/speech_encoder.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HuBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import fairseq\n",
    "from fairseq.models.hubert import HubertEncoder\n",
    "from fairseq.models.wav2vec import Wav2VecEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = \"/mnt/data/siqiouyang/download/hubert_large_ll60k_finetune_ls960.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models, cfg, task = fairseq.checkpoint_utils.load_model_ensemble_and_task([ckpt_path])\n",
    "model = models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cfg.model.w2v_args.model.encoder_embed_dim)\n",
    "print(cfg.model.w2v_args.model.encoder_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.w2v_encoder.w2v_model.encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simplified Wav2Vec2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/siqiouyang/work/projects/sllama\")\n",
    "sys.path.append(\"/home/siqiouyang/work/projects/sllama/wav2vec/src\")\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = torch.load(\"/mnt/taurus/data/xixu/models/wav2_vec_vox_960h_pl.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ckpt['args'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RoPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from rotary_embedding_torch import RotaryEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotary_emb = RotaryEmbedding(dim = 32)\n",
    "\n",
    "# mock queries and keys - dimensions should end with (seq_len, feature dimension), and any number of preceding dimensions (batch, heads, etc)\n",
    "\n",
    "q = torch.randn(1, 8, 1024, 64) # queries - (batch, heads, seq len, dimension of head)\n",
    "k = torch.randn(1, 8, 1024, 64) # keys\n",
    "\n",
    "# apply the rotations to your queries and keys after the heads have been split out, but prior to the dot product and subsequent softmax (attention)\n",
    "\n",
    "q = rotary_emb.rotate_queries_or_keys(q)\n",
    "k = rotary_emb.rotate_queries_or_keys(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotary_emb = RotaryEmbedding(dim = 16)\n",
    "\n",
    "# mock queries and keys - dimensions should end with (seq_len, feature dimension), and any number of preceding dimensions (batch, heads, etc)\n",
    "\n",
    "q = torch.randn(1, 8, 1024, 64) # queries - (batch, heads, seq len, dimension of head)\n",
    "k = torch.randn(1, 8, 1024, 64) # keys\n",
    "\n",
    "# apply the rotations to your queries and keys after the heads have been split out, but prior to the dot product and subsequent softmax (attention)\n",
    "\n",
    "q = rotary_emb.rotate_queries_or_keys(q)\n",
    "k = rotary_emb.rotate_queries_or_keys(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotary_emb.freqs.size(), \n",
    "q.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate New Speech Encoder on Long Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/siqiouya/work/sllama')\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import copy\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchaudio\n",
    "import transformers\n",
    "from model.speech_encoder import SpeechEncoder, SpeechEncoderW2V2RoPE\n",
    "from model.model import SpeechLlamaForCausalLM\n",
    "from fairseq.examples.speech_to_text.data_utils import load_df_from_tsv, save_df_to_tsv\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = SpeechLlamaForCausalLM.from_pretrained(\n",
    "    # \"/mnt/taurus/data/siqiouyang/download/llama3.1-8b-hf\",\n",
    "    \"/compute/babel-4-1/siqiouya/llama-3.1-8b-hf\",\n",
    "    # low_cpu_mem_usage=True,\n",
    "    load_in_8bit=False,\n",
    "    device_map='cuda'\n",
    "    # device_map='cpu',\n",
    ")\n",
    "\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "    # \"/mnt/taurus/data/siqiouyang/download/llama3.1-8b-hf\",\n",
    "    \"/compute/babel-4-1/siqiouya/llama-3.1-8b-hf\",\n",
    "    padding_side=\"right\",\n",
    "    use_fast=False,\n",
    ")\n",
    "tokenizer.pad_token = \"<|finetune_right_pad_id|>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SpeechEncoderW2V2RoPE(\n",
    "    \"/mnt/taurus/data/xixu/models/wav2_vec_vox_960h_pl.pt\",\n",
    "    True,\n",
    "    \"[(1024,2,2)] * 2\",    \n",
    "    48,\n",
    "    500,      \n",
    "    copy.deepcopy(llm.model.embed_tokens),\n",
    ").to('cuda')\n",
    "del llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = torch.load(\"/mnt/taurus/data/siqiouyang/runs/sllama/en-de/crtl-stage0-w2v2-cache10s/epoch=57-step=75021.ckpt\")\n",
    "model.load_state_dict(ckpt['state_dict'])\n",
    "del ckpt\n",
    "\n",
    "model.eval()\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_df_from_tsv(\"/mnt/aries/data/siqiouyang/datasets/must-c-v1.0/dev_st_de_full_mfa_llama3.tsv\")\n",
    "df_tst = load_df_from_tsv(\"/mnt/aries/data/siqiouyang/datasets/must-c-v1.0/tst-COMMON_st_de_full_mfa_llama3.tsv\")\n",
    "\n",
    "df_seg = load_df_from_tsv(\"/mnt/aries/data/siqiouyang/datasets/must-c-v1.0/dev_st_de_mfa_llama3.tsv\")\n",
    "df_tst_seg = load_df_from_tsv(\"/mnt/aries/data/siqiouyang/datasets/must-c-v1.0/tst-COMMON_st_de_mfa_llama3.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, df_tst], ignore_index=True)\n",
    "df_seg = pd.concat([df_seg, df_tst_seg], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sims(df):\n",
    "    all_sims = []\n",
    "    for df_idx in tqdm(range(len(df))):\n",
    "        d = df.iloc[df_idx]\n",
    "\n",
    "        if d['speech_word'] is None or d['speech_word'] == '':\n",
    "            continue\n",
    "\n",
    "        path, offset, duration = d['audio'].split(':')\n",
    "        offset = int(offset)\n",
    "        duration = int(duration)\n",
    "        wav, sr = torchaudio.load(path, frame_offset=offset, num_frames=duration)\n",
    "\n",
    "        ted_id = int(d['id'].split('_')[1])\n",
    "\n",
    "        cache = None\n",
    "        outputs = []\n",
    "        last_frame = 0\n",
    "        for i in range(79 + 320, wav.size(1), 320 * 48):\n",
    "            x = wav[:, last_frame : i + 320 * 48].to('cuda')\n",
    "\n",
    "            if x.size(1) < 320 * 48:\n",
    "                pad = torch.zeros(1, 320 * 48 - x.size(1)).to(x)\n",
    "                x = torch.cat([x, pad], dim=1)\n",
    "            \n",
    "            x_len = torch.LongTensor([x.size(1)]).to('cuda')\n",
    "\n",
    "            output, cache = model.encode_speech(x, x_len, cache=cache)\n",
    "            outputs.append(output)\n",
    "            last_frame = i + 320 * 48\n",
    "                \n",
    "        full_output = torch.cat(outputs, dim=1)\n",
    "\n",
    "        speech_words = torch.tensor(eval(d['speech_word']))\n",
    "        text_words = torch.tensor(eval(d['text_word']))\n",
    "        src_text = tokenizer.encode(\n",
    "            d['src_text'],\n",
    "            return_tensors=\"pt\",\n",
    "            padding=\"longest\",\n",
    "            truncation=False,\n",
    "            add_special_tokens=False\n",
    "        ).to('cuda')\n",
    "        src_text_emb = model.llm_embedding(src_text)\n",
    "        for i in range(speech_words.size(0)):\n",
    "            s_l, s_r = speech_words[i]\n",
    "            t_l, t_r = text_words[i]\n",
    "\n",
    "            s_l = int((s_l / 0.08).floor())\n",
    "            s_r = min(int((s_r / 0.08).ceil()), full_output.size(1)) - 1\n",
    "\n",
    "            s_word_emb = full_output[0][s_l : s_r + 1].mean(dim=0)\n",
    "            t_word_emb = src_text_emb[0][t_l : t_r + 1].mean(dim=0)\n",
    "\n",
    "            sim = F.cosine_similarity(s_word_emb, t_word_emb, dim=0)\n",
    "            all_sims.append((ted_id, speech_words[i][1].item() + offset / 16000, sim.item()))  \n",
    "    return all_sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sims = get_sims(df)\n",
    "all_sims_seg = get_sims(df_seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_full = {}\n",
    "d_seg = {}\n",
    "for ted_id, offset, sim in all_sims:\n",
    "    d_full[ted_id] = d_full.get(ted_id, []) + [(offset, sim)]\n",
    "for ted_id, offset, sim in all_sims_seg:\n",
    "    d_seg[ted_id] = d_seg.get(ted_id, []) + [(offset, sim)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_simr = []\n",
    "for ted_id in d_full.keys():\n",
    "    d_full[ted_id].sort(key=lambda x: x[0])\n",
    "    d_seg[ted_id].sort(key=lambda x: x[0])\n",
    "    for x, y in zip(d_full[ted_id], d_seg[ted_id]):\n",
    "        assert x[0] - y[0] < 1e-2\n",
    "        time_simr.append((x[0], np.log(x[1] / y[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_simr = np.array(time_simr)\n",
    "mean_simrs = []\n",
    "for i in range(30 * 6):\n",
    "    mean_simrs.append(np.nanmean(time_simr[(time_simr[:, 0] >= i * 10) & (time_simr[:, 0] < (i + 1) * 10), -1]))\n",
    "plt.plot(mean_simrs)\n",
    "plt.xlabel('Time (10s)')\n",
    "plt.ylabel('log(sim from full / sim from seg)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sims = np.array(all_sims)\n",
    "mean_sims = []\n",
    "for i in range(30 * 6):\n",
    "    mean_sims.append(all_sims[(all_sims[:, 1] >= i * 10) & (all_sims[:, 1] < (i + 1) * 10), -1].mean())\n",
    "plt.plot(mean_sims)\n",
    "plt.xlabel('Time (10s)')\n",
    "plt.ylabel('sim from full')\n",
    "# plt.xlabel(\"Input Length (unit: 10 seconds)\")\n",
    "# plt.ylabel(\"Cosine Similarity of Speech and Text Embeddings\")\n",
    "# plt.savefig(\"/home/siqiouyang/work/projects/sllama/notebooks/length_extrapolation.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_df_from_tsv(\"/mnt/aries/data/siqiouyang/datasets/must-c-v1.0/train_st_de_full_mfa_llama3.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df['n_frames'] >= 15 * 60 * 16000).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df_to_tsv(df[df['n_frames'] >= 15 * 60 * 16000], \"/mnt/aries/data/siqiouyang/datasets/must-c-v1.0/train_st_de_full_15min_mfa_llama3.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Speech Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "cfgs = [(1024, 10, 5)] + [(1024, 3, 2)] * 4 + [(1024,2,2)] * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/siqiouya/work/sllama')\n",
    "from model.speech_encoder import ConvFeatureExtractionModel\n",
    "feature_extractor = ConvFeatureExtractionModel(cfgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.rand(1, 79 + 1280 * 2)\n",
    "x2 = torch.cat([x1, torch.rand(1, 1280)], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = feature_extractor(x1)\n",
    "y2 = feature_extractor(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(y1[0, :, 0] - y2[0, :, 0]) / y1[0, :, 0].abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feat_extract_output_lengths(input_lengths):\n",
    "    \"\"\"\n",
    "    Computes the output length of the convolutional layers\n",
    "    \"\"\"\n",
    "\n",
    "    def _conv_out_length(input_length, kernel_size, stride):\n",
    "        return torch.floor((input_length - kernel_size) / stride + 1)\n",
    "\n",
    "    for cfg in cfgs:\n",
    "        input_lengths = _conv_out_length(\n",
    "            input_lengths, cfg[1], cfg[2]\n",
    "        )\n",
    "\n",
    "    return input_lengths.to(torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_lens = get_feat_extract_output_lengths(torch.arange(0, 160000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = []\n",
    "for i in range(len(out_lens) - 1):\n",
    "    if out_lens[i] != out_lens[i + 1]:\n",
    "        t.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_feat_extract_output_lengths(torch.tensor([80]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from x_transformers.x_transformers import RotaryEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = RotaryEmbedding(512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq, scale = emb(torch.ones(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\"/data/user_data/siqiouya/runs/pretrained/llama-2-7b/hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer(\n",
    "    [\"Hello\", \"Hello 1\"],\n",
    "    padding=True,\n",
    "    padding_side='left',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import types\n",
    "from comet import download_model, load_from_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def read_tsv(tsv_path):\n",
    "    import csv\n",
    "    with open(tsv_path) as f:\n",
    "        reader = csv.DictReader(\n",
    "            f,\n",
    "            delimiter=\"\\t\",\n",
    "            quotechar=None,\n",
    "            doublequote=False,\n",
    "            lineterminator=\"\\n\",\n",
    "            quoting=csv.QUOTE_NONE,\n",
    "        )\n",
    "        samples = [dict(e) for e in reader]\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comet_model = load_from_checkpoint(\"/compute/babel-7-5/siqiouya/xcomet_xxl/snapshots/bad20b47daa64c41a8b29f3d3016be75baf0d7b4/checkpoints/model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = \"/compute/babel-14-5/siqiouya/en-zh/\"\n",
    "samples = read_tsv(os.path.join(data_root, \"tst-COMMON.tsv\"))\n",
    "srcs = [s[\"src_text\"] for s in samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/compute/babel-5-23/siqiouya/runs/8B-traj-s2-v2.2/last.ckpt/simul-results/beam1_mult1_ms0/instances.log\", \"r\") as r:\n",
    "    instances = [json.loads(line) for line in r.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "comet_data = [\n",
    "    {\n",
    "        \"src\": srcs[i],\n",
    "        \"mt\" : instances[i]['prediction'].strip(),\n",
    "        \"ref\": instances[i]['reference'].strip()\n",
    "    }\n",
    "    for i in range(len(srcs))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comet_output = comet_model.predict(comet_data, batch_size=4, gpus=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comet_output.system_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "offline_results_dir = \"/compute/babel-5-23/siqiouya/runs/8B-s2-v2.0-bi/last.ckpt/offline_beam1/tst-COMMON/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(offline_results_dir, 'hyp'), 'r') as f:\n",
    "    hyps = [l for l in f.readlines() if len(l.split('\\t')) > 1]\n",
    "with open(os.path.join(offline_results_dir, 'ref'), 'r') as f:\n",
    "    refs = [l for l in f.readlines() if len(l.split('\\t')) > 1]\n",
    "\n",
    "hs = []\n",
    "rs = []\n",
    "for hyp, ref in zip(hyps, refs):\n",
    "    idx = int(hyp.split('\\t')[0])\n",
    "    hs.append((idx, hyp.split('\\t')[1].strip()))\n",
    "    rs.append((idx, ref.split('\\t')[1].strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs = sorted(hs)\n",
    "rs = sorted(rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "comet_data_off = [\n",
    "    {\n",
    "        \"src\": srcs[i],\n",
    "        \"mt\" : hs[i][1],\n",
    "        \"ref\": rs[i][1],\n",
    "    }\n",
    "    for i in range(len(srcs))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comet_output_off = comet_model.predict(comet_data_off, batch_size=4, gpus=1)\n",
    "comet_output_off.system_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tst-COMMON de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import yaml\n",
    "import pandas as pd\n",
    "from fairseq.examples.speech_to_text.data_utils import load_df_from_tsv, save_df_to_tsv\n",
    "from fairseq.data.audio.audio_utils import (\n",
    "    get_fbank,\n",
    "    get_waveform,\n",
    "    read_from_stored_zip,\n",
    "    is_npy_data,\n",
    "    is_sf_audio_data,\n",
    "    parse_path,\n",
    "    FEATURE_OR_SF_AUDIO_FILE_EXTENSIONS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_or_waveform(\n",
    "        path: str,\n",
    "):\n",
    "    import soundfile as sf\n",
    "    _path, slice_ptr = parse_path(path)\n",
    "    if len(slice_ptr) == 0:\n",
    "        waveform, sample_rate = sf.read(_path, dtype=\"float32\",)\n",
    "    elif len(slice_ptr) == 2:\n",
    "        waveform, sample_rate = sf.read(_path, dtype=\"float32\",\n",
    "                                start=int(slice_ptr[0]), frames=int(slice_ptr[1]))\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid path: {_path}\")\n",
    "    return waveform, sample_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('alignatt_instances.log', 'r') as r:\n",
    "    instances = [json.loads(l) for l in r.readlines() if l.strip() != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances[0]['reference']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_df_from_tsv('/data/user_data/siqiouya/dataset/must-c-v1.0/en-de/tst-COMMON.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/data/user_data/siqiouya/dataset/must-c-v1.0/en-de/data/tst-COMMON/txt/tst-COMMON.yaml', 'r') as r:\n",
    "    manifest = yaml.safe_load(r)\n",
    "with open('/data/user_data/siqiouya/dataset/must-c-v1.0/en-de/data/tst-COMMON/txt/tst-COMMON.en', 'r') as r:\n",
    "    src_text = [l.strip() for l in r.readlines() if l.strip() != '']\n",
    "with open('/data/user_data/siqiouya/dataset/must-c-v1.0/en-de/data/tst-COMMON/txt/tst-COMMON.de', 'r') as r:\n",
    "    tgt_text = [l.strip() for l in r.readlines() if l.strip() != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifest[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['audio'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df.columns\n",
    "columns[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame(columns=df.columns[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "ids = []\n",
    "audios = []\n",
    "n_frames = []\n",
    "speakers = []\n",
    "for i in range(len(manifest)):\n",
    "    if i > 0 and manifest[i]['wav'] != manifest[i - 1]['wav']:\n",
    "        cnt = 0\n",
    "\n",
    "    wav = manifest[i]['wav']\n",
    "    ids.append(wav.split('.')[0] + '_{}'.format(cnt))\n",
    "    offset_frame = int(manifest[i]['offset'] * 16000)\n",
    "    duration_frame = int(manifest[i]['duration'] * 16000)\n",
    "    audio = \"/data/user_data/siqiouya/dataset/must-c-v1.0/en-de/data/tst-COMMON/wav/{}:{}:{}\".format(wav, offset_frame, duration_frame)\n",
    "    audios.append(audio)\n",
    "    n_frames.append(duration_frame)\n",
    "    speakers.append(manifest[i]['speaker_id'])\n",
    "\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['id'] = ids\n",
    "new_df['audio'] = audios\n",
    "new_df['n_frames'] = n_frames\n",
    "new_df['speaker'] = speakers\n",
    "new_df['src_text'] = src_text\n",
    "new_df['tgt_text'] = tgt_text\n",
    "new_df['src_lang'] = ['en'] * len(src_text)\n",
    "new_df['tgt_lang'] = ['de'] * len(tgt_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df_to_tsv(new_df, '/data/user_data/siqiouya/dataset/must-c-v1.0/en-de/tst-COMMON.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Per 10s Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/data/user_data/siqiouya/dataset/must-c-v1.0/en-es/tst-COMMON.source', 'r') as r:\n",
    "    sources = np.array([line.strip() for line in r.readlines() if line.strip() != \"\"])\n",
    "with open('/data/user_data/siqiouya/dataset/must-c-v1.0/en-es/tst-COMMON.target', 'r') as r:\n",
    "    targets = np.array([line.strip() for line in r.readlines() if line.strip() != \"\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_frames = np.array([torchaudio.info(src).num_frames for src in tqdm(sources)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "durations = n_frames / 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for duration in [10, 20, 30, 40, 50, 60]:\n",
    "    source = sources[(duration - 1 < durations) & (durations < duration + 1)][0]\n",
    "    target = targets[(duration - 1 < durations) & (durations < duration + 1)][0]\n",
    "    with open('/data/user_data/siqiouya/dataset/must-c-v1.0/en-es/tst-COMMON-profile-{}s.source'.format(duration), 'w') as w:\n",
    "        w.write('\\n'.join([source] * 5))\n",
    "\n",
    "    with open('/data/user_data/siqiouya/dataset/must-c-v1.0/en-es/tst-COMMON-profile-{}s.target'.format(duration), 'w') as w:\n",
    "        w.write('\\n'.join([target] * 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computation Overhead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/data/user_data/siqiouya/runs/stage3-uni-waco-word-block50-fixed-mix-from-stage0/simul-results/30s-wait-k-word-inc-opt-1000ms-n3-bsz8/wait-1000ms-2/instances.log\"\n",
    "# path = \"/data/user_data/siqiouya/runs/stage3-uni-waco-word-block50-fixed-mix-from-stage0/simul-results/30s-wait-k-word-inc-opt-1000ms-n3-bsz8-recomp-w2v2/wait-1000ms-2/instances.log\"\n",
    "# path = \"/data/user_data/siqiouya/runs/stage3-uni-waco-word-block50-fixed-mix-from-stage0/simul-results/30s-wait-k-word-inc-opt-1000ms-n3-bsz8-recomp-llm/wait-1000ms-2/instances.log\"\n",
    "# path = \"/data/user_data/siqiouya/runs/stage2-bi-mix-fix/simul-results/30s-wait-k-word-1000ms-n3-bsz8/wait-1000ms-2/instances.log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = []\n",
    "with open(path, 'r') as r:\n",
    "    for line in r.readlines():\n",
    "        line = line.strip()\n",
    "        if line != \"\":\n",
    "            instances.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum = n = m = 0\n",
    "for ist in instances:\n",
    "    elapsed = np.array(ist['elapsed'])\n",
    "    delays = np.array(ist['delays'])\n",
    "    src_len = ist['source_length']\n",
    "    elapsed = elapsed[delays < src_len]\n",
    "    if len(elapsed) > 0:\n",
    "        sum += elapsed[-1]\n",
    "        n += len(elapsed)\n",
    "\n",
    "        # sum += ist['elapsed'][-1]\n",
    "        # n += len(ist['elapsed'])\n",
    "    else:\n",
    "        m += 1\n",
    "print(sum / n, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ist['elapsed']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# en-de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "from train.dataset import get_features_or_waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav = get_features_or_waveform(\"/data/user_data/siqiouya/dataset/must-c-v1.0/en-es/data/tst-COMMON/wav/ted_1096.wav:201760:1816160\")\n",
    "Audio(wav[0], rate=wav[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Previous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from fairseq.examples.speech_to_text.data_utils import load_df_from_tsv, save_df_to_tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirname = '/data/user_data/siqiouya/dataset/must-c-v1.0/en-es'\n",
    "split = 'train_mfa'\n",
    "df = load_df_from_tsv(os.path.join(dirname, split + '.tsv'))\n",
    "# new_paths = []\n",
    "# for a in df['audio']:\n",
    "#     new_paths.append('/scratch/siqiouya/dataset/must-c-v1.0/' + a)\n",
    "# df['audio'] = new_paths\n",
    "# save_df_to_tsv(df, os.path.join(dirname, split + '.tsv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['text_word'] == '']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_config = os.path.join(, 'config_large.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change path of tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from fairseq.examples.speech_to_text.data_utils import load_df_from_tsv, save_df_to_tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_df_from_tsv(os.path.join('/scratch/siqiouya/dataset/must-c-v1.0/en-es/', '{}.tsv'.format(dev)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_2d_causal_mask(seq_len, dtype, device='gpu', blocksize=1):\n",
    "    \"\"\"\n",
    "    Generates a 2D causal mask for multi-head attention.\n",
    "    \n",
    "    Args:\n",
    "        seq_len (int): The length of the sequence.\n",
    "        dtype (torch.dtype): The data type for the mask.\n",
    "        device (str): The device on which to create the mask.\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: A 2D causal attention mask.\n",
    "    \"\"\"\n",
    "    blocksizes = [min(blocksize, seq_len - i * blocksize) for i in range((seq_len + blocksize - 1) // blocksize)]\n",
    "    blocks = [torch.ones((s, s), device=device, dtype=dtype) for s in blocksizes]\n",
    "    mask = torch.block_diag(*blocks)\n",
    "\n",
    "    tril_row, tril_col = torch.tril_indices(seq_len, seq_len)\n",
    "    mask[tril_row, tril_col] = 1\n",
    "\n",
    "    mask.masked_fill_(mask == 0, float('-inf'))\n",
    "    mask.masked_fill_(mask == 1, 0)\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_2d_causal_mask(6, float, device='cpu', blocksize=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mfa_30s_mix_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = load_df_from_tsv(\"/data/user_data/siqiouya/dataset/must-c-v1.0/en-es/train_mfa_30s_mix_filtered.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.iloc[231870]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torchaudio.info(\"/scratch/siqiouya/dataset/must-c-v1.0/en-es/data/train/wav/ted_26.wav\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "17256479\n",
    "3857750"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tst-COMMON_30s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torchaudio\n",
    "import IPython.display\n",
    "from fairseq.examples.speech_to_text.data_utils import load_df_from_tsv, save_df_to_tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_path = '/data/user_data/siqiouya/dataset/must-c-v1.0/en-es/tst-COMMON.tsv'\n",
    "long_path = '/data/user_data/siqiouya/dataset/must-c-v1.0/en-es/tst-COMMON_st_es_30s.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_df = load_df_from_tsv(ori_path)\n",
    "long_df = load_df_from_tsv(long_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_df.iloc[19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_wav(path):\n",
    "    path, offset, duration = path.split(':')\n",
    "    wav, _ = torchaudio.load(path, int(offset), int(duration))\n",
    "    return wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(read_wav(ori_df['audio'][19]), rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_df['src_text'][19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import types\n",
    "from comet import download_model, load_from_checkpoint\n",
    "from fairseq.examples.speech_to_text.data_utils import load_df_from_tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comet_model = load_from_checkpoint(\"/data/user_data/siqiouya/runs/pretrained/models--Unbabel--XCOMET-XXL/snapshots/bad20b47daa64c41a8b29f3d3016be75baf0d7b4/checkpoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_df_from_tsv('/data/user_data/siqiouya/dataset/must-c-v1.0/en-es/tst-COMMON_30s.tsv')\n",
    "src_texts = df['src_text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [\n",
    "    '/data/user_data/siqiouya/runs/stage3-uni-waco-word-block16-fixed-mix-from-stage0-l40/simul-results/30s-wait-k-word-inc-opt-bsz8/wait-320ms-13/',\n",
    "    '/data/user_data/siqiouya/runs/stage2-bi-mix-fix/simul-results/30s-wait-k-word-bsz8/wait-320ms-13/'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in paths:\n",
    "    instances = []\n",
    "    instances_log_path = os.path.join(path, 'instances.log')\n",
    "    hyps = []\n",
    "    refs = []\n",
    "    with open(instances_log_path, 'r') as r:\n",
    "        for line in r.readlines():\n",
    "            line = line.strip()\n",
    "            if line != '':\n",
    "                d = json.loads(line)\n",
    "                instance = types.SimpleNamespace(**d)\n",
    "                hyps.append(instance.prediction)\n",
    "                refs.append(instance.reference)\n",
    "    comet_data = [\n",
    "        {\n",
    "            \"src\": src_texts[i],\n",
    "            \"mt\" : hyps[i],\n",
    "            \"ref\": refs[i]\n",
    "        }\n",
    "        for i in range(len(hyps))\n",
    "    ]\n",
    "    comet_output = comet_model.predict(comet_data[:10], batch_size=7, gpus=1)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speechllama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
