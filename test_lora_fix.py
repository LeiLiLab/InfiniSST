#!/usr/bin/env python3
"""
æµ‹è¯•LoRAä¿®å¤çš„è„šæœ¬
"""
import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), 'retriever', 'gigaspeech', 'modal'))

import torch
import numpy as np

def test_audio_encoding_shape():
    """æµ‹è¯•éŸ³é¢‘ç¼–ç å½¢çŠ¶ä¿®å¤"""
    print("ğŸ§ª Testing Audio Encoding Shape Fix")
    print("=" * 50)
    
    try:
        from Qwen2_Audio_train import Qwen2AudioSpeechEncoder, Qwen2AudioTextEncoder, ContrastiveQwen2AudioModel
        
        device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"Using device: {device}")
        
        # åˆ›å»ºæ¨¡å‹
        speech_encoder = Qwen2AudioSpeechEncoder(device=device)
        shared_model = speech_encoder.get_shared_model()
        text_encoder = Qwen2AudioTextEncoder(device=device, shared_model=shared_model)
        
        model = ContrastiveQwen2AudioModel(
            speech_encoder=speech_encoder,
            text_encoder=text_encoder,
            proj_dim=512,
            lora_r=16,
            lora_alpha=32,
            lora_dropout=0.1
        )
        
        # è®¾ç½®è®­ç»ƒæ¨¡å¼
        model.train()
        
        # å¼ºåˆ¶å¯ç”¨LoRAæ¢¯åº¦
        print("\nğŸ”§ Forcing LoRA gradients...")
        model.force_enable_lora_gradients()
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        print("\nğŸ¯ Creating test data...")
        batch_size = 4
        dummy_audios = [torch.randn(16000, dtype=torch.float32) for _ in range(batch_size)]
        dummy_texts = ["This is test text." for _ in range(batch_size)]
        
        # æµ‹è¯•ç¼–ç 
        print("\nğŸš€ Testing encoding...")
        audio_emb = model.encode_audio(dummy_audios)
        text_emb = model.encode_text(dummy_texts)
        
        print(f"âœ… Audio embeddings shape: {audio_emb.shape}")
        print(f"âœ… Text embeddings shape: {text_emb.shape}")
        print(f"âœ… Audio embeddings requires_grad: {audio_emb.requires_grad}")
        print(f"âœ… Text embeddings requires_grad: {text_emb.requires_grad}")
        
        # è®¡ç®—æŸå¤±
        print("\nğŸ’¡ Testing loss calculation...")
        sim_matrix = (audio_emb @ text_emb.T) / 0.07
        labels = torch.arange(batch_size, dtype=torch.long, device=audio_emb.device)
        loss = torch.nn.functional.cross_entropy(sim_matrix, labels)
        
        print(f"âœ… Similarity matrix shape: {sim_matrix.shape}")
        print(f"âœ… Labels shape: {labels.shape}")
        print(f"âœ… Loss: {loss.item():.6f}")
        print(f"âœ… Loss requires_grad: {loss.requires_grad}")
        
        # åå‘ä¼ æ’­
        print("\nâ¬…ï¸ Testing backward pass...")
        loss.backward()
        
        # æ£€æŸ¥æ¢¯åº¦
        print("\nğŸ” Checking gradients...")
        model.check_lora_gradients(step=1)
        
        print("\nâœ… All tests passed!")
        return True
        
    except Exception as e:
        print(f"\nâŒ Test failed: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = test_audio_encoding_shape()
    if success:
        print("\nğŸ‰ LoRA fix verification successful!")
    else:
        print("\nğŸ’¥ LoRA fix verification failed!")
        sys.exit(1)

