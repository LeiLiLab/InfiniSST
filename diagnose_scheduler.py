#!/usr/bin/env python3
"""
Scheduleré˜Ÿåˆ—è¯Šæ–­å·¥å…·
å®æ—¶åˆ†æInfiniSST schedulerçš„çŠ¶æ€ï¼Œæ£€æµ‹ç“¶é¢ˆå’Œé—®é¢˜
"""

import asyncio
import json
import time
from typing import Dict, Any, List
import requests
import argparse

class SchedulerDiagnostics:
    """Schedulerè¯Šæ–­å·¥å…·"""
    
    def __init__(self, server_url: str = "http://localhost:8000"):
        self.server_url = server_url
        self.previous_stats = None
        
    def get_scheduler_stats(self) -> Dict[str, Any]:
        """ä»APIè·å–schedulerç»Ÿè®¡ä¿¡æ¯"""
        try:
            response = requests.get(f"{self.server_url}/diagnose", timeout=5)
            if response.status_code == 200:
                return response.json()
            else:
                print(f"âŒ APIè¿”å›é”™è¯¯: {response.status_code}")
                return {}
        except Exception as e:
            print(f"âŒ æ— æ³•è¿æ¥åˆ°æœåŠ¡å™¨: {e}")
            return {}
    
    def analyze_queue_status(self, stats: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†æé˜Ÿåˆ—çŠ¶æ€"""
        analysis = {
            'total_prefill_requests': 0,
            'total_decode_requests': 0,
            'total_requests': 0,
            'gpu_analysis': {},
            'bottlenecks': [],
            'page_estimates': {}
        }
        
        queue_info = stats.get('queue_stats', {}).get('detailed_queue_info', {})
        
        for gpu_id, gpu_info in queue_info.items():
            gpu_id = str(gpu_id)  # ç¡®ä¿æ˜¯å­—ç¬¦ä¸²
            prefill_count = gpu_info.get('prefill_queue_size', 0)
            decode_count = gpu_info.get('decode_queue_size', 0)
            total_count = prefill_count + decode_count
            
            analysis['total_prefill_requests'] += prefill_count
            analysis['total_decode_requests'] += decode_count
            analysis['total_requests'] += total_count
            
            # æ¯ä¸ªGPUçš„åˆ†æ
            gpu_analysis = {
                'language': gpu_info.get('language', 'unknown'),
                'prefill_queue': prefill_count,
                'decode_queue': decode_count,
                'total_queue': total_count,
                'queue_ratio': f"{prefill_count}P:{decode_count}D",
                'status': 'normal'
            }
            
            # ä¼°ç®—é¡µé¢ä½¿ç”¨é‡
            # åŸºäºç»éªŒå€¼ï¼šæ¯ä¸ªprefill request ~20é¡µï¼Œæ¯ä¸ªdecode request ~5é¡µ
            estimated_prefill_pages = prefill_count * 20
            estimated_decode_pages = decode_count * 5
            total_estimated_pages = estimated_prefill_pages + estimated_decode_pages
            
            analysis['page_estimates'][gpu_id] = {
                'prefill_pages': estimated_prefill_pages,
                'decode_pages': estimated_decode_pages,
                'total_pages': total_estimated_pages,
                'page_utilization_percent': min(100, (total_estimated_pages / 576) * 100)  # å‡è®¾576ä¸ªæ€»é¡µé¢
            }
            
            # æ£€æµ‹ç“¶é¢ˆ
            if total_count > 32:
                analysis['bottlenecks'].append(f"GPU {gpu_id} é˜Ÿåˆ—ä¸¥é‡ç§¯å‹: {total_count}ä¸ªrequests")
                gpu_analysis['status'] = 'overloaded'
            elif total_count > 16:
                analysis['bottlenecks'].append(f"GPU {gpu_id} é˜Ÿåˆ—ç§¯å‹: {total_count}ä¸ªrequests")
                gpu_analysis['status'] = 'busy'
            elif decode_count > 20:
                analysis['bottlenecks'].append(f"GPU {gpu_id} DECODEé˜Ÿåˆ—ç§¯å‹: {decode_count}ä¸ªrequests")
                gpu_analysis['status'] = 'decode_backlog'
            elif prefill_count > 8:
                analysis['bottlenecks'].append(f"GPU {gpu_id} PREFILLé˜Ÿåˆ—ç§¯å‹: {prefill_count}ä¸ªrequests")
                gpu_analysis['status'] = 'prefill_backlog'
            
            # é¡µé¢ä½¿ç”¨ç‡æ£€æŸ¥
            if total_estimated_pages > 500:
                analysis['bottlenecks'].append(f"GPU {gpu_id} é¡µé¢ä½¿ç”¨ç‡è¿‡é«˜: ~{total_estimated_pages}é¡µ")
                gpu_analysis['status'] = 'memory_pressure'
            
            analysis['gpu_analysis'][gpu_id] = gpu_analysis
        
        return analysis
    
    def analyze_session_status(self, stats: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†æsessionçŠ¶æ€"""
        analysis = {
            'active_sessions': 0,
            'stuck_sessions': [],
            'session_distribution': {},
            'memory_usage': {}
        }
        
        # è·å–å¡ä½çš„sessionä¿¡æ¯
        if 'stuck_sessions' in stats:
            analysis['stuck_sessions'] = stats['stuck_sessions']
        
        # åˆ†æsessionåˆ†å¸ƒ
        queue_stats = stats.get('queue_stats', {})
        if 'inactive_sessions' in queue_stats:
            inactive_sessions = queue_stats['inactive_sessions']
            analysis['active_sessions'] = queue_stats.get('active_sessions', 0)
            
            # æŒ‰è¯­è¨€ç»Ÿè®¡session
            for session in inactive_sessions:
                lang = session.get('language_id', 'unknown')
                if lang not in analysis['session_distribution']:
                    analysis['session_distribution'][lang] = 0
                analysis['session_distribution'][lang] += 1
        
        return analysis
    
    def print_diagnosis_report(self, stats: Dict[str, Any]):
        """æ‰“å°è¯Šæ–­æŠ¥å‘Š"""
        print("=" * 80)
        print("ğŸ” InfiniSST Scheduler è¯Šæ–­æŠ¥å‘Š")
        print("=" * 80)
        print(f"æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
        
        # é˜Ÿåˆ—çŠ¶æ€åˆ†æ
        queue_analysis = self.analyze_queue_status(stats)
        print("ğŸ“Š é˜Ÿåˆ—çŠ¶æ€:")
        print(f"   æ€»è¯·æ±‚æ•°: {queue_analysis['total_requests']}")
        print(f"   PREFILLé˜Ÿåˆ—: {queue_analysis['total_prefill_requests']} ä¸ªè¯·æ±‚")
        print(f"   DECODEé˜Ÿåˆ—: {queue_analysis['total_decode_requests']} ä¸ªè¯·æ±‚")
        print()
        
        # å„GPUè¯¦ç»†çŠ¶æ€
        print("ğŸ–¥ï¸  å„GPUçŠ¶æ€:")
        for gpu_id, gpu_info in queue_analysis['gpu_analysis'].items():
            status_emoji = {
                'normal': 'âœ…',
                'busy': 'âš ï¸',
                'overloaded': 'ğŸš¨',
                'decode_backlog': 'ğŸŸ¡',
                'prefill_backlog': 'ğŸŸ ',
                'memory_pressure': 'ğŸ”´'
            }.get(gpu_info['status'], 'â“')
            
            print(f"   GPU {gpu_id} ({gpu_info['language']}) {status_emoji}")
            print(f"      é˜Ÿåˆ—: {gpu_info['queue_ratio']} (æ€»è®¡: {gpu_info['total_queue']})")
            
            # é¡µé¢ä½¿ç”¨ä¼°ç®—
            page_info = queue_analysis['page_estimates'][gpu_id]
            print(f"      ä¼°ç®—é¡µé¢ä½¿ç”¨: {page_info['total_pages']} é¡µ ({page_info['page_utilization_percent']:.1f}%)")
            print(f"         - PREFILL: {page_info['prefill_pages']} é¡µ")
            print(f"         - DECODE: {page_info['decode_pages']} é¡µ")
            print()
        
        # SessionçŠ¶æ€åˆ†æ
        session_analysis = self.analyze_session_status(stats)
        print("ğŸ‘¥ SessionçŠ¶æ€:")
        print(f"   æ´»è·ƒSessions: {session_analysis['active_sessions']}")
        print(f"   å¡ä½Sessions: {len(session_analysis['stuck_sessions'])}")
        
        if session_analysis['stuck_sessions']:
            print("   å¡ä½çš„Sessionsè¯¦æƒ…:")
            for session in session_analysis['stuck_sessions']:
                print(f"      - {session.get('user_id', 'unknown')} ({session.get('language_id', 'unknown')})")
                print(f"        ä¸æ´»è·ƒæ—¶é—´: {session.get('inactive_seconds', 0):.1f}s")
                print(f"        æœªå¤„ç†éŸ³é¢‘: {session.get('unprocessed_samples', 0)} æ ·æœ¬")
                print(f"        é˜Ÿåˆ—çŠ¶æ€: P{session.get('prefill_queue_size', 0)} + D{session.get('decode_queue_size', 0)}")
        print()
        
        # ç“¶é¢ˆåˆ†æ
        print("ğŸš¨ ç“¶é¢ˆåˆ†æ:")
        if queue_analysis['bottlenecks']:
            for bottleneck in queue_analysis['bottlenecks']:
                print(f"   - {bottleneck}")
        else:
            print("   âœ… æœªæ£€æµ‹åˆ°æ˜æ˜¾ç“¶é¢ˆ")
        print()
        
        # æ¨èæ“ä½œ
        print("ğŸ’¡ æ¨èæ“ä½œ:")
        self.generate_recommendations(queue_analysis, session_analysis)
        print()
    
    def generate_recommendations(self, queue_analysis: Dict, session_analysis: Dict):
        """ç”Ÿæˆæ¨èæ“ä½œ"""
        recommendations = []
        
        # åŸºäºé˜Ÿåˆ—çŠ¶æ€çš„æ¨è
        if queue_analysis['total_requests'] > 50:
            recommendations.append("ç³»ç»Ÿè´Ÿè½½è¿‡é«˜ï¼Œå»ºè®®æš‚åœæ–°ç”¨æˆ·æ¥å…¥")
        
        if queue_analysis['total_decode_requests'] > 30:
            recommendations.append("DECODEé˜Ÿåˆ—ç§¯å‹ä¸¥é‡ï¼Œå¯èƒ½å­˜åœ¨decodeæ— é™å¾ªç¯é—®é¢˜")
        
        # åŸºäºé¡µé¢ä½¿ç”¨çš„æ¨è
        for gpu_id, page_info in queue_analysis['page_estimates'].items():
            if page_info['page_utilization_percent'] > 80:
                recommendations.append(f"GPU {gpu_id} é¡µé¢ä½¿ç”¨ç‡è¿‡é«˜ï¼Œå»ºè®®æ¸…ç†é•¿æ—¶é—´ä¸æ´»è·ƒçš„sessions")
        
        # åŸºäºsessionçŠ¶æ€çš„æ¨è
        if len(session_analysis['stuck_sessions']) > 0:
            recommendations.append("å‘ç°å¡ä½çš„sessionsï¼Œå»ºè®®æ£€æŸ¥å‰ç«¯WebSocketè¿æ¥æˆ–é‡ç½®è¿™äº›sessions")
        
        # åŸºäºç“¶é¢ˆçš„æ¨è
        if len(queue_analysis['bottlenecks']) > 3:
            recommendations.append("æ£€æµ‹åˆ°å¤šä¸ªç“¶é¢ˆï¼Œå»ºè®®é‡å¯æœåŠ¡")
        
        if not recommendations:
            recommendations.append("ç³»ç»Ÿè¿è¡Œæ­£å¸¸ï¼Œç»§ç»­ç›‘æ§")
        
        for rec in recommendations:
            print(f"   - {rec}")
    
    def monitor_continuously(self, interval: int = 10):
        """æŒç»­ç›‘æ§æ¨¡å¼"""
        print(f"ğŸ”„ å¼€å§‹æŒç»­ç›‘æ§ï¼Œæ¯{interval}ç§’æ›´æ–°ä¸€æ¬¡...")
        print("æŒ‰ Ctrl+C åœæ­¢ç›‘æ§\n")
        
        try:
            while True:
                stats = self.get_scheduler_stats()
                if stats:
                    self.print_diagnosis_report(stats)
                    print(f"â° ä¸‹æ¬¡æ›´æ–°: {interval}ç§’å...")
                    print("=" * 80 + "\n")
                else:
                    print("âŒ æ— æ³•è·å–ç»Ÿè®¡ä¿¡æ¯ï¼Œæ£€æŸ¥æœåŠ¡å™¨çŠ¶æ€")
                
                time.sleep(interval)
        except KeyboardInterrupt:
            print("\nğŸ‘‹ ç›‘æ§å·²åœæ­¢")
    
    def single_check(self):
        """å•æ¬¡æ£€æŸ¥æ¨¡å¼"""
        stats = self.get_scheduler_stats()
        if stats:
            self.print_diagnosis_report(stats)
        else:
            print("âŒ æ— æ³•è·å–ç»Ÿè®¡ä¿¡æ¯ï¼Œæ£€æŸ¥æœåŠ¡å™¨çŠ¶æ€")

def main():
    parser = argparse.ArgumentParser(description='InfiniSST Scheduler è¯Šæ–­å·¥å…·')
    parser.add_argument('--server', default='http://localhost:8000', help='æœåŠ¡å™¨åœ°å€')
    parser.add_argument('--monitor', action='store_true', help='æŒç»­ç›‘æ§æ¨¡å¼')
    parser.add_argument('--interval', type=int, default=10, help='ç›‘æ§é—´éš”(ç§’)')
    
    args = parser.parse_args()
    
    diagnostics = SchedulerDiagnostics(args.server)
    
    if args.monitor:
        diagnostics.monitor_continuously(args.interval)
    else:
        diagnostics.single_check()

if __name__ == "__main__":
    main() 