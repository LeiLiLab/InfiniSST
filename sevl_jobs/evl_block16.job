#!/usr/bin/env bash

#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=4
#SBATCH --mem=128GB
#SBATCH --gres=gpu:v100:1
##SBATCH --nodelist=babel-3-17
##SBATCH --constraint=xeon-4116 
##SBATCH --partition=gemini
#SBATCH --time=1-00:00:00
##SBATCH --dependency=afterok:job_id
##SBATCH --array=1-13:2
#SBATCH --account=siqiouyang
#SBATCH --mail-type=ALL
#SBATCH --mail-user=siqiouya@andrew.cmu.edu
#SBATCH --output=result_uni_b4.txt

# test must-c mt result
source /home/siqiouya/anaconda3/bin/activate sllama_lightning

cd eval
model_path=/data/user_data/siqiouya/runs/stage3-uni-waco-block16-fixed
data_path=/data/user_data/siqiouya/dataset/must-c-v1.0/en-es

beam=4
result=${model_path}/result_uni_b${beam}
blocksize=16

# python ../train/zero_to_fp32.py ${model_path} \
#     ${model_path}/pytorch_model.bin

# python ../train/extract_adapter.py \
#   --model_name_or_path ${model_path} \
#   --extracted_name 'mm_length_adapter' \
#   --output ${model_path}/length_adapter.bin 

# python ../train/extract_adapter.py \
#   --model_name_or_path ${model_pasth} \
#   --extracted_name 'mm_mlp_adapter' \
#   --output ${model_path}/mlp_adapter.bin 

# python ../train/extract_adapter.py \
#     --model_name_or_path ${model_path} \
#     --extracted_name 'speech_tower' \
#     --output ${model_path}/speech_tower.bin

export PYTHONPATH=/home/siqiouya/work/sllama
python ./test_dataset_large.py --model-name ${model_path} --data-path ${data_path} --data-split 'tst-COMMON' --result ${result} --beam ${beam} \
        --mlp-adapter-path ${model_path}/mlp_adapter.bin --length-adapter-path ${model_path}/length_adapter.bin --speech-tower-path ${model_path}/speech_tower.bin \
        --blocksize ${blocksize}

python ./compute_bleu.py ${result}/tst-COMMON