#!/usr/bin/env bash

#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=4
#SBATCH --mem=128GB
#SBATCH --gres=gpu:A6000:1
##SBATCH --nodelist=babel-3-17
##SBATCH --constraint=xeon-4116 
##SBATCH --partition=gemini
#SBATCH --time=1-00:00:00
##SBATCH --dependency=afterok:job_id
#SBATCH --array=1-6
#SBATCH --account=siqiouyang
#SBATCH --mail-type=ALL
#SBATCH --mail-user=siqiouya@andrew.cmu.edu
##SBATCH --output=/home/xixu/slurm.txts

source /home/siqiouya/anaconda3/bin/activate sllama_lightning

src_segment_size=$(expr 500 \* ${SLURM_ARRAY_TASK_ID})
la_n=2
beam=1
batch_size=8

checkpoint_dir=/data/user_data/siqiouya/runs/stage2-bi-mix-fix

export PYTHONPATH=/home/siqiouya/work/sllama:/home/siqiouya/work/SimulEval
simuleval \
  --agent eval/agents/tt_la_sllama.py \
  --agent-class "agents.LocalAgreement" \
  --source-segment-size ${src_segment_size} \
  --la-n ${la_n} --beam ${beam} \
  --repeat-penalty 1.0 \
  --model-dir ${checkpoint_dir} \
  --prompt "<speech_here>" \
  --source /data/user_data/siqiouya/dataset/must-c-v1.0/en-es/tst-COMMON_30s.source \
  --target /data/user_data/siqiouya/dataset/must-c-v1.0/en-es/tst-COMMON_30s.target \
  --output ${checkpoint_dir}/simul-results/local_agreement/la-${la_n}-beam${beam}-${src_segment_size}ms \
  --quality-metrics BLEU --sacrebleu-tokenizer 13a \
  --batch-size ${batch_size}