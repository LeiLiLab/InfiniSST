#!/usr/bin/env bash

#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=4
#SBATCH --mem=128GB
#SBATCH --gres=gpu:L40:1
##SBATCH --nodelist=babel-3-17
##SBATCH --constraint=xeon-4116 
##SBATCH --partition=gemini
#SBATCH --time=1-00:00:00
##SBATCH --dependency=afterok:job_id
#SBATCH --array=1-10:1
#SBATCH --account=siqiouyang
#SBATCH --mail-type=ALL
#SBATCH --mail-user=siqiouya@andrew.cmu.edu
##SBATCH --output=/home/xixu/slurm.txts

source /home/siqiouya/anaconda3/bin/activate sllama_lightning

src_segment_size=1000
k=${SLURM_ARRAY_TASK_ID}
blocksize=50
n_word_per_input=3
batch_size=8
warmup=0

mkdir -p /scratch/siqiouya/runs/
scp -r babel-4-7:/scratch/siqiouya/runs/stage3-uni-waco-block50-mix-from-stage0-tower/checkpoint-2000 /scratch/siqiouya/runs/

# checkpoint_dir=/data/user_data/siqiouya/runs/en-de/stage3-uni-waco-word-block50-fixed-mix-from-stage0
checkpoint_dir=/scratch/siqiouya/runs/checkpoint-2000

export PYTHONPATH=/home/siqiouya/work/sllama:/home/siqiouya/work/SimulEval
simuleval \
  --agent eval/agents/tt_waitk_sllama_word_incremental.py \
  --agent-class "agents.IncrementalWaitkSpeechLlama" \
  --source-segment-size ${src_segment_size} \
  --waitk-lagging ${k} --warmup ${warmup} --n-word-per-input ${n_word_per_input} \
  --repeat-penalty 1.0 \
  --model-dir ${checkpoint_dir} --blocksize ${blocksize} \
  --prompt "<speech_here>" \
  --source /data/user_data/siqiouya/dataset/must-c-v1.0/en-de/tst-COMMON_30s.source \
  --target /data/user_data/siqiouya/dataset/must-c-v1.0/en-de/tst-COMMON_30s.target \
  --output ${checkpoint_dir}/simul-results/30s-wait-k-word-inc-opt-1000ms-n${n_word_per_input}-warmup${warmup}-bsz${batch_size}/wait-${src_segment_size}ms-${k} \
  --quality-metrics BLEU --sacrebleu-tokenizer 13a \
  --batch-size ${batch_size}

export PYTHONPATH=/home/siqiouya/work/sllama:/home/siqiouya/work/SimulEval
simuleval \
  --agent eval/agents/tt_waitk_sllama_word_incremental.py \
  --agent-class "agents.IncrementalWaitkSpeechLlama" \
  --source-segment-size ${src_segment_size} \
  --waitk-lagging ${k} --warmup ${warmup} --n-word-per-input ${n_word_per_input} \
  --repeat-penalty 1.0 \
  --model-dir ${checkpoint_dir} --blocksize ${blocksize} \
  --prompt "<speech_here>" \
  --source /data/user_data/siqiouya/dataset/must-c-v1.0/en-de/tst-COMMON_30s.source \
  --target /data/user_data/siqiouya/dataset/must-c-v1.0/en-de/tst-COMMON_30s.target \
  --output /data/user_data/siqiouya/runs/en-de/stage3-uni-tower/simul-results/30s-wait-k-word-inc-opt-1000ms-n${n_word_per_input}-warmup${warmup}-bsz${batch_size}/wait-${src_segment_size}ms-${k} \
  --quality-metrics BLEU --sacrebleu-tokenizer 13a \
  --batch-size ${batch_size}

simuleval \
  --agent eval/agents/tt_waitk_sllama_word_incremental.py \
  --agent-class "agents.IncrementalWaitkSpeechLlama" \
  --source-segment-size ${src_segment_size} \
  --waitk-lagging ${k} --warmup ${warmup} --n-word-per-input ${n_word_per_input} \
  --repeat-penalty 1.3 \
  --model-dir ${checkpoint_dir} --blocksize ${blocksize} \
  --prompt "<speech_here>" \
  --source /data/user_data/siqiouya/dataset/must-c-v1.0/en-de/tst-COMMON_30s.source \
  --target /data/user_data/siqiouya/dataset/must-c-v1.0/en-de/tst-COMMON_30s.target \
  --output /data/user_data/siqiouya/runs/en-de/stage3-uni-tower/simul-results/30s-wait-k-word-inc-opt-1000ms-n${n_word_per_input}-warmup${warmup}-bsz${batch_size}/wait-${src_segment_size}ms-${k}-rp1.3 \
  --quality-metrics BLEU --sacrebleu-tokenizer 13a \
  --batch-size ${batch_size}


# cd /home/siqiouya/work/sllama

# source /home/siqiouya/anaconda3/bin/activate sllama_lightning

# src_segment_size=1000
# k=100
# blocksize=50
# n_word_per_input=3
# warmup=0
# batch_size=1

# checkpoint_dir=/scratch/siqiouya/runs/stage3-uni-waco-block50-mix-from-stage0-tower/checkpoint-2000
# export PYTHONPATH=/home/siqiouya/work/sllama:/home/siqiouya/work/SimulEval

# CUDA_VISIBLE_DEVICES=6 simuleval \
#   --agent eval/agents/tt_waitk_sllama_word_incremental.py \
#   --agent-class "agents.IncrementalWaitkSpeechLlama" \
#   --source-segment-size 1000 \
#   --waitk-lagging ${k} --warmup ${warmup} --n-word-per-input 3 \
#   --repeat-penalty 1.0 \
#   --model-dir ${checkpoint_dir} --blocksize ${blocksize} \
#   --prompt "<speech_here>" \
#   --source /data/user_data/siqiouya/dataset/must-c-v1.0/en-de/tst-COMMON_30s.source \
#   --target /data/user_data/siqiouya/dataset/must-c-v1.0/en-de/tst-COMMON_30s.target \
#   --output ${checkpoint_dir}/simul-results/30s-wait-k-word-inc-opt-1000ms-n${n_word_per_input}-warmup${warmup}-bsz${batch_size}/wait-${src_segment_size}ms-${k} \
#   --quality-metrics BLEU --sacrebleu-tokenizer 13a \
#   --batch-size ${batch_size}