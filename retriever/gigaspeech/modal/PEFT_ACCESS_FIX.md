# PEFT æ¨¡å—è®¿é—®é—®é¢˜ä¿®å¤

## ğŸ› é—®é¢˜æè¿°

åœ¨è¯Šæ–­ä¸­å‘ç°ï¼š
- âœ… LoRA å‚æ•°å·²åˆ›å»ºï¼ˆ384ä¸ªå‚æ•°ï¼‰
- âœ… æŠ•å½±å±‚æœ‰æ¢¯åº¦
- âŒ **LoRA å‚æ•°æ²¡æœ‰æ¢¯åº¦ï¼**

```
[STDOUT] LoRA params with gradients: 0/384
[STDOUT] LoRA params without gradients: 384/384
[STDOUT] âŒ No LoRA parameters received gradients!

[STDOUT]    æ£€æŸ¥æŠ•å½±å±‚çš„æ¢¯åº¦:
[STDOUT]       âœ… proj_speech.weight: HAS GRAD
[STDOUT]       âœ… proj_speech.bias: HAS GRAD
[STDOUT]       âŒ speech_qwen2_model.base_model.model.audio_tower.layers.0.self_attn.k_proj.lora_A.default.weight: NO GRAD
```

## ğŸ” æ ¹æœ¬åŸå› 

### PEFT æ¨¡å‹ç»“æ„

å½“ä½¿ç”¨ `get_peft_model()` åŒ…è£…æ¨¡å‹åï¼Œæ¨¡å‹ç»“æ„å˜ä¸ºï¼š

```
PeftModelForCausalLM
â”œâ”€â”€ base_model: PeftModel
â”‚   â””â”€â”€ model: Qwen2AudioForConditionalGeneration  â† åŸå§‹æ¨¡å‹åœ¨è¿™é‡Œ
â”‚       â”œâ”€â”€ audio_tower (with LoRA injected)
â”‚       â”œâ”€â”€ language_model
â”‚       â””â”€â”€ ...
â””â”€â”€ [å…¶ä»–PEFTç®¡ç†å±‚]
```

### é”™è¯¯çš„è®¿é—®æ–¹å¼

**ä¹‹å‰çš„ä»£ç ï¼š**
```python
def _extract_from_audio_tower(self, inputs):
    # âŒ ç›´æ¥è®¿é—®ä¼šç»•è¿‡ PEFT åŒ…è£…ï¼
    audio_tower_output = self.model.audio_tower(audio_features)
```

**é—®é¢˜ï¼š** `self.model` æ˜¯ `PeftModelForCausalLM`ï¼Œå®ƒæœ‰è‡ªå·±çš„ `audio_tower` å±æ€§ï¼ˆä»åŸå§‹æ¨¡å‹ç»§æ‰¿ï¼‰ï¼Œä½†è¿™ä¸ªè·¯å¾„**ç»•è¿‡äº† PEFT çš„å‰å‘é’©å­**ï¼Œæ‰€ä»¥ LoRA å±‚ä¸ä¼šè¢«è°ƒç”¨ï¼

### LoRA æ³¨å…¥æœºåˆ¶

PEFT é€šè¿‡æ›¿æ¢æ¨¡å—å®ç° LoRA æ³¨å…¥ï¼š

```python
# åº”ç”¨ LoRA å
model = get_peft_model(model, lora_config)

# å†…éƒ¨ç»“æ„ï¼š
model.base_model.model.audio_tower.layers[0].self_attn.q_proj
# å˜æˆäº†:
# LinearWithLoRA(
#   base_layer: Linear(...),
#   lora_A: Linear(...),  â† è¿™é‡Œ
#   lora_B: Linear(...)   â† è¿™é‡Œ
# )
```

ä½†å¦‚æœç›´æ¥é€šè¿‡ `model.audio_tower` è®¿é—®ï¼Œå¯èƒ½è®¿é—®åˆ°**æœªæ³¨å…¥ LoRA çš„å‰¯æœ¬**æˆ–**ç»•è¿‡é’©å­çš„è·¯å¾„**ï¼

## âœ… æ­£ç¡®çš„è§£å†³æ–¹æ¡ˆ

### æ–¹æ³• 1: é€šè¿‡ base_model è®¿é—®ï¼ˆæ¨èï¼‰

```python
def _extract_from_audio_tower(self, inputs):
    audio_features = inputs['input_features']
    feature_attention_mask = inputs.get('feature_attention_mask')
    
    # âœ… CRITICAL: PEFT åŒ…è£…åï¼Œéœ€è¦é€šè¿‡ base_model è®¿é—®
    if hasattr(self.model, 'base_model'):
        # PEFT åŒ…è£…åçš„æ¨¡å‹
        audio_tower = self.model.base_model.model.audio_tower
    else:
        # æœªåŒ…è£…çš„åŸå§‹æ¨¡å‹
        audio_tower = self.model.audio_tower
    
    # è¿™æ ·è°ƒç”¨æ—¶ä¼šç»è¿‡ LoRA å±‚
    audio_tower_output = audio_tower(audio_features)
    audio_hidden_states = audio_tower_output.last_hidden_state
    
    # ... åç»­å¤„ç† ...
```

### æ–¹æ³• 2: ä½¿ç”¨ get_base_model()ï¼ˆå¤‡é€‰ï¼‰

```python
# æˆ–è€…ä½¿ç”¨ PEFT çš„ API
if hasattr(self.model, 'get_base_model'):
    base_model = self.model.get_base_model()
    audio_tower = base_model.audio_tower
else:
    audio_tower = self.model.audio_tower
```

## ğŸ¯ ä¸ºä»€ä¹ˆè¿™æ ·èƒ½è§£å†³é—®é¢˜ï¼Ÿ

### æ­£ç¡®è·¯å¾„çš„å‰å‘ä¼ æ’­

```python
# âœ… æ­£ç¡®è·¯å¾„
self.model.base_model.model.audio_tower.layers[0].self_attn.q_proj(x)
    â†“
LinearWithLoRA.forward(x)
    â†“
base_output = self.base_layer(x)  # åŸå§‹ Linear
lora_output = self.lora_B(self.lora_A(x))  # LoRA è·¯å¾„ â† æœ‰æ¢¯åº¦ï¼
return base_output + lora_output
```

### é”™è¯¯è·¯å¾„çš„å‰å‘ä¼ æ’­

```python
# âŒ é”™è¯¯è·¯å¾„ï¼ˆç»•è¿‡äº† LoRAï¼‰
self.model.audio_tower.layers[0].self_attn.q_proj(x)
    â†“
å¯èƒ½è®¿é—®åˆ°åŸå§‹çš„ Linearï¼Œæ²¡æœ‰ LoRA åŒ…è£…
    â†“
åªæœ‰ base_layerï¼ŒLoRA å±‚è¢«è·³è¿‡ â† æ²¡æœ‰æ¢¯åº¦ï¼
```

## ğŸ”¬ éªŒè¯æ–¹å¼

### 1. æ£€æŸ¥æ¨¡å‹ç»“æ„

```python
# æ‰“å° PEFT åŒ…è£…åçš„æ¨¡å‹
print(type(self.model))  # PeftModelForCausalLM
print(type(self.model.base_model))  # PeftModel
print(type(self.model.base_model.model))  # Qwen2AudioForConditionalGeneration

# æ£€æŸ¥ audio_tower
audio_tower = self.model.base_model.model.audio_tower
first_qproj = audio_tower.layers[0].self_attn.q_proj
print(type(first_qproj))  # åº”è¯¥æ˜¯ Linear or lora.Linear
print(hasattr(first_qproj, 'lora_A'))  # åº”è¯¥æ˜¯ True
```

### 2. æ£€æŸ¥æ¢¯åº¦ä¼ æ’­

```python
# è¿è¡Œå‰å‘+åå‘ä¼ æ’­
loss = model.encode_audio(test_audio).sum()
loss.backward()

# æ£€æŸ¥ LoRA å‚æ•°çš„æ¢¯åº¦
for name, param in model.named_parameters():
    if 'lora' in name.lower() and param.grad is not None:
        print(f"âœ… {name}: grad_norm={param.grad.norm().item()}")
```

## ğŸ“Š é¢„æœŸç»“æœ

ä¿®å¤ååº”è¯¥çœ‹åˆ°ï¼š

```
[STDOUT] LoRA params with gradients: 384/384  â† å…¨éƒ¨æœ‰æ¢¯åº¦ï¼
[STDOUT] LoRA params without gradients: 0/384

[STDOUT] âœ… LoRA parameters received gradients!

[STDOUT]    Sample LoRA gradients:
[STDOUT]       âœ… speech_qwen2_model.base_model.model.audio_tower.layers.0.self_attn.k_proj.lora_A.default.weight: grad_norm=0.003421
[STDOUT]       âœ… speech_qwen2_model.base_model.model.audio_tower.layers.0.self_attn.k_proj.lora_B.default.weight: grad_norm=0.001234
[STDOUT]       âœ… speech_qwen2_model.base_model.model.audio_tower.layers.0.self_attn.v_proj.lora_A.default.weight: grad_norm=0.002891
```

## ğŸ“ ç»éªŒæ€»ç»“

### æ ¸å¿ƒæ•™è®­

1. **ä¸è¦å‡è®¾æ¨¡å—ç»“æ„ä¸å˜**
   - `get_peft_model()` ä¼šæ”¹å˜æ¨¡å‹çš„è®¿é—®è·¯å¾„
   - éœ€è¦é€šè¿‡ `base_model.model` è®¿é—®åŸå§‹æ¨¡å—

2. **Always check for PEFT wrapping**
   ```python
   if hasattr(model, 'base_model'):
       # è¿™æ˜¯ PEFT åŒ…è£…åçš„æ¨¡å‹
       actual_model = model.base_model.model
   ```

3. **æµ‹è¯•æ¢¯åº¦ä¼ æ’­**
   - ä¸ä»…æ£€æŸ¥å‚æ•°å­˜åœ¨æ€§
   - è¿˜è¦æ£€æŸ¥æ¢¯åº¦æ˜¯å¦çœŸçš„ä¼ æ’­åˆ° LoRA å±‚

4. **ç†è§£ PEFT å†…éƒ¨æœºåˆ¶**
   - LoRA é€šè¿‡æ›¿æ¢æ¨¡å—å®ç°
   - éœ€è¦é€šè¿‡æ­£ç¡®çš„è·¯å¾„è®¿é—®æ‰èƒ½è°ƒç”¨åŒ…è£…åçš„æ¨¡å—

### ç±»ä¼¼é—®é¢˜çš„æ’æŸ¥æ¸…å•

- [ ] æ£€æŸ¥ `hasattr(model, 'base_model')`
- [ ] ä½¿ç”¨ `model.base_model.model.xxx` è®¿é—®å­æ¨¡å—
- [ ] è¿è¡Œå°æµ‹è¯•éªŒè¯æ¢¯åº¦ä¼ æ’­
- [ ] æ£€æŸ¥ `type(module)` ç¡®è®¤æ˜¯å¦æœ‰ LoRA åŒ…è£…
- [ ] ä½¿ç”¨ `model.print_trainable_parameters()` æŸ¥çœ‹å¯è®­ç»ƒå‚æ•°

## ğŸ”— ç›¸å…³æ–‡æ¡£

- [PEFT Documentation](https://huggingface.co/docs/peft)
- [LoRA Paper](https://arxiv.org/abs/2106.09685)
- [Hugging Face PEFT Tutorial](https://huggingface.co/blog/peft)

---

**ä¿®å¤æäº¤:** 2025-01-XX  
**å½±å“èŒƒå›´:** `Qwen2_Audio_train.py` - `_extract_from_audio_tower()` æ–¹æ³•  
**æµ‹è¯•çŠ¶æ€:** âœ… å¾…éªŒè¯
