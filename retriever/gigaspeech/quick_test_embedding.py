#!/usr/bin/env python3
"""
å¿«é€Ÿæµ‹è¯•Qwen2-Audioçš„å•ä¸ªæ ·æœ¬embedding
"""

import torch
import numpy as np
import json
import os
from sklearn.metrics.pairwise import cosine_similarity

# å¯¼å…¥æˆ‘ä»¬çš„Qwen2-Audioæ¨¡å‹
from Qwen2_Audio_train import (
    Qwen2AudioSpeechEncoder, 
    Qwen2AudioTextEncoder, 
    ContrastiveQwen2AudioModel
)


def quick_test():
    """å¿«é€Ÿæµ‹è¯•å•ä¸ªæ ·æœ¬"""
    
    # æµ‹è¯•æ ·æœ¬ï¼ˆä½ å¯ä»¥ä¿®æ”¹è¿™äº›è·¯å¾„ï¼‰
    test_samples_path = "data/samples/xl/term_level_chunks_500000_1000000.json"
    
    print("=== Quick Qwen2-Audio Embedding Test ===")
    
    # æ£€æŸ¥è®¾å¤‡
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"Using device: {device}")
    
    # åŠ è½½ä¸€ä¸ªæµ‹è¯•æ ·æœ¬
    print(f"Loading samples from {test_samples_path}")
    with open(test_samples_path, 'r') as f:
        all_samples = json.load(f)
    
    # æ‰¾ç¬¬ä¸€ä¸ªæœ‰æ•ˆæ ·æœ¬
    test_sample = None
    for sample in all_samples[:100]:  # åªæ£€æŸ¥å‰100ä¸ª
        audio_path = sample.get('term_chunk_audio', '')
        chunk_text = sample.get('term_chunk_text', '')
        ground_truth_terms = sample.get('term_chunk_audio_ground_truth_terms', [])
        
        if (audio_path and chunk_text.strip() and 
            os.path.exists(audio_path) and 
            ground_truth_terms):
            test_sample = sample
            break
    
    if not test_sample:
        print("ERROR: No valid test sample found!")
        return
    
    # æ˜¾ç¤ºæµ‹è¯•æ ·æœ¬ä¿¡æ¯
    audio_path = test_sample['term_chunk_audio']
    chunk_text = test_sample['term_chunk_text']
    ground_truth_terms = test_sample['term_chunk_audio_ground_truth_terms']
    
    print(f"\n=== Test Sample ===")
    print(f"Audio: {os.path.basename(audio_path)}")
    print(f"Text: '{chunk_text}'")
    print(f"Ground truth terms: {ground_truth_terms}")
    
    # åˆå§‹åŒ–ç¼–ç å™¨
    print(f"\nInitializing Qwen2-Audio encoders...")
    try:
        speech_encoder = Qwen2AudioSpeechEncoder(device=device)
        text_encoder = Qwen2AudioTextEncoder(device=device)
        print("Encoders initialized successfully!")
        
    except Exception as e:
        print(f"ERROR: Failed to initialize encoders: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # æµ‹è¯•ç¼–ç 
    print(f"\n=== Testing Encodings ===")
    
    try:
        # ç¼–ç éŸ³é¢‘
        print("1. Encoding audio...")
        audio_embeddings = speech_encoder.predict([audio_path])
        audio_emb = audio_embeddings[0]
        print(f"   Audio embedding shape: {audio_emb.shape}")
        print(f"   Audio embedding stats: mean={np.mean(audio_emb):.4f}, std={np.std(audio_emb):.4f}, norm={np.linalg.norm(audio_emb):.4f}")
        
        # ç¼–ç æ–‡æœ¬
        print("2. Encoding text...")
        text_embeddings = text_encoder.predict([chunk_text])
        text_emb = text_embeddings[0]
        print(f"   Text embedding shape: {text_emb.shape}")
        print(f"   Text embedding stats: mean={np.mean(text_emb):.4f}, std={np.std(text_emb):.4f}, norm={np.linalg.norm(text_emb):.4f}")
        
        # ç¼–ç ground truth terms
        print("3. Encoding ground truth terms...")
        term_embeddings = text_encoder.predict(ground_truth_terms)
        print(f"   Terms embedding shape: {term_embeddings.shape}")
        
        # è®¡ç®—ç›¸ä¼¼åº¦
        print(f"\n=== Similarity Results ===")
        
        # éŸ³é¢‘ vs æ–‡æœ¬
        audio_text_sim = cosine_similarity([audio_emb], [text_emb])[0][0]
        print(f"Audio-Text similarity: {audio_text_sim:.4f}")
        
        # éŸ³é¢‘ vs terms
        audio_term_sims = cosine_similarity([audio_emb], term_embeddings)[0]
        print(f"Audio-Terms similarities:")
        for i, (term, sim) in enumerate(zip(ground_truth_terms, audio_term_sims)):
            print(f"  - '{term}': {sim:.4f}")
        max_audio_term_sim = np.max(audio_term_sims)
        best_term = ground_truth_terms[np.argmax(audio_term_sims)]
        print(f"  Best match: '{best_term}' ({max_audio_term_sim:.4f})")
        
        # æ–‡æœ¬ vs terms
        text_term_sims = cosine_similarity([text_emb], term_embeddings)[0]
        print(f"Text-Terms similarities:")
        for i, (term, sim) in enumerate(zip(ground_truth_terms, text_term_sims)):
            print(f"  - '{term}': {sim:.4f}")
        max_text_term_sim = np.max(text_term_sims)
        best_term = ground_truth_terms[np.argmax(text_term_sims)]
        print(f"  Best match: '{best_term}' ({max_text_term_sim:.4f})")
        
        # æ€»ç»“
        print(f"\n=== Summary ===")
        print(f"âœ… Audio and text successfully encoded")
        print(f"ğŸ“Š Audio-Text similarity: {audio_text_sim:.4f}")
        print(f"ğŸ“Š Best Audio-Term similarity: {max_audio_term_sim:.4f}")
        print(f"ğŸ“Š Best Text-Term similarity: {max_text_term_sim:.4f}")
        
        if audio_text_sim > 0.5:
            print("ğŸ‰ Good audio-text alignment!")
        elif audio_text_sim > 0.3:
            print("ğŸ¤” Moderate audio-text alignment")
        else:
            print("âš ï¸  Low audio-text alignment")
            
    except Exception as e:
        print(f"ERROR: Failed during encoding: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # æµ‹è¯•å¯¹æ¯”å­¦ä¹ æ¨¡å‹
    print(f"\n=== Testing Contrastive Model ===")
    try:
        model = ContrastiveQwen2AudioModel(
            speech_encoder, text_encoder,
            hidden_dim=4096,
            proj_dim=512,
            unfreeze_layers=0
        ).to(device)
        
        # ç¼–ç é€šè¿‡æŠ•å½±å±‚
        print("Testing projection layers...")
        audio_proj = model.encode_audio([audio_path])
        text_proj = model.encode_text([chunk_text])
        
        if isinstance(audio_proj, torch.Tensor):
            audio_proj = audio_proj.detach().cpu().numpy()
        if isinstance(text_proj, torch.Tensor):
            text_proj = text_proj.detach().cpu().numpy()
        
        proj_sim = cosine_similarity(audio_proj, text_proj)[0][0]
        print(f"Projected embeddings similarity: {proj_sim:.4f}")
        print(f"Projection layer effect: {proj_sim - audio_text_sim:+.4f}")
        
    except Exception as e:
        print(f"ERROR: Failed to test contrastive model: {e}")
        import traceback
        traceback.print_exc()
    
    print(f"\n=== Test Completed ===")


if __name__ == "__main__":
    quick_test()


