#!/usr/bin/env python3
"""
åŸºäº MFA å¯¹é½ä¿¡æ¯ï¼Œä¸ºæ¯ä¸ª ground truth term ç”Ÿæˆå•ç‹¬çš„ term-level chunk éŸ³é¢‘ç‰‡æ®µ
æ¯ä¸ª chunk åªè¦†ç›–ä¸€ä¸ªå®Œæ•´çš„ termï¼Œä¸è¢«æˆªæ–­ï¼Œå¹¶åœ¨å‰åå„æ‰©å±•1ç§’ä¸Šä¸‹æ–‡
"""

import os
import json
import argparse
import re
import soundfile as sf
import numpy as np
from typing import List, Dict, Tuple, Optional
from tqdm import tqdm


def parse_textgrid(textgrid_path: str) -> List[Dict]:
    """
    è§£æTextGridæ–‡ä»¶ï¼Œæå–wordså±‚çš„å¯¹é½ä¿¡æ¯
    è¿”å›æ ¼å¼: [{"word": "hello", "start": 1.0, "end": 1.5}, ...]
    """
    words = []
    
    if not os.path.exists(textgrid_path):
        print(f"[WARNING] TextGrid file not found: {textgrid_path}")
        return words
    
    try:
        with open(textgrid_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # æŸ¥æ‰¾wordså±‚çš„å¼€å§‹å’Œç»“æŸä½ç½®
        words_tier_start = content.find('"words"')
        if words_tier_start == -1:
            print(f"[WARNING] No 'words' tier found in {textgrid_path}")
            return words
        
        # æŸ¥æ‰¾ä¸‹ä¸€ä¸ªIntervalTierçš„å¼€å§‹ä½ç½®ï¼ˆphoneså±‚ï¼‰
        phones_tier_start = content.find('"phones"', words_tier_start)
        if phones_tier_start == -1:
            # å¦‚æœæ²¡æœ‰phoneså±‚ï¼Œä½¿ç”¨æ•´ä¸ªæ–‡ä»¶çš„å‰©ä½™éƒ¨åˆ†
            words_content = content[words_tier_start:]
        else:
            # åªå¤„ç†wordså±‚çš„å†…å®¹
            words_content = content[words_tier_start:phones_tier_start]
        
        lines = words_content.split('\n')
        
        # æ‰¾åˆ°intervalsæ•°é‡
        interval_count = 0
        start_parsing = False
        parse_start_idx = 0
        
        # åœ¨wordså±‚ä¸­æŸ¥æ‰¾æ ¼å¼: "words" -> 0 -> 19.98 -> 82 (intervalsæ•°é‡)
        for i, line in enumerate(lines):
            line = line.strip()
            if line == '"words"' and i + 3 < len(lines):
                # æ£€æŸ¥æ¥ä¸‹æ¥çš„å‡ è¡Œæ˜¯å¦ç¬¦åˆé¢„æœŸæ ¼å¼
                try:
                    # è·³è¿‡ "words" åé¢çš„èµ·å§‹æ—¶é—´(0)å’Œç»“æŸæ—¶é—´(19.98)
                    if (lines[i+1].strip().replace('.', '').isdigit() and 
                        lines[i+2].strip().replace('.', '').isdigit() and
                        lines[i+3].strip().isdigit()):
                        interval_count = int(lines[i+3].strip())
                        start_parsing = True
                        parse_start_idx = i + 4  # ä»intervalså¼€å§‹çš„ä½ç½®
                        break
                except (ValueError, IndexError):
                    continue
        
        if not start_parsing:
            print(f"[WARNING] Could not find interval count in words tier")
            return words
        
        # è§£ææ¯ä¸ªintervalï¼ˆè·³è¿‡å‰é¢çš„å…ƒä¿¡æ¯ï¼‰
        i = parse_start_idx
        parsed_intervals = 0
        
        while i < len(lines) and parsed_intervals < interval_count:
            line = lines[i].strip()
            
            # è·³è¿‡ç©ºè¡Œ
            if not line:
                i += 1
                continue
                
            try:
                # æ£€æŸ¥æ˜¯å¦æ˜¯æ—¶é—´æ•°å­—
                if line.replace('.', '').replace('-', '').isdigit():
                    # è¯»å–start time
                    start_time = float(line)
                    i += 1
                    
                    if i >= len(lines):
                        break
                        
                    # è¯»å–end time  
                    end_time = float(lines[i].strip())
                    i += 1
                    
                    if i >= len(lines):
                        break
                    
                    # è¯»å–word text
                    word_line = lines[i].strip()
                    word = word_line.strip('"')
                    i += 1
                    
                    # åªæ·»åŠ éç©ºå•è¯ï¼ˆæ’é™¤é™éŸ³æ ‡è®°ç­‰ï¼‰
                    if word and word != '' and word not in ['<SIL>', 'SIL', '<s>', '</s>', 'sp', 'sil']:
                        words.append({
                            "word": word.lower(),
                            "start": start_time,
                            "end": end_time
                        })
                    
                    parsed_intervals += 1
                else:
                    i += 1
                    
            except (ValueError, IndexError) as e:
                i += 1
                continue
                
        print(f"[INFO] Parsed {len(words)} words from {textgrid_path} (expected {interval_count})")
        
    except Exception as e:
        print(f"[ERROR] Failed to parse TextGrid {textgrid_path}: {e}")
    
    return words


def get_textgrid_path(segment_id: str, textgrid_base_dir: str = "/mnt/data/siqiouyang/datasets/gigaspeech/textgrids") -> str:
    """æ ¹æ®segment_idè·å–å¯¹åº”çš„TextGridæ–‡ä»¶è·¯å¾„"""
    textgrid_filename = f"{segment_id}.TextGrid"
    return os.path.join(textgrid_base_dir, textgrid_filename)


def find_term_time_spans(words: List[Dict], ground_truth_terms: List[str]) -> Tuple[List[Dict], List[str]]:
    """
    åœ¨wordsä¸­æ‰¾åˆ°ground_truth_termså¯¹åº”çš„æ—¶é—´è·¨åº¦
    è¿”å›æ ¼å¼: (term_spans, unmatched_terms)
    æ¯ä¸ªterm_spanåŒ…å«: {"term": "original_term", "start": float, "end": float}
    """
    term_spans = []
    unmatched_terms = []
    word_texts = [w["word"] for w in words]
    
    for term in ground_truth_terms:
        # æ¸…ç†termï¼Œå»æ‰æè¿°éƒ¨åˆ†ï¼Œåªä¿ç•™ä¸»è¦è¯æ±‡
        clean_term = term.lower()
        if ',' in clean_term:
            clean_term = clean_term.split(',')[0].strip()
        
        # å°†termåˆ†è§£ä¸ºå•è¯
        term_words = clean_term.split()
        
        if not term_words:
            unmatched_terms.append(term)
            continue
        
        found = False
        
        # ç²¾ç¡®åºåˆ—åŒ¹é…
        for i in range(len(word_texts) - len(term_words) + 1):
            match = True
            for j, term_word in enumerate(term_words):
                if term_word != word_texts[i + j]:
                    match = False
                    break
            
            if match:
                start_time = words[i]["start"]
                end_time = words[i + len(term_words) - 1]["end"]
                term_spans.append({
                    "term": term,  # ä¿ç•™åŸå§‹term
                    "start": start_time,
                    "end": end_time
                })
                found = True
                break
        
        if not found:
            unmatched_terms.append(term)
    
    print(f"[DEBUG] Found {len(term_spans)} term spans out of {len(ground_truth_terms)} terms")
    if unmatched_terms:
        print(f"[DEBUG] Unmatched terms ({len(unmatched_terms)}): {unmatched_terms[:5]}{'...' if len(unmatched_terms) > 5 else ''}")
    
    return term_spans, unmatched_terms


def extract_chunk_text(words: List[Dict], chunk_start: float, chunk_end: float) -> str:
    """
    æ ¹æ®æ—¶é—´èŒƒå›´ä»wordsä¸­æå–å¯¹åº”çš„æ–‡æœ¬
    """
    chunk_words = []
    
    for word in words:
        word_start = word["start"]
        word_end = word["end"]
        
        # æ£€æŸ¥å•è¯æ˜¯å¦ä¸chunkæ—¶é—´èŒƒå›´æœ‰é‡å 
        if not (chunk_end <= word_start or chunk_start >= word_end):
            chunk_words.append(word["word"])
    
    return " ".join(chunk_words)


def extract_chunk_text_from_sample(original_text: str, chunk_start: float, chunk_end: float, total_duration: float) -> str:
    """
    ä»åŸå§‹æ ·æœ¬æ–‡æœ¬ä¸­æŒ‰æ—¶é—´æ¯”ä¾‹æå–chunkå¯¹åº”çš„æ–‡æœ¬
    """
    if not original_text or total_duration <= 0:
        return ""
    
    # è®¡ç®—æ—¶é—´æ¯”ä¾‹
    start_ratio = chunk_start / total_duration
    end_ratio = chunk_end / total_duration
    
    # ç¡®ä¿æ¯”ä¾‹åœ¨æœ‰æ•ˆèŒƒå›´å†…
    start_ratio = max(0, min(1, start_ratio))
    end_ratio = max(start_ratio, min(1, end_ratio))
    
    # æŒ‰å­—ç¬¦ä½ç½®æˆªå–æ–‡æœ¬
    text_length = len(original_text)
    start_pos = int(start_ratio * text_length)
    end_pos = int(end_ratio * text_length)
    
    # ç¡®ä¿ä½ç½®æœ‰æ•ˆ
    start_pos = max(0, min(text_length, start_pos))
    end_pos = max(start_pos, min(text_length, end_pos))
    
    chunk_text = original_text[start_pos:end_pos].strip()
    
    # å¦‚æœæˆªå–çš„æ–‡æœ¬å¤ªçŸ­æˆ–ä¸ºç©ºï¼Œå°è¯•æ‰©å±•ä¸€äº›
    if len(chunk_text) < 10 and end_pos < text_length:
        # å‘åæ‰©å±•ä¸€äº›å­—ç¬¦
        extended_end = min(text_length, end_pos + 20)
        chunk_text = original_text[start_pos:extended_end].strip()
    
    return chunk_text


def extract_term_audio(original_audio_path: str, term_start: float, term_end: float, 
                      segment_id: str, term: str, output_dir: str = "/mnt/gemini/data1/jiaxuanluo/term_chunks",
                      context_seconds: float = 1.0) -> str:
    """
    ä»åŸå§‹éŸ³é¢‘ä¸­æå–å•ä¸ªtermçš„éŸ³é¢‘ç‰‡æ®µï¼Œå‰åå„æ‰©å±•context_secondsç§’
    """
    try:
        # åˆ›å»ºè¾“å‡ºç›®å½•ç»“æ„
        audio_id = segment_id.split('_')[0] if '_' in segment_id else segment_id
        layer1 = audio_id[:3] if len(audio_id) >= 3 else audio_id
        chunk_dir = os.path.join(output_dir, layer1, audio_id)
        os.makedirs(chunk_dir, exist_ok=True)
        
        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶åï¼ŒåŒ…å«termä¿¡æ¯ï¼ˆæ¸…ç†ç‰¹æ®Šå­—ç¬¦ï¼‰
        safe_term = re.sub(r'[^\w\s-]', '', term).strip().replace(' ', '_')[:20]  # é™åˆ¶é•¿åº¦
        chunk_filename = f"{segment_id}_term_{safe_term}_{term_start:.2f}_{term_end:.2f}_ctx{context_seconds:.1f}s.wav"
        chunk_path = os.path.join(chunk_dir, chunk_filename)
        
        # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œç›´æ¥è¿”å›
        if os.path.exists(chunk_path):
            return chunk_path
        
        # è¯»å–åŸå§‹éŸ³é¢‘
        if not os.path.exists(original_audio_path):
            print(f"[ERROR] Original audio not found: {original_audio_path}")
            return None
            
        audio_data, sr = sf.read(original_audio_path)
        
        # è®¡ç®—æ‰©å±•åçš„æ—¶é—´èŒƒå›´ï¼ˆå‰åå„åŠ context_secondsç§’ï¼‰
        extended_start = term_start - context_seconds
        extended_end = term_end + context_seconds
        
        # è®¡ç®—æ ·æœ¬ç´¢å¼•
        start_sample = int(extended_start * sr)
        end_sample = int(extended_end * sr)
        
        # ç¡®ä¿ç´¢å¼•åœ¨æœ‰æ•ˆèŒƒå›´å†…
        start_sample = max(0, start_sample)
        end_sample = min(len(audio_data), end_sample)
        
        if start_sample >= end_sample:
            print(f"[ERROR] Invalid term range for {segment_id}: {term}")
            return None
        
        # æå–éŸ³é¢‘ç‰‡æ®µ
        term_audio = audio_data[start_sample:end_sample]
        
        # æ£€æŸ¥éŸ³é¢‘é•¿åº¦æ˜¯å¦å¤ªçŸ­ï¼ˆæ‰©å±•åçš„æœ€å°é•¿åº¦æ£€æŸ¥ï¼‰
        if len(term_audio) < sr * 0.5:  # å°‘äº0.5ç§’ï¼ˆè€ƒè™‘åˆ°æ‰©å±•äº†ä¸Šä¸‹æ–‡ï¼‰
            print(f"[WARNING] Extended term audio too short for {segment_id}: {term} ({len(term_audio)/sr:.3f}s)")
            # å¯ä»¥é€‰æ‹©è·³è¿‡æˆ–è€…æ‰©å±•ï¼Œè¿™é‡Œé€‰æ‹©ç»§ç»­ä¿å­˜
        
        # ä¿å­˜terméŸ³é¢‘
        sf.write(chunk_path, term_audio, sr)
        
        return chunk_path
        
    except Exception as e:
        print(f"[ERROR] Failed to extract term audio for {segment_id} - {term}: {e}")
        return None


def process_sample(sample: Dict, textgrid_base_dir: str, context_seconds: float = 1.0, generate_no_term_ratio: float = 0.1) -> List[Dict]:
    """
    å¤„ç†å•ä¸ªæ ·æœ¬ï¼Œä¸ºæ¯ä¸ªground truth termç”Ÿæˆå•ç‹¬çš„chunkï¼Œå‰åå„æ‰©å±•context_secondsç§’
    åŒæ—¶æ ¹æ®generate_no_term_ratioæ¯”ä¾‹ç”Ÿæˆä¸€äº›no-term chunksç”¨äºè®­ç»ƒæ‹’ç­”èƒ½åŠ›
    è¿”å›term-level chunkæ ·æœ¬åˆ—è¡¨ï¼ˆåŒ…æ‹¬term chunkså’Œno-term chunksï¼‰
    """
    segment_id = sample["segment_id"]
    begin_time = sample.get("begin_time", 0)
    end_time = sample.get("end_time", 0)
    audio_path = sample.get("audio", "")
    ground_truth_terms = sample.get("ground_truth_term", [])
    original_text = sample.get("text", "")
    
    if not ground_truth_terms:
        print(f"[SKIP] No ground truth terms for {segment_id}")
        return []
    
    # è·å–TextGridè·¯å¾„å¹¶è§£æ
    textgrid_path = get_textgrid_path(segment_id, textgrid_base_dir)
    words = parse_textgrid(textgrid_path)
    
    if not words:
        print(f"[SKIP] No words found in TextGrid for {segment_id}")
        return []
    
    # æ‰¾åˆ°æœ¯è¯­åœ¨éŸ³é¢‘ä¸­çš„æ—¶é—´è·¨åº¦
    term_spans, unmatched_terms = find_term_time_spans(words, ground_truth_terms)
    
    # è°ƒè¯•ä¿¡æ¯ï¼šæ˜¾ç¤ºæ—¶é—´èŒƒå›´
    if words:
        textgrid_start = words[0]["start"]
        textgrid_end = words[-1]["end"]
        print(f"[DEBUG] {segment_id} - TextGrid time range: {textgrid_start:.2f} - {textgrid_end:.2f}")
        print(f"[DEBUG] {segment_id} - Sample time range: {begin_time:.2f} - {end_time:.2f}")
    
    # å¦‚æœæœ‰æœªåŒ¹é…çš„æœ¯è¯­ï¼Œæ‰“å°è¯¦ç»†ä¿¡æ¯è¿›è¡Œè°ƒè¯•
    if unmatched_terms:
        print(f"[DEBUG] {segment_id} - Unmatched terms: {unmatched_terms}")
        print(f"[DEBUG] {segment_id} - Available words: {[w['word'] for w in words[:10]]}{'...' if len(words) > 10 else ''}")
        print(f"[DEBUG] {segment_id} - Ground truth terms: {ground_truth_terms}")
        
        # æ¯”è¾ƒåŸå§‹æ–‡æœ¬å’ŒTextGridæ–‡æœ¬ï¼ˆç”¨äºè°ƒè¯•ï¼‰
        if original_text:
            textgrid_text = " ".join([w["word"] for w in words]).lower()
            print(f"[DEBUG] {segment_id} - Original text: {original_text[:100]}...")
            print(f"[DEBUG] {segment_id} - TextGrid text: {textgrid_text[:100]}...")
    
    # ä¸ºæ¯ä¸ªæ‰¾åˆ°çš„termç”Ÿæˆchunk
    term_chunks = []
    segment_duration = end_time - begin_time
    
    for term_span in term_spans:
        term = term_span["term"]
        term_start_abs = term_span["start"]  # MFAç»™å‡ºçš„æ˜¯ç›¸å¯¹äºæ•´ä¸ªéŸ³é¢‘çš„æ—¶é—´
        term_end_abs = term_span["end"]
        
        # MFAç»™å‡ºçš„æ—¶é—´åº”è¯¥å·²ç»æ˜¯ç›¸å¯¹äºå½“å‰éŸ³é¢‘ç‰‡æ®µçš„æ—¶é—´
        # å…ˆå°è¯•ç›´æ¥ä½¿ç”¨MFAæ—¶é—´ï¼Œå¦‚æœè¶…å‡ºèŒƒå›´å†è€ƒè™‘è°ƒæ•´
        term_start_rel = term_start_abs
        term_end_rel = term_end_abs
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦æ—¶é—´åç§»è°ƒæ•´
        if term_start_rel < 0 or term_end_rel > segment_duration:
            # å¦‚æœè¶…å‡ºèŒƒå›´ï¼Œå¯èƒ½MFAæ—¶é—´æ˜¯ç»å¯¹æ—¶é—´ï¼Œéœ€è¦å‡å»begin_time
            term_start_rel_adjusted = term_start_abs - begin_time
            term_end_rel_adjusted = term_end_abs - begin_time
            
            # æ£€æŸ¥è°ƒæ•´åæ˜¯å¦åˆç†
            if (0 <= term_start_rel_adjusted <= segment_duration and 
                0 <= term_end_rel_adjusted <= segment_duration and
                term_end_rel_adjusted > term_start_rel_adjusted):
                print(f"[INFO] Using time offset adjustment for {segment_id} - {term}")
                term_start_rel = term_start_rel_adjusted
                term_end_rel = term_end_rel_adjusted
            else:
                print(f"[WARNING] Term '{term}' time range ({term_start_rel:.2f}-{term_end_rel:.2f}) exceeds segment duration ({segment_duration:.2f}) for {segment_id}")
                print(f"[WARNING] Adjusted range ({term_start_rel_adjusted:.2f}-{term_end_rel_adjusted:.2f}) also invalid")
                # è·³è¿‡è¿™ä¸ªæœ¯è¯­
                continue
        
        # æå–terméŸ³é¢‘ï¼ˆå‰åå„æ‰©å±•æŒ‡å®šç§’æ•°ï¼‰
        term_audio_path = extract_term_audio(audio_path, term_start_rel, term_end_rel, segment_id, term, 
                                           context_seconds=context_seconds)
        
        if not term_audio_path:
            print(f"[SKIP] Failed to extract term audio for {segment_id} - {term}")
            continue
        
        # è®¡ç®—æ‰©å±•åçš„æ—¶é—´èŒƒå›´
        extended_start_rel = max(0, term_start_rel - context_seconds)
        extended_end_rel = min(segment_duration, term_end_rel + context_seconds)
        
        # æå–æ‰©å±•åchunkçš„æ–‡æœ¬å†…å®¹
        # ä¼˜å…ˆä½¿ç”¨MFAå¯¹é½çš„wordsæ¥æå–ç²¾ç¡®çš„æ–‡æœ¬
        chunk_text = ""
        if words:
            # ä½¿ç”¨MFA wordsæå–æ‰©å±•åæ—¶é—´èŒƒå›´å†…çš„æ–‡æœ¬
            chunk_text = extract_chunk_text(words, extended_start_rel, extended_end_rel)
        
        # å¦‚æœMFAæ–‡æœ¬æå–å¤±è´¥æˆ–ä¸ºç©ºï¼Œå›é€€åˆ°åŸå§‹æ–‡æœ¬çš„æ—¶é—´æ¯”ä¾‹æå–
        if not chunk_text.strip() and original_text:
            chunk_text = extract_chunk_text_from_sample(
                original_text, extended_start_rel, extended_end_rel, segment_duration
            )
        
        # å¦‚æœä»ç„¶æ²¡æœ‰æ–‡æœ¬ï¼Œä½¿ç”¨åŸå§‹termä½œä¸ºå›é€€
        if not chunk_text.strip():
            chunk_text = term
            print(f"[WARNING] Using term as fallback text for {segment_id} - {term}")
        
        # æ„å»ºterm-level chunkæ ·æœ¬ï¼ˆåŒ…å«ä¸Šä¸‹æ–‡æ‰©å±•ä¿¡æ¯ï¼‰
        term_chunk = {
            "segment_id": segment_id,
            "term_chunk_audio": term_audio_path,
            "term_chunk_text": chunk_text,  # ä½¿ç”¨æ‰©å±•åchunkå¯¹åº”çš„æ–‡æœ¬
            "term_chunk_audio_ground_truth_terms": [term],  # åªåŒ…å«è¿™ä¸€ä¸ªterm
            "term_start_time": term_start_rel,      # ç›¸å¯¹äºéŸ³é¢‘ç‰‡æ®µçš„æ—¶é—´ï¼ˆåŸå§‹termè¾¹ç•Œï¼‰
            "term_end_time": term_end_rel,          # ç›¸å¯¹äºéŸ³é¢‘ç‰‡æ®µçš„æ—¶é—´ï¼ˆåŸå§‹termè¾¹ç•Œï¼‰
            "term_start_time_abs": term_start_abs,  # ç›¸å¯¹äºåŸå§‹é•¿éŸ³é¢‘çš„ç»å¯¹æ—¶é—´ï¼ˆåŸå§‹termè¾¹ç•Œï¼‰
            "term_end_time_abs": term_end_abs,      # ç›¸å¯¹äºåŸå§‹é•¿éŸ³é¢‘çš„ç»å¯¹æ—¶é—´ï¼ˆåŸå§‹termè¾¹ç•Œï¼‰
            "term_duration": term_end_rel - term_start_rel,  # åŸå§‹termæ—¶é•¿
            # æ‰©å±•åçš„ä¿¡æ¯
            "extended_start_time": extended_start_rel,      # æ‰©å±•åçš„å¼€å§‹æ—¶é—´
            "extended_end_time": extended_end_rel,          # æ‰©å±•åçš„ç»“æŸæ—¶é—´
            "extended_duration": extended_end_rel - extended_start_rel,  # æ‰©å±•åçš„æ€»æ—¶é•¿
            "context_seconds": context_seconds,             # å‰åæ‰©å±•çš„ç§’æ•°
            "actual_extended_start": term_start_rel - context_seconds,  # ç†è®ºæ‰©å±•å¼€å§‹æ—¶é—´ï¼ˆå¯èƒ½ä¸ºè´Ÿï¼‰
            "actual_extended_end": term_end_rel + context_seconds       # ç†è®ºæ‰©å±•ç»“æŸæ—¶é—´ï¼ˆå¯èƒ½è¶…å‡ºè¾¹ç•Œï¼‰
        }
        
        term_chunks.append(term_chunk)
    
    print(f"[INFO] Generated {len(term_chunks)} term chunks for {segment_id} (out of {len(ground_truth_terms)} terms)")
    
    # æ‰“å°å‰å‡ ä¸ªchunkçš„æ–‡æœ¬æå–ä¿¡æ¯ç”¨äºè°ƒè¯•
    for i, chunk in enumerate(term_chunks[:3]):  # åªæ‰“å°å‰3ä¸ª
        chunk_text_preview = chunk["term_chunk_text"][:50] + "..." if len(chunk["term_chunk_text"]) > 50 else chunk["term_chunk_text"]
        print(f"[DEBUG] Chunk {i+1} - Term: '{chunk['term_chunk_audio_ground_truth_terms'][0]}', Text: '{chunk_text_preview}'")
    
    # === ç”Ÿæˆno-term chunks ===
    no_term_chunks = []
    if generate_no_term_ratio > 0 and len(term_chunks) > 0:
        # è®¡ç®—éœ€è¦ç”Ÿæˆçš„no-term chunkæ•°é‡
        target_no_term_count = max(1, int(len(term_chunks) * generate_no_term_ratio))
        
        # æ‰¾åˆ°æ‰€æœ‰æœ¯è¯­è¦†ç›–çš„æ—¶é—´åŒºé—´ï¼ˆæ‰©å±•åçš„ï¼‰
        covered_intervals = []
        for chunk in term_chunks:
            start_time = chunk["extended_start_time"]
            end_time = chunk["extended_end_time"]
            covered_intervals.append((start_time, end_time))
        
        # åˆå¹¶é‡å çš„åŒºé—´
        covered_intervals.sort()
        merged_intervals = []
        for start, end in covered_intervals:
            if merged_intervals and start <= merged_intervals[-1][1]:
                # åˆå¹¶é‡å åŒºé—´
                merged_intervals[-1] = (merged_intervals[-1][0], max(merged_intervals[-1][1], end))
            else:
                merged_intervals.append((start, end))
        
        # æ‰¾åˆ°ç©ºç™½åŒºé—´ï¼ˆæœªè¢«æœ¯è¯­è¦†ç›–çš„åŒºåŸŸï¼‰
        gap_intervals = []
        prev_end = 0
        for start, end in merged_intervals:
            if start > prev_end:
                gap_intervals.append((prev_end, start))
            prev_end = end
        
        # æ·»åŠ æœ€åä¸€ä¸ªç©ºç™½åŒºé—´
        if prev_end < segment_duration:
            gap_intervals.append((prev_end, segment_duration))
        
        # è¿‡æ»¤æ‰å¤ªçŸ­çš„ç©ºç™½åŒºé—´ï¼ˆè‡³å°‘éœ€è¦2*context_seconds + 0.5ç§’ï¼‰
        min_gap_duration = 2 * context_seconds + 0.5
        valid_gaps = [(start, end) for start, end in gap_intervals if (end - start) >= min_gap_duration]
        
        print(f"[DEBUG] {segment_id} - Found {len(valid_gaps)} valid gaps for no-term chunks (min duration: {min_gap_duration:.1f}s)")
        
        # åœ¨æœ‰æ•ˆç©ºç™½åŒºé—´ä¸­éšæœºé‡‡æ ·ç”Ÿæˆno-term chunks
        import random
        random.seed(42)  # å›ºå®šéšæœºç§å­ç¡®ä¿å¯å¤ç°
        
        generated_no_term = 0
        for gap_start, gap_end in valid_gaps:
            if generated_no_term >= target_no_term_count:
                break
            
            # åœ¨è¿™ä¸ªç©ºç™½åŒºé—´ä¸­ç”Ÿæˆä¸€ä¸ªno-term chunk
            gap_duration = gap_end - gap_start
            chunk_duration = 2 * context_seconds + random.uniform(0.5, min(2.0, gap_duration - 2 * context_seconds))
            
            # éšæœºé€‰æ‹©chunkåœ¨gapä¸­çš„ä½ç½®
            max_start = gap_end - chunk_duration
            chunk_start = random.uniform(gap_start, max_start)
            chunk_end = chunk_start + chunk_duration
            
            # æå–no-term chunkçš„éŸ³é¢‘
            no_term_audio_path = extract_term_audio(
                audio_path, chunk_start, chunk_end, segment_id, 
                f"no_term_{generated_no_term}", context_seconds=0  # no-term chunkä¸éœ€è¦é¢å¤–æ‰©å±•
            )
            
            if no_term_audio_path:
                # æå–chunkçš„æ–‡æœ¬å†…å®¹
                chunk_text = ""
                if words:
                    chunk_text = extract_chunk_text(words, chunk_start, chunk_end)
                
                if not chunk_text.strip() and original_text:
                    chunk_text = extract_chunk_text_from_sample(
                        original_text, chunk_start, chunk_end, segment_duration
                    )
                
                # å¦‚æœä»ç„¶æ²¡æœ‰æ–‡æœ¬ï¼Œä½¿ç”¨ç©ºå­—ç¬¦ä¸²
                if not chunk_text.strip():
                    chunk_text = ""
                
                # æ„å»ºno-term chunkæ ·æœ¬
                no_term_chunk = {
                    "segment_id": segment_id + f"_no_term_{generated_no_term}",
                    "term_chunk_audio": no_term_audio_path,
                    "term_chunk_text": chunk_text,
                    "term_chunk_audio_ground_truth_terms": [],  # ç©ºæœ¯è¯­åˆ—è¡¨
                    "term_start_time": chunk_start,
                    "term_end_time": chunk_end,
                    "term_start_time_abs": chunk_start,
                    "term_end_time_abs": chunk_end,
                    "term_duration": chunk_end - chunk_start,
                    "extended_start_time": chunk_start,
                    "extended_end_time": chunk_end,
                    "extended_duration": chunk_end - chunk_start,
                    "context_seconds": 0,  # no-term chunkä¸éœ€è¦contextæ‰©å±•
                    "actual_extended_start": chunk_start,
                    "actual_extended_end": chunk_end,
                    "is_no_term_chunk": True  # æ ‡è®°ä¸ºno-term chunk
                }
                
                no_term_chunks.append(no_term_chunk)
                generated_no_term += 1
                
                print(f"[DEBUG] Generated no-term chunk {generated_no_term} at {chunk_start:.2f}-{chunk_end:.2f}s, text: '{chunk_text[:30]}...'")
    
    all_chunks = term_chunks + no_term_chunks
    if no_term_chunks:
        print(f"[INFO] Generated {len(no_term_chunks)} no-term chunks for {segment_id}")
    
    return all_chunks


def main():
    parser = argparse.ArgumentParser(description="Extract term-level audio chunks based on MFA alignment with context extension")
    parser.add_argument("--input_json", type=str, required=True, help="Input samples JSON file")
    parser.add_argument("--output_json", type=str, required=True, help="Output term-level chunks JSON file")
    parser.add_argument("--textgrid_dir", type=str, 
                       default="/mnt/data/siqiouyang/datasets/gigaspeech/textgrids",
                       help="TextGrid files directory")
    parser.add_argument("--output_audio_dir", type=str,
                       default="/mnt/gemini/data1/jiaxuanluo/term_chunks",
                       help="Output directory for term audio chunks")
    parser.add_argument("--context_seconds", type=float, default=1.0,
                       help="Number of seconds to extend before and after each term (default: 1.0)")
    parser.add_argument("--generate_no_term_ratio", type=float, default=0.1,
                       help="Ratio of no-term chunks to generate relative to term chunks (default: 0.1)")
    
    args = parser.parse_args()
    
    print(f"[INFO] Loading samples from {args.input_json}")
    
    # è¯»å–è¾“å…¥æ ·æœ¬
    with open(args.input_json, 'r', encoding='utf-8') as f:
        samples = json.load(f)
    
    print(f"[INFO] Processing {len(samples)} samples for term-level chunks with {args.context_seconds}s context extension")
    
    # ç¡®ä¿è¾“å‡ºéŸ³é¢‘ç›®å½•å­˜åœ¨
    os.makedirs(args.output_audio_dir, exist_ok=True)
    
    # å¤„ç†æ¯ä¸ªæ ·æœ¬
    all_term_chunks = []
    total_terms_processed = 0
    processed_samples = 0
    skipped_samples = 0
    
    for sample in tqdm(samples, desc="Processing samples"):
        try:
            term_chunks = process_sample(sample, args.textgrid_dir, args.context_seconds, args.generate_no_term_ratio)
            all_term_chunks.extend(term_chunks)
            total_terms_processed += len(term_chunks)
            processed_samples += 1
            
            # æ¯1000ä¸ªæ ·æœ¬æ‰“å°è¿›åº¦
            if processed_samples % 1000 == 0:
                print(f"[PROGRESS] Processed {processed_samples}/{len(samples)} samples, generated {total_terms_processed} term chunks")
                
        except Exception as e:
            print(f"[ERROR] Failed to process {sample.get('segment_id', 'unknown')}: {e}")
            skipped_samples += 1
            continue
    
    # ç»Ÿè®¡term chunkså’Œno-term chunks
    term_chunks_count = sum(1 for chunk in all_term_chunks if not chunk.get('is_no_term_chunk', False))
    no_term_chunks_count = sum(1 for chunk in all_term_chunks if chunk.get('is_no_term_chunk', False))
    
    print(f"[INFO] Processing completed!")
    print(f"[INFO] - Total input samples: {len(samples)}")
    print(f"[INFO] - Successfully processed samples: {processed_samples}")
    print(f"[INFO] - Skipped samples: {skipped_samples}")
    print(f"[INFO] - Generated term chunks: {term_chunks_count}")
    print(f"[INFO] - Generated no-term chunks: {no_term_chunks_count}")
    print(f"[INFO] - Total chunks: {total_terms_processed}")
    print(f"[INFO] - No-term ratio: {no_term_chunks_count/total_terms_processed:.1%}" if total_terms_processed > 0 else "[INFO] - No chunks generated")
    print(f"[INFO] - Context extension: Â±{args.context_seconds}s per term")
    print(f"[INFO] - Average chunks per processed sample: {total_terms_processed/processed_samples:.2f}" if processed_samples > 0 else "[INFO] - No samples processed successfully")
    
    # ä¿å­˜ç»“æœ
    os.makedirs(os.path.dirname(args.output_json), exist_ok=True)
    with open(args.output_json, 'w', encoding='utf-8') as f:
        json.dump(all_term_chunks, f, indent=2, ensure_ascii=False)
    
    print(f"âœ… Results saved to {args.output_json}")
    print(f"âœ… Term audio chunks (with Â±{args.context_seconds}s context) saved to {args.output_audio_dir}")
    print(f"ğŸ“Š Each chunk contains:")
    print(f"   - Original term boundaries and timing information")
    print(f"   - Extended audio with Â±{args.context_seconds}s context")
    print(f"   - Metadata about actual vs. theoretical extension ranges")


if __name__ == "__main__":
    main() 