# ç›´æ¥è¯„ä¼°åŠŸèƒ½è¯´æ˜

å·²ä¸º `SONAR_term_level_train_glossary.py` æ·»åŠ äº†ç›´æ¥è¯„ä¼°åŠŸèƒ½ï¼Œå¯ä»¥è·³è¿‡è®­ç»ƒç›´æ¥å¯¹checkpointè¿›è¡Œè¯„ä¼°ã€‚

## åŠŸèƒ½ç‰¹ç‚¹

- ğŸš€ è·³è¿‡è®­ç»ƒè¿‡ç¨‹ï¼Œç›´æ¥åŠ è½½checkpointè¿›è¡Œè¯„ä¼°
- ğŸ“Š æ”¯æŒå¤šç§top-kå¬å›ç‡è¯„ä¼° (5, 10, 20)
- ğŸ” è¯¦ç»†çš„æœªå‘½ä¸­æœ¯è¯­åˆ†æ
- ğŸ“ˆ æ”¯æŒå®Œæ•´è¯æ±‡è¡¨è¯„ä¼°
- ğŸ¯ æ”¯æŒseen/unseenæœ¯è¯­åˆ†æ
- ğŸ’» æ”¯æŒGPUé€‰æ‹©

## ä½¿ç”¨æ–¹æ³•

### 1. åŸºæœ¬ç”¨æ³•

```bash
python3 SONAR_term_level_train_glossary.py \
    --direct_evaluate \
    --checkpoint_path=data/clap_term_level_epoch1.pt
```

### 2. å®Œæ•´å‚æ•°ç¤ºä¾‹

```bash
python3 SONAR_term_level_train_glossary.py \
    --direct_evaluate \
    --checkpoint_path=data/clap_term_level_epoch1.pt \
    --train_samples_path=data/xl_term_level_chunks_merged.json \
    --test_samples_path=data/samples/xl/term_level_chunks_500000_1000000.json \
    --glossary_path=data/terms/glossary_filtered.json \
    --enable_full_eval \
    --filter_no_term \
    --gpu_ids="0"
```

### 3. ä½¿ç”¨ä¾¿æ·è„šæœ¬

```bash
# ç®€å•è¯„ä¼°
python3 evaluate_checkpoint.py data/clap_term_level_epoch1.pt

# å¸¦å®Œæ•´è¯æ±‡è¡¨è¯„ä¼°
python3 evaluate_checkpoint.py data/clap_term_level_epoch1.pt --enable_full_eval

# æŒ‡å®šGPU
python3 evaluate_checkpoint.py data/clap_term_level_epoch1.pt --gpu_ids="0"
```

## ä¸»è¦å‚æ•°

| å‚æ•° | å¿…éœ€ | è¯´æ˜ |
|------|------|------|
| `--direct_evaluate` | æ˜¯ | å¯ç”¨ç›´æ¥è¯„ä¼°æ¨¡å¼ |
| `--checkpoint_path` | æ˜¯ | checkpointæ–‡ä»¶è·¯å¾„ |
| `--train_samples_path` | å¦ | è®­ç»ƒæ ·æœ¬è·¯å¾„ï¼ˆç”¨äºæ„å»ºæœ¯è¯­é›†ï¼‰ |
| `--test_samples_path` | å¦ | æµ‹è¯•æ ·æœ¬è·¯å¾„ |
| `--enable_full_eval` | å¦ | å¯ç”¨å®Œæ•´è¯æ±‡è¡¨è¯„ä¼° |
| `--gpu_ids` | å¦ | æŒ‡å®šGPUï¼ˆå¦‚"0,1"æˆ–"2"ï¼‰ |

## è¾“å‡ºå†…å®¹

### åŸºæœ¬è¯„ä¼°è¾“å‡º
- Sample-level å¬å›ç‡ (Recall@5, @10, @20)
- Term-level å¾®å¹³å‡å¬å›ç‡
- Seen/Unseen æœ¯è¯­åˆ†æ
- è¯¦ç»†çš„æœªå‘½ä¸­æœ¯è¯­åˆ—è¡¨

### å®Œæ•´è¯æ±‡è¡¨è¯„ä¼°è¾“å‡ºï¼ˆå¦‚æœå¯ç”¨ï¼‰
- ä½¿ç”¨å®Œæ•´glossaryçš„å¬å›ç‡è¯„ä¼°
- æ›´å…¨é¢çš„æ€§èƒ½åˆ†æ

## ç¤ºä¾‹è¾“å‡º

```
=== Evaluation Results for Top-10 ===
[EVAL] Term Samples - Sample-level Average Recall@10: 45.67% (1000 samples)
[EVAL] Term Samples - Term-level Micro-Average Recall@10: 43.21% (1234/2856 terms)
[EVAL] Sample-level - Seen Recall@10: 52.34% (800/1000 samples), Unseen Recall@10: 31.25% (200/1000 samples)
[EVAL] Term-level - Seen Recall@10: 48.90% (1000/2045 terms), Unseen Recall@10: 28.87% (234/811 terms)
```

## æ–‡ä»¶è¯´æ˜

- `SONAR_term_level_train_glossary.py`: ä¸»è„šæœ¬ï¼Œå·²æ·»åŠ ç›´æ¥è¯„ä¼°åŠŸèƒ½
- `evaluate_checkpoint.py`: ä¾¿æ·è¯„ä¼°è„šæœ¬
- `direct_evaluate_example.sh`: ä½¿ç”¨ç¤ºä¾‹è„šæœ¬

## æ³¨æ„äº‹é¡¹

1. checkpointæ–‡ä»¶å¿…é¡»å­˜åœ¨ä¸”å¯è¯»
2. éœ€è¦æä¾›è®­ç»ƒæ•°æ®è·¯å¾„ä»¥æ„å»ºæœ¯è¯­è¯æ±‡è¡¨
3. ç›´æ¥è¯„ä¼°æ¨¡å¼ä¼šè·³è¿‡æ‰€æœ‰è®­ç»ƒç›¸å…³çš„è®¾ç½®
4. å»ºè®®ä½¿ç”¨GPUè¿›è¡Œè¯„ä¼°ä»¥æé«˜é€Ÿåº¦


