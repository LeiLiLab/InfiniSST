# 实时语音翻译 Demo

这是一个基于FastAPI和WebSocket的实时语音翻译演示应用。

## 功能特点

- 支持InfiniSST翻译模型（StreamAtt暂时禁用）
- 支持多种语言方向（英译中、英译德、英译西）
- 可动态调整延迟倍数，平衡翻译速度和准确性
- 实时音频处理和翻译
- 基于WebSocket的低延迟通信
- 支持重置翻译状态，无需重新加载模型
- 优化的音频处理，减少开头空白段
- 自动检测并移除音频开头的静音部分
- 加载新模型时自动清理资源，防止内存泄漏
- 重置翻译后强制重新上传音频文件，确保干净的状态

## 安装依赖

```bash
pip install fastapi uvicorn python-multipart websockets soundfile numpy
```

## 运行服务器

```bash
cd serve
python run.py
```

服务器将在 http://localhost:8000 上启动。

## 使用方法

1. 打开浏览器访问 http://localhost:8000
2. 选择翻译模型（如InfiniSST）和语言方向（如English -> Chinese）
3. 点击"Load Model"加载模型
   - 如果已有加载的模型，系统会自动清理现有资源
   - 包括关闭WebSocket连接、释放音频资源和删除后端会话
   - 已上传的音频文件会被保留，可以继续使用相同的音频
4. 选择延迟倍数（影响翻译的响应速度和准确性）
   - 1x: 最快响应，处理960*16个样本，但准确性可能较低
   - 2x: 默认设置，处理960*16*2个样本，平衡速度和准确性
   - 3x: 更准确，处理960*16*3个样本，但响应较慢
   - 4x: 最准确，处理960*16*4个样本，但响应最慢
5. 点击"Update Latency"应用新的延迟设置（无需重新加载模型）
6. 上传音频文件
7. 点击"Start Translation"开始翻译
8. 音频将自动播放，同时显示实时翻译结果
9. 翻译过程中可随时调整延迟倍数并点击"Update Latency"应用
10. 如需停止当前翻译并重置状态，点击"Reset Translation"（无需重新加载模型）
    - 重置后需要重新上传音频文件
    - 会话保持活跃，无需重新加载模型

## 技术说明

- 前端使用原生JavaScript和Web Audio API进行音频处理
- 后端使用FastAPI和WebSocket进行实时通信
- 音频数据以16kHz采样率处理
- 基础数据块大小为960*16个采样点，实际处理块大小为基础大小乘以延迟倍数
- 延迟倍数越大，一次处理的数据越多，翻译质量越高，但响应速度越慢
- 支持动态调整延迟倍数，无需重新加载模型
- 重置功能保留会话状态，允许在重置后继续使用相同的模型
- 音频处理优化：
  - 第一个数据块使用较小的缓冲区大小，加快初始响应速度
  - 使用预缓冲技术，确保音频处理管道准备就绪后再开始播放
  - 可选跳过音频开头的一小段，减少感知到的空白
  - 前后端同时实现静音检测，自动移除音频开头的静音部分（阈值为0.005）
- 资源管理：
  - 加载新模型时自动清理现有资源，包括WebSocket连接、音频上下文和后端会话
  - 重置翻译时正确清理音频资源，确保可以重新开始翻译
  - 完善的错误处理，确保资源在异常情况下也能被正确释放
  - 重置翻译后强制重新上传音频文件，避免使用旧的音频数据
  - 加载新模型时保留已上传的音频文件，提高用户体验 