#!/usr/bin/env python3
"""
InfiniSST Evaluation Framework
æ¨¡æ‹Ÿå¹¶å‘ç”¨æˆ·ï¼Œæ‰§è¡ŒstreamLAALæµ‹è¯•ï¼Œæ”¯æŒåŠ¨æ€è°ƒåº¦
"""

import asyncio
import json
import logging
import os
import random
import statistics
import time
import uuid
from dataclasses import dataclass, field
from pathlib import Path
from typing import Dict, List, Optional, Any, Union
import argparse
import numpy as np
import urllib.parse

import aiohttp
import aiofiles
import soundfile as sf

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

@dataclass
class TestConfig:
    """æµ‹è¯•é…ç½®"""
    num_users: int = 16
    language_split: float = 0.5  # 50% Chinese, 50% Italian
    server_url: str = "http://localhost:8000"
    test_videos: List[str] = field(default_factory=lambda: [
        "2022.acl-long.110.wav",
        "2022.acl-long.117.wav", 
        "2022.acl-long.268.wav",
        "2022.acl-long.367.wav",
        "2022.acl-long.590.wav"
    ])
    arrival_rate: float = 2.0  # Poisson rate parameter (users per second)
    test_duration: int = 300  # 5 minutes
    output_dir: str = "evaluation_results"
    use_dynamic_schedule: bool = False
    max_batch_size: int = 32
    batch_timeout: float = 0.1
    # è¯„ä¼°ä¸“ç”¨é…ç½®
    session_timeout_extension: bool = True  # æ˜¯å¦å»¶é•¿sessionè¶…æ—¶æ—¶é—´
    ping_interval: int = 60  # pingé—´éš”ï¼ˆç§’ï¼‰
    
@dataclass 
class UserSimulation:
    """å•ä¸ªç”¨æˆ·æ¨¡æ‹Ÿ"""
    user_id: str
    language_pair: str
    video_file: str
    arrival_time: float
    session_id: Optional[str] = None
    start_time: Optional[float] = None
    end_time: Optional[float] = None
    stream_laal: Optional[float] = None
    total_characters: int = 0
    total_segments: int = 0
    delays: List[float] = field(default_factory=list)
    errors: List[str] = field(default_factory=list)
    status: str = "pending"  # pending, running, completed, failed

@dataclass
class EvaluationResults:
    """è¯„ä¼°ç»“æœ"""
    config: TestConfig
    users: List[UserSimulation]
    start_time: float
    end_time: float
    total_duration: float
    
    # æ±‡æ€»ç»Ÿè®¡
    completed_users: int = 0
    failed_users: int = 0
    avg_stream_laal: float = 0.0
    median_stream_laal: float = 0.0
    std_stream_laal: float = 0.0
    min_stream_laal: float = 0.0
    max_stream_laal: float = 0.0
    
    # æŒ‰è¯­è¨€çš„ç»Ÿè®¡
    chinese_results: Dict[str, float] = field(default_factory=dict)
    italian_results: Dict[str, float] = field(default_factory=dict)
    
    # ç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡
    server_stats: Dict[str, Any] = field(default_factory=dict)

class SimulatedUser:
    """æ¨¡æ‹Ÿç”¨æˆ·ç±»"""
    
    def __init__(self, simulation: UserSimulation, config: TestConfig):
        self.simulation = simulation
        self.config = config
        self.session: Optional[aiohttp.ClientSession] = None
        
    async def run(self) -> UserSimulation:
        """è¿è¡Œç”¨æˆ·æ¨¡æ‹Ÿ"""
        try:
            self.simulation.status = "running"
            self.simulation.start_time = time.time()
            
            # åˆ›å»ºHTTPä¼šè¯
            async with aiohttp.ClientSession() as session:
                self.session = session
                
                # æ­¥éª¤1ï¼šåŠ è½½æ¨¡å‹
                await self._load_model()
                                        
                # æ­¥éª¤2ï¼šè·å–æµ‹è¯•è§†é¢‘
                video_path = await self._get_test_video()
                
                # æ­¥éª¤3ï¼šå¤„ç†éŸ³é¢‘å¹¶æ”¶é›†å»¶è¿Ÿæ•°æ®
                await self._process_audio(video_path)
                
                # æ­¥éª¤4ï¼šè®¡ç®—æœ€ç»ˆæŒ‡æ ‡
                await self._calculate_metrics()
                
                self.simulation.status = "completed"
                self.simulation.end_time = time.time()
                
        except Exception as e:
            self.simulation.status = "failed"
            self.simulation.errors.append(str(e))
            self.simulation.end_time = time.time()
            logger.error(f"User {self.simulation.user_id} failed: {e}")
            
        return self.simulation
    
    async def _load_model(self):
        """åŠ è½½ç¿»è¯‘æ¨¡å‹"""
        logger.info(f"ğŸ¤– User {self.simulation.user_id}: Loading model for {self.simulation.language_pair}")
        
        payload = {
            "agent_type": "InfiniSST",
            "language_pair": self.simulation.language_pair,
            "latency_multiplier": 2,
            "client_id": self.simulation.user_id,
            "evaluation_mode": "true"  # ğŸ”¥ ä½¿ç”¨å­—ç¬¦ä¸²è€Œä¸æ˜¯å¸ƒå°”å€¼
        }
        
        async with self.session.post(f"{self.config.server_url}/init", params=payload) as response:
            if response.status != 200:
                raise Exception(f"Failed to load model: {response.status}")
            
            data = await response.json()
            self.simulation.session_id = data["session_id"]
            
            # å¦‚æœåœ¨é˜Ÿåˆ—ä¸­ï¼Œç­‰å¾…æ¨¡å‹åŠ è½½
            if data.get("queued", False):
                await self._wait_for_model_ready()
                
        logger.info(f"âœ… User {self.simulation.user_id}: Model loaded, session {self.simulation.session_id}")
    
    async def _wait_for_model_ready(self):
        """ç­‰å¾…æ¨¡å‹å‡†å¤‡å°±ç»ª"""
        max_wait = 180  # 3åˆ†é’Ÿ
        start_wait = time.time()
        
        while time.time() - start_wait < max_wait:
            async with self.session.get(f"{self.config.server_url}/queue_status/{self.simulation.session_id}") as response:
                if response.status == 200:
                    data = await response.json()
                    if data["status"] == "active":
                        return
                    elif data["status"] == "not_found":
                        raise Exception("Session not found in queue")
                        
            await asyncio.sleep(2)
            
        raise Exception(f"Model loading timeout after {max_wait}s")
    
    async def _get_test_video(self) -> str:
        """è·å–æµ‹è¯•è§†é¢‘æ–‡ä»¶"""
        # å°è¯•ä»æœåŠ¡å™¨è·å–æµ‹è¯•è§†é¢‘
        # try:
        #     async with self.session.get(f"{self.config.server_url}/test_video/{self.simulation.video_file}") as response:
        #         if response.status == 200:
        #             # ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
        #             temp_path = f"/tmp/{self.simulation.user_id}_{self.simulation.video_file}"
                    
        #             async with aiofiles.open(temp_path, 'wb') as f:
        #                 async for chunk in response.content.iter_chunked(8192):
        #                     await f.write(chunk)
                    
        #             logger.info(f"ğŸ“¹ User {self.simulation.user_id}: Downloaded test video to {temp_path}")
        #             return temp_path
        # except Exception as e:
        #     logger.warning(f"Failed to download test video from server: {e}")
        
        # å›é€€ï¼šå°è¯•æœ¬åœ°æ–‡ä»¶
        local_paths = [
            f"static/test_video/{self.simulation.video_file}",
            f"~/Downloads/{self.simulation.video_file}",
            f"/tmp/{self.simulation.video_file}"
        ]
        
        for path in local_paths:
            expanded_path = os.path.expanduser(path)
            if os.path.exists(expanded_path):
                logger.info(f"ğŸ“¹ User {self.simulation.user_id}: Using local video {expanded_path}")
                return expanded_path
                
        raise Exception(f"Test video {self.simulation.video_file} not found")
    
    async def _process_audio(self, video_path: str):
        """å¤„ç†éŸ³é¢‘å¹¶æ”¶é›†å»¶è¿Ÿæ•°æ® - å‚ç…§index.htmlçš„éŸ³é¢‘å¤„ç†æ–¹å¼"""
        # æå–éŸ³é¢‘
        audio_data, original_sample_rate = sf.read(video_path)
        
        # è½¬æ¢ä¸ºå•å£°é“
        if len(audio_data.shape) > 1:
            audio_data = audio_data.mean(axis=1)
        
        logger.info(f"ğŸµ User {self.simulation.user_id}: Processing {len(audio_data)/original_sample_rate:.1f}s of audio")
        logger.info(f"   - Original sample rate: {original_sample_rate}Hz")
        
        # åˆ›å»ºpingä»»åŠ¡ä»¥ä¿æŒsessionæ´»è·ƒ
        ping_task = asyncio.create_task(self._ping_session_periodically())
        
        try:
            # å»ºç«‹WebSocketè¿æ¥å¹¶æµå¼ä¼ è¾“éŸ³é¢‘
            ws_url = f"ws://localhost:8000/wss/{self.simulation.session_id}"
            
            max_retries = 3
            retry_count = 0
            
            while retry_count < max_retries:
                try:
                    async with self.session.ws_connect(ws_url) as ws:
                        logger.info(f"ğŸ”— User {self.simulation.user_id}: WebSocket connected (attempt {retry_count + 1})")
                        
                        # ğŸ¯ å‚ç…§index.htmlçš„éŸ³é¢‘å¤„ç†å‚æ•°
                        segment_size = 4096
                        target_sample_rate = 16000
                        base_chunk_size = 960 * 16  # 15360 samples
                        current_latency_multiplier = 2
                        
                        # è®¡ç®—é‡é‡‡æ ·æ¯”ä¾‹
                        resample_ratio = target_sample_rate / original_sample_rate
                        logger.info(f"   - Target sample rate: {target_sample_rate}Hz")
                        logger.info(f"   - Resample ratio: {resample_ratio:.3f}")
                        logger.info(f"   - Segment size: {segment_size} samples")
                        logger.info(f"   - Base chunk size: {base_chunk_size} samples")
                        
                        # é‡é‡‡æ ·éŸ³é¢‘æ•°æ®ï¼ˆå‚ç…§index.htmlçš„é‡é‡‡æ ·é€»è¾‘ï¼‰
                        if original_sample_rate != target_sample_rate:
                            resampled_length = int(len(audio_data) * resample_ratio)
                            resampled_audio = np.zeros(resampled_length, dtype=np.float32)
                            
                            for i in range(resampled_length):
                                original_index = int(i / resample_ratio)
                                if original_index < len(audio_data):
                                    resampled_audio[i] = audio_data[original_index]
                            
                            audio_data = resampled_audio
                            sample_rate = target_sample_rate
                            logger.info(f"   - Resampled to {len(audio_data)} samples @ {sample_rate}Hz")
                        else:
                            sample_rate = original_sample_rate
                        
                        # ğŸ¯ å‚ç…§index.htmlçš„ç¼“å†²åŒºå’Œåˆ†å—é€»è¾‘
                        resampled_buffer = np.array([], dtype=np.float32)
                        target_chunk_size = base_chunk_size * current_latency_multiplier
                        
                        logger.info(f"   - Target chunk size: {target_chunk_size} samples ({target_chunk_size/sample_rate:.3f}s)")
                        logger.info(f"   - Segment size: {segment_size} samples ({segment_size/sample_rate:.3f}s)")
                        
                        # ğŸ¯ æ¨¡æ‹Ÿå®æ—¶éŸ³é¢‘æµå¤„ç† (å‚ç…§index.htmlçš„éŸ³é¢‘å¤„ç†æµç¨‹)
                        audio_position = 0
                        start_time = time.time()
                        chunks_sent = 0
                        
                        while audio_position < len(audio_data):
                            # æ£€æŸ¥WebSocketè¿æ¥çŠ¶æ€
                            if ws.closed:
                                raise aiohttp.ClientConnectionError("WebSocket connection closed unexpectedly")
                            
                            # è®¡ç®—å½“å‰åº”è¯¥å¤„ç†åˆ°çš„ä½ç½®ï¼ˆåŸºäºå®æ—¶æ’­æ”¾ï¼‰
                            elapsed_time = time.time() - start_time
                            expected_position = int(elapsed_time * sample_rate)
                            
                            # å¦‚æœæˆ‘ä»¬å¤„ç†å¾—å¤ªå¿«ï¼Œç­‰å¾…ä¸€ä¸‹ä»¥æ¨¡æ‹Ÿå®æ—¶æ’­æ”¾
                            if audio_position >= expected_position:
                                sleep_time = (audio_position - expected_position) / sample_rate
                                if sleep_time > 0:
                                    await asyncio.sleep(min(sleep_time, 0.1))  # æœ€å¤šç­‰å¾…100ms
                            
                            # è·å–ä¸‹ä¸€ä¸ªsegmentï¼ˆå‚ç…§index.htmlçš„segment_sizeï¼‰
                            segment_end = min(audio_position + segment_size, len(audio_data))
                            current_segment = audio_data[audio_position:segment_end]
                            
                            # æ·»åŠ åˆ°é‡é‡‡æ ·ç¼“å†²åŒºï¼ˆå‚ç…§index.htmlçš„ç¼“å†²åŒºç®¡ç†ï¼‰
                            resampled_buffer = np.concatenate([resampled_buffer, current_segment])
                            
                            # è®°å½•è¾“å…¥æ—¶é—´æˆ³ï¼ˆå½“segmentè¿›å…¥ç¼“å†²åŒºæ—¶ï¼‰
                            input_timestamp = time.time()
                            
                            # å½“ç¼“å†²åŒºè¶³å¤Ÿå¤§æ—¶ï¼Œå‘é€chunkï¼ˆå‚ç…§index.htmlçš„chunkå‘é€é€»è¾‘ï¼‰
                            while len(resampled_buffer) >= target_chunk_size:
                                chunk = resampled_buffer[:target_chunk_size]
                                resampled_buffer = resampled_buffer[target_chunk_size:]
                                
                                # å‘é€éŸ³é¢‘chunkï¼ˆå‚ç…§index.htmlå‘é€Float32Arrayï¼‰
                                try:
                                    if ws.closed:
                                        raise aiohttp.ClientConnectionError("WebSocket closed before sending chunk")
                                        
                                    await ws.send_bytes(chunk.astype(np.float32).tobytes())
                                    chunks_sent += 1
                                    logger.debug(f"ğŸ“¤ User {self.simulation.user_id}: Sent chunk {chunks_sent} ({len(chunk)} samples)")
                                    
                                except Exception as chunk_error:
                                    logger.error(f"âŒ User {self.simulation.user_id}: Error sending chunk {chunks_sent}: {chunk_error}")
                                    raise
                                
                                # æ¥æ”¶ç¿»è¯‘ç»“æœï¼ˆéé˜»å¡ï¼‰
                                try:
                                    msg = await asyncio.wait_for(ws.receive(), timeout=0.1)
                                    if msg.type == aiohttp.WSMsgType.TEXT:
                                        text = msg.data
                                        output_timestamp = time.time()
                                        
                                        # è®¡ç®—å­—ç¬¦çº§å»¶è¿Ÿ
                                        if text and not text.startswith("ERROR:") and not text.startswith("READY:"):
                                            # ğŸ¯ æ›´ç²¾ç¡®çš„å»¶è¿Ÿè®¡ç®—ï¼šæ¯ä¸ªå­—ç¬¦ä½¿ç”¨ç›¸åŒçš„å»¶è¿Ÿ
                                            chunk_delay = output_timestamp - input_timestamp
                                            for char in text:
                                                self.simulation.delays.append(chunk_delay)
                                                self.simulation.total_characters += 1
                                            
                                            logger.debug(f"ğŸ“¤ User {self.simulation.user_id}: Received '{text}' (delay: {chunk_delay:.3f}s)")
                                    elif msg.type == aiohttp.WSMsgType.ERROR:
                                        logger.warning(f"âš ï¸ User {self.simulation.user_id}: WebSocket error: {msg.data}")
                                    elif msg.type == aiohttp.WSMsgType.CLOSE:
                                        logger.warning(f"âš ï¸ User {self.simulation.user_id}: WebSocket closed by server")
                                        raise aiohttp.ClientConnectionError("WebSocket closed by server")
                                    
                                except asyncio.TimeoutError:
                                    # æ²¡æœ‰ç«‹å³æ”¶åˆ°å›å¤ï¼Œç»§ç»­å¤„ç†
                                    pass
                                except Exception as receive_error:
                                    logger.warning(f"âš ï¸ User {self.simulation.user_id}: Error receiving message: {receive_error}")
                                    # ç»§ç»­å¤„ç†ï¼Œä¸ä¸­æ–­éŸ³é¢‘æµ
                            
                            audio_position = segment_end
                            
                            # çŸ­æš‚ä¼‘çœ ä»¥é¿å…è¿‡åº¦å ç”¨CPUï¼ˆå‚ç…§index.htmlçš„å¤„ç†é—´éš”ï¼‰
                            await asyncio.sleep(0.01)
                        
                        # å‘é€å‰©ä½™çš„ç¼“å†²åŒºæ•°æ®
                        if len(resampled_buffer) > 0:
                            try:
                                if not ws.closed:
                                    await ws.send_bytes(resampled_buffer.astype(np.float32).tobytes())
                                    logger.debug(f"ğŸ“¤ User {self.simulation.user_id}: Sent final chunk {len(resampled_buffer)} samples")
                            except Exception as e:
                                logger.error(f"âŒ User {self.simulation.user_id}: Error sending final chunk: {e}")
                        
                        # å‘é€ç»“æŸä¿¡å·
                        try:
                            if not ws.closed:
                                await ws.send_str("EOF")
                        except Exception as e:
                            logger.warning(f"âš ï¸ User {self.simulation.user_id}: Error sending EOF: {e}")
                        
                        # ç­‰å¾…å‰©ä½™çš„ç¿»è¯‘ç»“æœ
                        final_wait_start = time.time()
                        while time.time() - final_wait_start < 5.0:
                            try:
                                if ws.closed:
                                    break
                                    
                                msg = await asyncio.wait_for(ws.receive(), timeout=1.0)
                                if msg.type == aiohttp.WSMsgType.TEXT:
                                    text = msg.data
                                    if text.startswith("PROCESSING_COMPLETE"):
                                        logger.info(f"âœ… User {self.simulation.user_id}: Audio processing completed")
                                        break
                                    elif text and not text.startswith("ERROR:") and not text.startswith("READY:"):
                                        # å¤„ç†æœ€ç»ˆçš„ç¿»è¯‘ç»“æœ
                                        output_timestamp = time.time()
                                        final_delay = output_timestamp - input_timestamp
                                        for char in text:
                                            self.simulation.delays.append(final_delay)
                                            self.simulation.total_characters += 1
                                        
                                        logger.debug(f"ğŸ“¤ User {self.simulation.user_id}: Final result '{text}' (delay: {final_delay:.3f}s)")
                                elif msg.type == aiohttp.WSMsgType.CLOSE:
                                    break
                                    
                            except asyncio.TimeoutError:
                                continue
                            except Exception as e:
                                logger.warning(f"âš ï¸ User {self.simulation.user_id}: Error in final wait: {e}")
                                break
                        
                        logger.info(f"ğŸ User {self.simulation.user_id}: Audio processing completed. Chunks sent: {chunks_sent}, Total characters: {self.simulation.total_characters}")
                        
                        # æˆåŠŸå®Œæˆï¼Œé€€å‡ºé‡è¯•å¾ªç¯
                        break
                        
                except (aiohttp.ClientConnectionError, aiohttp.ClientResponseError, ConnectionResetError) as e:
                    retry_count += 1
                    logger.warning(f"ğŸ”„ User {self.simulation.user_id}: Connection error (attempt {retry_count}/{max_retries}): {e}")
                    
                    if retry_count < max_retries:
                        # ç­‰å¾…ä¸€æ®µæ—¶é—´åé‡è¯•
                        wait_time = min(2 ** retry_count, 10)  # æŒ‡æ•°é€€é¿ï¼Œæœ€å¤š10ç§’
                        logger.info(f"â³ User {self.simulation.user_id}: Waiting {wait_time}s before retry...")
                        await asyncio.sleep(wait_time)
                    else:
                        logger.error(f"âŒ User {self.simulation.user_id}: Max retries exceeded, giving up")
                        raise
                        
                except Exception as e:
                    logger.error(f"âŒ User {self.simulation.user_id}: Unexpected error: {e}")
                    raise
        
        finally:
            # åœæ­¢pingä»»åŠ¡
            ping_task.cancel()
            try:
                await ping_task
            except asyncio.CancelledError:
                pass

    
    async def _calculate_metrics(self):
        """è®¡ç®—ç”¨æˆ·æŒ‡æ ‡"""
        # é¦–å…ˆå°è¯•ä»æœåŠ¡å™¨è·å–ç²¾ç¡®çš„å»¶è¿Ÿæ•°æ®
        await self._fetch_server_delays()
        
        # ä½¿ç”¨æœ¬åœ°æ”¶é›†çš„å»¶è¿Ÿæ•°æ®ä½œä¸ºå¤‡ç”¨
        if self.simulation.delays:
            self.simulation.stream_laal = statistics.mean(self.simulation.delays)
            self.simulation.total_segments = len(self.simulation.delays)
            logger.info(f"ğŸ“Š User {self.simulation.user_id}: streamLAAL = {self.simulation.stream_laal:.3f}s "
                       f"({self.simulation.total_characters} chars, {self.simulation.total_segments} segments)")
        else:
            self.simulation.stream_laal = 0.0
            logger.warning(f"âš ï¸ User {self.simulation.user_id}: No delays recorded")
    
    async def _fetch_server_delays(self):
        """ä»æœåŠ¡å™¨è·å–ç²¾ç¡®çš„å»¶è¿Ÿæ•°æ®"""
        try:
            if not self.simulation.session_id:
                return
            
            # ç›´æ¥ä½¿ç”¨session_idä½œä¸ºURLå‚æ•°ï¼Œè®©FastAPIè‡ªåŠ¨å¤„ç†
            async with self.session.get(f"{self.config.server_url}/session_delays/{self.simulation.session_id}", params={"include_details": True}) as response:
                if response.status == 200:
                    data = await response.json()
                    if data.get("success", False):
                        delay_stats = data.get("delays", {})
                        
                        # æ›´æ–°ç»Ÿè®¡æ•°æ®
                        if "stream_laal" in delay_stats:
                            self.simulation.stream_laal = delay_stats["stream_laal"]
                            self.simulation.total_characters = delay_stats.get("total_characters", 0)
                            self.simulation.total_segments = delay_stats.get("segments", 0)
                            
                            # å¦‚æœæœ‰è¯¦ç»†çš„å­—ç¬¦å»¶è¿Ÿæ•°æ®ï¼Œä½¿ç”¨å®ƒ
                            if "character_delays" in delay_stats:
                                self.simulation.delays = [cd["delay"] for cd in delay_stats["character_delays"]]
                            
                            logger.info(f"ğŸ¯ User {self.simulation.user_id}: Server delays - streamLAAL = {self.simulation.stream_laal:.3f}s "
                                       f"({self.simulation.total_characters} chars, {self.simulation.total_segments} segments)")
                        else:
                            logger.warning(f"âš ï¸ User {self.simulation.user_id}: No server delay data available")
                    else:
                        logger.warning(f"âš ï¸ User {self.simulation.user_id}: Failed to get server delays: {data.get('error', 'Unknown error')}")
                else:
                    logger.debug(f"âš ï¸ User {self.simulation.user_id}: Server delays API returned status {response.status}")
                    
        except Exception as e:
            logger.debug(f"âš ï¸ User {self.simulation.user_id}: Failed to fetch server delays: {e}")
            # ä½¿ç”¨æœ¬åœ°æ•°æ®ä½œä¸ºå¤‡ç”¨
    
    async def _ping_session_periodically(self):
        """å®šæœŸå‘é€pingä»¥ä¿æŒsessionæ´»è·ƒ"""
        ping_interval = self.config.ping_interval  # ä½¿ç”¨é…ç½®çš„pingé—´éš”
        
        while True:
            try:
                await asyncio.sleep(ping_interval)
                
                if self.simulation.session_id:
                    try:
                        # ç›´æ¥ä½¿ç”¨session_idä½œä¸ºå‚æ•°ï¼Œè®©FastAPIè‡ªåŠ¨å¤„ç†
                        async with self.session.post(f"{self.config.server_url}/ping", params={"session_id": self.simulation.session_id}) as response:
                            if response.status == 200:
                                logger.debug(f"ğŸ’“ User {self.simulation.user_id}: Session ping successful")
                            else:
                                logger.warning(f"âš ï¸ User {self.simulation.user_id}: Session ping failed with status {response.status}")
                    except Exception as e:
                        logger.warning(f"âš ï¸ User {self.simulation.user_id}: Session ping error: {e}")
                        
            except asyncio.CancelledError:
                logger.debug(f"ğŸ”‡ User {self.simulation.user_id}: Ping task cancelled")
                break
            except Exception as e:
                logger.error(f"âŒ User {self.simulation.user_id}: Ping task error: {e}")
                # ç»§ç»­è¿è¡Œï¼Œä¸è¦å› ä¸ºpingå¤±è´¥è€Œåœæ­¢

class EvaluationFramework:
    """è¯„ä¼°æ¡†æ¶ä¸»ç±»"""
    
    def __init__(self, config: TestConfig):
        self.config = config
        self.results = None
        
    async def run_evaluation(self) -> EvaluationResults:
        """è¿è¡Œå®Œæ•´è¯„ä¼°"""
        logger.info(f"ğŸš€ Starting evaluation with {self.config.num_users} users")
        logger.info(f"   - Language split: {self.config.language_split*100:.0f}% Chinese, {(1-self.config.language_split)*100:.0f}% Italian")
        logger.info(f"   - Arrival rate: {self.config.arrival_rate} users/second")
        logger.info(f"   - Dynamic scheduling: {self.config.use_dynamic_schedule}")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(self.config.output_dir, exist_ok=True)
        
        # ç”Ÿæˆç”¨æˆ·æ¨¡æ‹Ÿ
        users = self._generate_user_simulations()
        
        # åˆå§‹åŒ–ç»“æœ
        self.results = EvaluationResults(
            config=self.config,
            users=users,
            start_time=time.time(),
            end_time=0.0,
            total_duration=0.0
        )
        
        # å¯åŠ¨æœåŠ¡å™¨é…ç½®ï¼ˆå¦‚æœéœ€è¦åŠ¨æ€è°ƒåº¦ï¼‰
        if self.config.use_dynamic_schedule:
            await self._configure_server()
        
        # æ¨¡æ‹Ÿæ³Šæ¾åˆ°è¾¾å¹¶æ‰§è¡Œç”¨æˆ·
        await self._simulate_poisson_arrivals(users)
        
        # è®¡ç®—æ±‡æ€»ç»Ÿè®¡
        self._calculate_summary_statistics()
        
        # å¯¼å‡ºç»“æœ
        await self._export_results()
        
        self.results.end_time = time.time()
        self.results.total_duration = self.results.end_time - self.results.start_time
        
        logger.info(f"âœ… Evaluation completed in {self.results.total_duration:.1f}s")
        return self.results
    
    def _generate_user_simulations(self) -> List[UserSimulation]:
        """ç”Ÿæˆç”¨æˆ·æ¨¡æ‹Ÿé…ç½®"""
        users = []
        
        for i in range(self.config.num_users):
            # ç”Ÿæˆæ³Šæ¾åˆ°è¾¾æ—¶é—´
            if i == 0:
                arrival_time = 0.0
            else:
                # æ³Šæ¾è¿‡ç¨‹ï¼šæŒ‡æ•°åˆ†å¸ƒçš„é—´éš”æ—¶é—´
                interval = random.expovariate(self.config.arrival_rate)
                arrival_time = users[-1].arrival_time + interval
            
            # åˆ†é…è¯­è¨€å¯¹
            if random.random() < self.config.language_split:
                language_pair = "English -> Chinese"
            else:
                language_pair = "English -> Italian"
            
            # éšæœºé€‰æ‹©æµ‹è¯•è§†é¢‘
            video_file = random.choice(self.config.test_videos)
            
            user = UserSimulation(
                user_id=f"eval_user_{i:03d}_{uuid.uuid4().hex[:8]}",
                language_pair=language_pair,
                video_file=video_file,
                arrival_time=arrival_time
            )
            
            users.append(user)
        
        return users
    
    async def _configure_server(self):
        """é…ç½®æœåŠ¡å™¨çš„åŠ¨æ€è°ƒåº¦å‚æ•°"""
        # TODO: å®ç°æœåŠ¡å™¨é…ç½®APIè°ƒç”¨
        logger.info(f"ğŸ”§ Configuring server for dynamic scheduling")
        logger.info(f"   - max_batch_size: {self.config.max_batch_size}")
        logger.info(f"   - batch_timeout: {self.config.batch_timeout}s")
        
        # è¿™é‡Œå¯ä»¥æ·»åŠ å¯¹æœåŠ¡å™¨é…ç½®APIçš„è°ƒç”¨
    
    async def _simulate_poisson_arrivals(self, users: List[UserSimulation]):
        """æ¨¡æ‹Ÿæ³Šæ¾åˆ°è¾¾è¿‡ç¨‹"""
        logger.info(f"â° Simulating Poisson arrivals over {self.config.test_duration}s")
        
        # å¯åŠ¨æ‰€æœ‰ç”¨æˆ·ä»»åŠ¡
        tasks = []
        
        for user in users:
            # å¦‚æœåˆ°è¾¾æ—¶é—´è¶…è¿‡æµ‹è¯•æŒç»­æ—¶é—´ï¼Œè·³è¿‡
            if user.arrival_time > self.config.test_duration:
                user.status = "skipped"
                continue
                
            # åˆ›å»ºå»¶è¿Ÿä»»åŠ¡
            task = asyncio.create_task(self._delayed_user_start(user))
            tasks.append(task)
        
        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆæˆ–è¶…æ—¶
        try:
            await asyncio.wait_for(
                asyncio.gather(*tasks, return_exceptions=True),
                timeout=self.config.test_duration + 300  # é¢å¤–5åˆ†é’Ÿç¼“å†²
            )
        except asyncio.TimeoutError:
            logger.warning("â° Some users did not complete within timeout")
            
            # å–æ¶ˆæœªå®Œæˆçš„ä»»åŠ¡
            for task in tasks:
                if not task.done():
                    task.cancel()
    
    async def _delayed_user_start(self, user: UserSimulation) -> UserSimulation:
        """å»¶è¿Ÿå¯åŠ¨ç”¨æˆ·"""
        # ç­‰å¾…åˆ°è¾¾æ—¶é—´
        await asyncio.sleep(user.arrival_time)
        
        logger.info(f"ğŸ‘¤ User {user.user_id} arriving at t={user.arrival_time:.1f}s ({user.language_pair})")
        
        # å¯åŠ¨ç”¨æˆ·æ¨¡æ‹Ÿ
        simulated_user = SimulatedUser(user, self.config)
        return await simulated_user.run()
    
    def _calculate_summary_statistics(self):
        """è®¡ç®—æ±‡æ€»ç»Ÿè®¡"""
        assert self.results is not None, "Results must be initialized before calculating statistics"
        
        completed_users = [u for u in self.results.users if u.status == "completed" and u.stream_laal is not None]
        failed_users = [u for u in self.results.users if u.status == "failed"]
        
        self.results.completed_users = len(completed_users)
        self.results.failed_users = len(failed_users)
        
        if completed_users:
            # è¿‡æ»¤æ‰Noneå€¼ï¼Œç¡®ä¿åªæœ‰æœ‰æ•ˆçš„streamLAALæ•°æ®
            laals = [u.stream_laal for u in completed_users if u.stream_laal is not None]
            
            if laals:  # ç¡®ä¿æœ‰æœ‰æ•ˆæ•°æ®
                self.results.avg_stream_laal = statistics.mean(laals)
                self.results.median_stream_laal = statistics.median(laals)
                self.results.std_stream_laal = statistics.stdev(laals) if len(laals) > 1 else 0.0
                self.results.min_stream_laal = min(laals)
                self.results.max_stream_laal = max(laals)
                
                # æŒ‰è¯­è¨€åˆ†ç»„ç»Ÿè®¡
                chinese_laals = [u.stream_laal for u in completed_users if "Chinese" in u.language_pair and u.stream_laal is not None]
                italian_laals = [u.stream_laal for u in completed_users if "Italian" in u.language_pair and u.stream_laal is not None]
                
                if chinese_laals:
                    self.results.chinese_results = {
                        "count": len(chinese_laals),
                        "avg_stream_laal": statistics.mean(chinese_laals),
                        "std_stream_laal": statistics.stdev(chinese_laals) if len(chinese_laals) > 1 else 0.0
                    }
                
                if italian_laals:
                    self.results.italian_results = {
                        "count": len(italian_laals),
                        "avg_stream_laal": statistics.mean(italian_laals),
                        "std_stream_laal": statistics.stdev(italian_laals) if len(italian_laals) > 1 else 0.0
                    }
        
        logger.info(f"ğŸ“Š Summary: {self.results.completed_users} completed, {self.results.failed_users} failed")
        logger.info(f"ğŸ“Š Overall streamLAAL: {self.results.avg_stream_laal:.3f}s Â± {self.results.std_stream_laal:.3f}s")
    
    async def _export_results(self):
        """å¯¼å‡ºç»“æœåˆ°æ–‡ä»¶"""
        assert self.results is not None, "Results must be initialized before exporting"
        
        timestamp = int(time.time())
        
        # å¯¼å‡ºè¯¦ç»†ç»“æœ
        detailed_results_path = os.path.join(
            self.config.output_dir, 
            f"evaluation_detailed_{timestamp}.json"
        )
        
        # å‡†å¤‡å¯¼å‡ºæ•°æ®
        export_data = {
            "config": {
                "num_users": self.config.num_users,
                "language_split": self.config.language_split,
                "arrival_rate": self.config.arrival_rate,
                "test_duration": self.config.test_duration,
                "use_dynamic_schedule": self.config.use_dynamic_schedule,
                "max_batch_size": self.config.max_batch_size,
                "batch_timeout": self.config.batch_timeout
            },
            "summary": {
                "completed_users": self.results.completed_users,
                "failed_users": self.results.failed_users,
                "avg_stream_laal": self.results.avg_stream_laal,
                "median_stream_laal": self.results.median_stream_laal,
                "std_stream_laal": self.results.std_stream_laal,
                "min_stream_laal": self.results.min_stream_laal,
                "max_stream_laal": self.results.max_stream_laal,
                "chinese_results": self.results.chinese_results,
                "italian_results": self.results.italian_results
            },
            "users": []
        }
        
        # æ·»åŠ ç”¨æˆ·è¯¦ç»†æ•°æ®
        for user in self.results.users:
            user_data = {
                "user_id": user.user_id,
                "language_pair": user.language_pair,
                "video_file": user.video_file,
                "arrival_time": user.arrival_time,
                "start_time": user.start_time,
                "end_time": user.end_time,
                "stream_laal": user.stream_laal,
                "total_characters": user.total_characters,
                "total_segments": user.total_segments,
                "status": user.status,
                "errors": user.errors
            }
            export_data["users"].append(user_data)
        
        # å†™å…¥è¯¦ç»†ç»“æœæ–‡ä»¶
        async with aiofiles.open(detailed_results_path, 'w') as f:
            await f.write(json.dumps(export_data, indent=2, ensure_ascii=False))
        
        logger.info(f"ğŸ“ Detailed results exported to {detailed_results_path}")
        
        # å¯¼å‡ºsimulevalæ ¼å¼çš„instance.logæ–‡ä»¶
        await self._export_simuleval_logs()
        
        # ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
        await self._generate_summary_report(timestamp)
    
    async def _export_simuleval_logs(self):
        """å¯¼å‡ºsimulevalå…¼å®¹çš„instance.logæ–‡ä»¶"""
        for user in self.results.users:
            if user.status == "completed":
                log_path = os.path.join(
                    self.config.output_dir,
                    f"instance_{user.user_id}.log"
                )
                
                # é¦–å…ˆå°è¯•ä»æœåŠ¡å™¨å¯¼å‡ºç²¾ç¡®çš„å»¶è¿Ÿæ•°æ®
                server_exported = await self._export_server_delays(user, log_path)
                
                if not server_exported and user.delays:
                    # å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨æœ¬åœ°æ”¶é›†çš„å»¶è¿Ÿæ•°æ®
                    await self._export_local_delays(user, log_path)
                    
                logger.debug(f"ğŸ“ Simuleval log exported for {user.user_id}")
    
    async def _export_server_delays(self, user: UserSimulation, log_path: str) -> bool:
        """ä»æœåŠ¡å™¨å¯¼å‡ºç²¾ç¡®çš„å»¶è¿Ÿæ•°æ®"""
        try:
            if not user.session_id:
                return False
                
            # è°ƒç”¨æœåŠ¡å™¨çš„å¯¼å‡ºAPI
            async with aiohttp.ClientSession() as temp_session:
                # ç›´æ¥ä½¿ç”¨session_idä½œä¸ºå‚æ•°ï¼Œè®©FastAPIè‡ªåŠ¨å¤„ç†
                async with temp_session.post(
                    f"{self.config.server_url}/export_session_delays", 
                    params={
                        "session_id": user.session_id,
                        "filepath": log_path
                    }
                ) as response:
                    if response.status == 200:
                        data = await response.json()
                        if data.get("success", False):
                            logger.info(f"ğŸ¯ User {user.user_id}: Server delays exported to {log_path}")
                            return True
                        else:
                            logger.warning(f"âš ï¸ User {user.user_id}: Server export failed: {data.get('error', 'Unknown error')}")
                    else:
                        logger.debug(f"âš ï¸ User {user.user_id}: Server export API returned status {response.status}")
                        
        except Exception as e:
            logger.debug(f"âš ï¸ User {user.user_id}: Failed to export server delays: {e}")
            
        return False
    
    async def _export_local_delays(self, user: UserSimulation, log_path: str):
        """ä½¿ç”¨æœ¬åœ°æ”¶é›†çš„å»¶è¿Ÿæ•°æ®å¯¼å‡ºï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
        log_entries = []
        
        # ğŸ”¥ æ”¹è¿›ï¼šå°è¯•ä»æœåŠ¡å™¨è·å–çœŸå®çš„ç¿»è¯‘æ–‡æœ¬
        real_segments = []
        try:
            if user.session_id:
                async with aiohttp.ClientSession() as temp_session:
                    # ç›´æ¥ä½¿ç”¨session_idä½œä¸ºURLå‚æ•°ï¼Œè®©FastAPIè‡ªåŠ¨å¤„ç†
                    async with temp_session.get(
                        f"{self.config.server_url}/session_delays/{user.session_id}",
                        params={"include_details": True}
                    ) as response:
                        if response.status == 200:
                            data = await response.json()
                            if data.get("success", False):
                                delay_stats = data.get("delays", {})
                                if "segment_logs" in delay_stats:
                                    real_segments = delay_stats["segment_logs"]
                                    logger.info(f"ğŸ¯ User {user.user_id}: Retrieved {len(real_segments)} real segments from server")
        except Exception as e:
            logger.debug(f"âš ï¸ User {user.user_id}: Failed to get real segments: {e}")
        
        # æ”¹è¿›çš„æœ¬åœ°å»¶è¿Ÿå¯¼å‡º - ä¼˜å…ˆä½¿ç”¨çœŸå®æ•°æ®
        if real_segments:
            # ä½¿ç”¨ä»æœåŠ¡å™¨è·å–çš„çœŸå®æ•°æ®
            for segment in real_segments:
                entry = {
                    "segment_id": segment["segment_id"],
                    "src": segment["src"],  # çœŸå®çš„æºæ–‡æœ¬ï¼ˆè™½ç„¶å¯èƒ½æ˜¯å ä½ç¬¦ï¼‰
                    "tgt": segment["tgt"],  # çœŸå®çš„ç¿»è¯‘æ–‡æœ¬
                    "tokens": segment["tokens"],  # çœŸå®çš„token
                    "delays": segment["delays"],  # çœŸå®çš„å»¶è¿Ÿ
                    "input_start_time": segment.get("input_start_time", 0),
                    "output_time": segment.get("output_time", 0),
                    "average_delay": segment.get("average_delay", 0),
                    "user_id": user.user_id,
                    "language_pair": user.language_pair,
                    "video_file": user.video_file,
                    "estimated": False  # æ ‡è®°è¿™æ˜¯çœŸå®æ•°æ®
                }
                log_entries.append(entry)
        else:
            raise ValueError("No real segments found")
        
        # å†™å…¥æ–‡ä»¶
        async with aiofiles.open(log_path, 'w') as f:
            for entry in log_entries:
                await f.write(json.dumps(entry, ensure_ascii=False) + '\n')
        
        data_type = "real" if real_segments else "estimated"
        logger.info(f"ğŸ“ User {user.user_id}: Local delays exported to {log_path} ({len(log_entries)} entries, {data_type} data)")
    
    async def _generate_summary_report(self, timestamp: int):
        """ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š"""
        report_path = os.path.join(
            self.config.output_dir,
            f"evaluation_summary_{timestamp}.txt"
        )
        
        report_lines = [
            "=" * 80,
            "InfiniSST Evaluation Framework - Summary Report",
            "=" * 80,
            "",
            f"Test Configuration:",
            f"  - Number of users: {self.config.num_users}",
            f"  - Language split: {self.config.language_split*100:.0f}% Chinese, {(1-self.config.language_split)*100:.0f}% Italian",
            f"  - Arrival rate: {self.config.arrival_rate} users/second",
            f"  - Test duration: {self.config.test_duration}s",
            f"  - Dynamic scheduling: {self.config.use_dynamic_schedule}",
            "",
            f"Results Summary:",
            f"  - Completed users: {self.results.completed_users}",
            f"  - Failed users: {self.results.failed_users}",
            f"  - Success rate: {self.results.completed_users/(self.results.completed_users+self.results.failed_users)*100:.1f}%",
            "",
            f"StreamLAAL Metrics:",
            f"  - Average: {self.results.avg_stream_laal:.3f}s",
            f"  - Median: {self.results.median_stream_laal:.3f}s", 
            f"  - Std Dev: {self.results.std_stream_laal:.3f}s",
            f"  - Min: {self.results.min_stream_laal:.3f}s",
            f"  - Max: {self.results.max_stream_laal:.3f}s",
            ""
        ]
        
        # æŒ‰è¯­è¨€åˆ†ç»„çš„ç»“æœ
        if self.results.chinese_results:
            report_lines.extend([
                f"Chinese Translation Results:",
                f"  - Count: {self.results.chinese_results['count']}",
                f"  - Average streamLAAL: {self.results.chinese_results['avg_stream_laal']:.3f}s",
                f"  - Std Dev: {self.results.chinese_results['std_stream_laal']:.3f}s",
                ""
            ])
        
        if self.results.italian_results:
            report_lines.extend([
                f"Italian Translation Results:",
                f"  - Count: {self.results.italian_results['count']}",
                f"  - Average streamLAAL: {self.results.italian_results['avg_stream_laal']:.3f}s",
                f"  - Std Dev: {self.results.italian_results['std_stream_laal']:.3f}s",
                ""
            ])
        
        report_lines.extend([
            "=" * 80,
            f"Test completed at: {time.strftime('%Y-%m-%d %H:%M:%S')}",
            f"Total duration: {self.results.total_duration:.1f}s",
            "=" * 80
        ])
        
        # å†™å…¥æŠ¥å‘Šæ–‡ä»¶
        async with aiofiles.open(report_path, 'w') as f:
            await f.write('\n'.join(report_lines))
        
        # åŒæ—¶æ‰“å°åˆ°æ§åˆ¶å°
        print('\n'.join(report_lines))
        
        logger.info(f"ğŸ“Š Summary report saved to {report_path}")

async def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="InfiniSST Evaluation Framework")
    parser.add_argument("--num-users", type=int, default=16, help="Number of concurrent users")
    parser.add_argument("--language-split", type=float, default=0.5, help="Fraction of Chinese users (0.0-1.0)")
    parser.add_argument("--arrival-rate", type=float, default=2.0, help="Poisson arrival rate (users/second)")
    parser.add_argument("--test-duration", type=int, default=300, help="Test duration in seconds")
    parser.add_argument("--server-url", default="http://localhost:8000", help="Server URL")
    parser.add_argument("--output-dir", default="evaluation_results", help="Output directory")
    parser.add_argument("--use-dynamic-schedule", action="store_true", help="Enable dynamic scheduling")
    parser.add_argument("--max-batch-size", type=int, default=32, help="Maximum batch size")
    parser.add_argument("--batch-timeout", type=float, default=0.1, help="Batch timeout in seconds")
    
    args = parser.parse_args()
    
    # åˆ›å»ºæµ‹è¯•é…ç½®
    config = TestConfig(
        num_users=args.num_users,
        language_split=args.language_split,
        arrival_rate=args.arrival_rate,
        test_duration=args.test_duration,
        server_url=args.server_url,
        output_dir=args.output_dir,
        use_dynamic_schedule=args.use_dynamic_schedule,
        max_batch_size=args.max_batch_size,
        batch_timeout=args.batch_timeout
    )
    
    # è¿è¡Œè¯„ä¼°
    framework = EvaluationFramework(config)
    results = await framework.run_evaluation()
    
    print(f"\nğŸ‰ Evaluation completed!")
    print(f"Results saved to: {config.output_dir}")
    print(f"Overall streamLAAL: {results.avg_stream_laal:.3f}s Â± {results.std_stream_laal:.3f}s")

if __name__ == "__main__":
    asyncio.run(main()) 