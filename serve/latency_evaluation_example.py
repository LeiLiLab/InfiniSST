#!/usr/bin/env python3
"""
Latency Evaluation Example
å±•ç¤ºå¦‚ä½•ä½¿ç”¨ä¸åŒlatencyé…ç½®è¿›è¡Œè¯„ä¼°æµ‹è¯•çš„ç¤ºä¾‹
"""

import asyncio
import sys
import os

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(__file__))

from evaluation_framework import EvaluationFramework, TestConfig

async def example_uniform_latency_test():
    """ç¤ºä¾‹1: å‡åŒ€åˆ†å¸ƒçš„latencyæµ‹è¯•"""
    print("ðŸ”¥ ç¤ºä¾‹1: å‡åŒ€åˆ†å¸ƒlatencyæµ‹è¯• (1x-4x)")
    
    config = TestConfig(
        num_users=12,
        language_split=0.5,
        arrival_rate=1.5,
        test_duration=90,
        server_url="http://localhost:8000",
        output_dir="evaluation_results/uniform_latency",
        latency_range=[1, 2, 3, 4],        # ðŸ”¥ æµ‹è¯•æ‰€æœ‰latency
        latency_distribution=None          # ðŸ”¥ å‡åŒ€åˆ†å¸ƒ
    )
    
    framework = EvaluationFramework(config)
    results = await framework.run_evaluation()
    
    print(f"\nðŸ“Š å‡åŒ€latencyæµ‹è¯•ç»“æžœ:")
    print(f"   - å®Œæˆç”¨æˆ·: {results.completed_users}")
    print(f"   - å¹³å‡streamLAAL: {results.avg_stream_laal:.3f}s")
    
    # æ˜¾ç¤ºæŒ‰latencyåˆ†ç»„çš„ç»“æžœ
    for latency, stats in sorted(results.latency_results.items()):
        print(f"   - Latency {latency}x: {stats['count']} ç”¨æˆ·, avg = {stats['avg_stream_laal']:.3f}s")
    
    return results

async def example_weighted_latency_test():
    """ç¤ºä¾‹2: åŠ æƒåˆ†å¸ƒçš„latencyæµ‹è¯•"""
    print("\nðŸ”¥ ç¤ºä¾‹2: åŠ æƒåˆ†å¸ƒlatencyæµ‹è¯• (åå‘2xå’Œ3x)")
    
    config = TestConfig(
        num_users=16,
        language_split=0.5,
        arrival_rate=2.0,
        test_duration=120,
        server_url="http://localhost:8000",
        output_dir="evaluation_results/weighted_latency",
        latency_range=[1, 2, 3, 4],        # ðŸ”¥ æµ‹è¯•æ‰€æœ‰latency
        latency_distribution=[0.1, 0.4, 0.4, 0.1]  # ðŸ”¥ åå‘ä¸­ç­‰latency
    )
    
    framework = EvaluationFramework(config)
    results = await framework.run_evaluation()
    
    print(f"\nðŸ“Š åŠ æƒlatencyæµ‹è¯•ç»“æžœ:")
    print(f"   - å®Œæˆç”¨æˆ·: {results.completed_users}")
    print(f"   - å¹³å‡streamLAAL: {results.avg_stream_laal:.3f}s")
    
    # æ˜¾ç¤ºæŒ‰latencyåˆ†ç»„çš„ç»“æžœ
    for latency, stats in sorted(results.latency_results.items()):
        print(f"   - Latency {latency}x: {stats['count']} ç”¨æˆ·, avg = {stats['avg_stream_laal']:.3f}s")
    
    return results

async def example_single_latency_test():
    """ç¤ºä¾‹3: å•ä¸€latencyæµ‹è¯•"""
    print("\nðŸ”¥ ç¤ºä¾‹3: å•ä¸€latencyæµ‹è¯• (ä»…3x)")
    
    config = TestConfig(
        num_users=8,
        language_split=0.5,
        arrival_rate=1.0,
        test_duration=60,
        server_url="http://localhost:8000",
        output_dir="evaluation_results/single_latency_3x",
        latency_range=[3],                 # ðŸ”¥ ä»…æµ‹è¯•3x latency
        latency_distribution=None
    )
    
    framework = EvaluationFramework(config)
    results = await framework.run_evaluation()
    
    print(f"\nðŸ“Š å•ä¸€latency (3x) æµ‹è¯•ç»“æžœ:")
    print(f"   - å®Œæˆç”¨æˆ·: {results.completed_users}")
    print(f"   - å¹³å‡streamLAAL: {results.avg_stream_laal:.3f}s")
    print(f"   - æ ‡å‡†å·®: {results.std_stream_laal:.3f}s")
    
    return results

async def example_extreme_latency_test():
    """ç¤ºä¾‹4: æžç«¯latencyå¯¹æ¯”æµ‹è¯•"""
    print("\nðŸ”¥ ç¤ºä¾‹4: æžç«¯latencyå¯¹æ¯”æµ‹è¯• (1x vs 4x)")
    
    # æµ‹è¯•æœ€ä½Žlatency (1x)
    low_config = TestConfig(
        num_users=6,
        language_split=0.5,
        arrival_rate=1.0,
        test_duration=60,
        server_url="http://localhost:8000",
        output_dir="evaluation_results/extreme_low_latency",
        latency_range=[1],                 # ðŸ”¥ ä»…1x latency
        latency_distribution=None
    )
    
    low_framework = EvaluationFramework(low_config)
    low_results = await low_framework.run_evaluation()
    
    # æµ‹è¯•æœ€é«˜latency (4x)
    high_config = TestConfig(
        num_users=6,
        language_split=0.5,
        arrival_rate=1.0,
        test_duration=60,
        server_url="http://localhost:8000",
        output_dir="evaluation_results/extreme_high_latency",
        latency_range=[4],                 # ðŸ”¥ ä»…4x latency
        latency_distribution=None
    )
    
    high_framework = EvaluationFramework(high_config)
    high_results = await high_framework.run_evaluation()
    
    # å¯¹æ¯”ç»“æžœ
    print(f"\nðŸ“Š æžç«¯latencyå¯¹æ¯”ç»“æžœ:")
    print(f"   1x Latency: {low_results.avg_stream_laal:.3f}s ({low_results.completed_users} ç”¨æˆ·)")
    print(f"   4x Latency: {high_results.avg_stream_laal:.3f}s ({high_results.completed_users} ç”¨æˆ·)")
    
    if low_results.avg_stream_laal > 0 and high_results.avg_stream_laal > 0:
        ratio = high_results.avg_stream_laal / low_results.avg_stream_laal
        print(f"   4x/1x æ¯”ä¾‹: {ratio:.2f}")
        
        if ratio > 1.5:
            print(f"   ðŸ“ˆ é«˜latencyæ˜¾è‘—å¢žåŠ äº†streamLAAL")
        elif ratio < 0.8:
            print(f"   ðŸ“‰ é«˜latencyå®žé™…é™ä½Žäº†streamLAAL (å¯èƒ½å› ä¸ºå‡å°‘äº†ç­‰å¾…)")
        else:
            print(f"   âš–ï¸  latencyå¯¹streamLAALå½±å“è¾ƒå°")
    
    return low_results, high_results

async def example_mixed_language_latency_test():
    """ç¤ºä¾‹5: æ··åˆè¯­è¨€+latencyæµ‹è¯•"""
    print("\nðŸ”¥ ç¤ºä¾‹5: æ··åˆè¯­è¨€+latencyç»„åˆæµ‹è¯•")
    
    config = TestConfig(
        num_users=20,
        language_split=0.5,               # 50% Chinese, 50% Italian
        arrival_rate=2.0,
        test_duration=150,
        server_url="http://localhost:8000",
        output_dir="evaluation_results/mixed_lang_latency",
        latency_range=[1, 2, 3, 4],       # ðŸ”¥ æ‰€æœ‰latency
        latency_distribution=[0.25, 0.25, 0.25, 0.25]  # ðŸ”¥ å®Œå…¨å‡åŒ€åˆ†å¸ƒ
    )
    
    framework = EvaluationFramework(config)
    results = await framework.run_evaluation()
    
    print(f"\nðŸ“Š æ··åˆè¯­è¨€+latencyæµ‹è¯•ç»“æžœ:")
    print(f"   - å®Œæˆç”¨æˆ·: {results.completed_users}")
    print(f"   - å¹³å‡streamLAAL: {results.avg_stream_laal:.3f}s")
    
    # æŒ‰è¯­è¨€æ˜¾ç¤ºç»“æžœ
    if results.chinese_results:
        print(f"   - ä¸­æ–‡ç¿»è¯‘: {results.chinese_results['count']} ç”¨æˆ·, avg = {results.chinese_results['avg_stream_laal']:.3f}s")
    if results.italian_results:
        print(f"   - æ„å¤§åˆ©è¯­ç¿»è¯‘: {results.italian_results['count']} ç”¨æˆ·, avg = {results.italian_results['avg_stream_laal']:.3f}s")
    
    # æŒ‰latencyæ˜¾ç¤ºç»“æžœ
    print(f"   - æŒ‰Latencyåˆ†ç»„:")
    for latency, stats in sorted(results.latency_results.items()):
        print(f"     Latency {latency}x: {stats['count']} ç”¨æˆ·, avg = {stats['avg_stream_laal']:.3f}s")
    
    return results

async def main():
    """è¿è¡Œæ‰€æœ‰latencyè¯„ä¼°ç¤ºä¾‹"""
    print("ðŸš€ å¼€å§‹Latencyè¯„ä¼°ç¤ºä¾‹æµ‹è¯•")
    print("=" * 80)
    
    try:
        # è¿è¡Œæ‰€æœ‰ç¤ºä¾‹
        await example_uniform_latency_test()
        await asyncio.sleep(2)  # çŸ­æš‚ä¼‘æ¯
        
        await example_weighted_latency_test()
        await asyncio.sleep(2)
        
        await example_single_latency_test()
        await asyncio.sleep(2)
        
        await example_extreme_latency_test()
        await asyncio.sleep(2)
        
        await example_mixed_language_latency_test()
        
        print("\n" + "=" * 80)
        print("ðŸŽ‰ æ‰€æœ‰Latencyè¯„ä¼°ç¤ºä¾‹å®Œæˆ!")
        print("\nðŸ“ ç»“æžœä¿å­˜åœ¨ä»¥ä¸‹ç›®å½•:")
        print("   - evaluation_results/uniform_latency/")
        print("   - evaluation_results/weighted_latency/")
        print("   - evaluation_results/single_latency_3x/")
        print("   - evaluation_results/extreme_low_latency/")
        print("   - evaluation_results/extreme_high_latency/")
        print("   - evaluation_results/mixed_lang_latency/")
        
        print("\nðŸ’¡ ä½¿ç”¨æŠ€å·§:")
        print("   1. è°ƒæ•´ latency_range æ¥æµ‹è¯•ä¸åŒçš„latencyç»„åˆ")
        print("   2. ä½¿ç”¨ latency_distribution æ¥æŽ§åˆ¶latencyåˆ†å¸ƒæƒé‡")
        print("   3. ç»“åˆè¯­è¨€å’Œlatencyåˆ†æžå¯ä»¥å‘çŽ°æ›´æ·±å±‚çš„æ€§èƒ½æ¨¡å¼")
        print("   4. å¯¹æ¯”æžç«¯å€¼å¯ä»¥è¯„ä¼°latencyç­–ç•¥çš„æ•ˆæžœ")
        
    except Exception as e:
        print(f"\nâŒ ç¤ºä¾‹æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(main()) 