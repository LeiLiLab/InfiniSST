class ElectronAudioProcessor {
    constructor() {
        this.audioContext = null;
        this.workletNode = null;
        this.micStream = null;
        this.sourceNode = null;
        this.ws = null;
        this.isProcessing = false;
        this.resampledBuffer = new Float32Array();
        this.chunksSentCount = 0;
        this.errorCount = 0;
        this.lastIdleResetTime = 0;

        this.config = {
            targetSampleRate: 16000,
            baseChunkSize: 960 * 16,
            maxErrorCount: 5,
            idleResetThrottleMs: 1000
        };

        console.log('ğŸµ ElectronAudioProcessor with AudioWorklet created');
    }

    async initializeAudio(audioSource, websocket, sourceType = 'microphone') {
        try {
            console.log('ğŸš€ Initializing AudioWorklet-based processor for', sourceType, '...');
            if (sourceType === 'microphone') {
                this.micStream = audioSource;
            } else if (sourceType === 'media') {
                this.mediaElement = audioSource;
            }
            this.audioSource = audioSource;
            this.sourceType = sourceType;
            this.ws = websocket;
            this.isProcessing = true;
            this.errorCount = 0;
            this.chunksSentCount = 0;
            this.resampledBuffer = new Float32Array();

            // åˆ›å»ºAudioContextå¹¶æ£€æŸ¥çŠ¶æ€
            this.audioContext = new AudioContext({ sampleRate: 48000 });
            console.log('ğŸ™ï¸ AudioContext created, state:', this.audioContext.state);
            
            // ç¡®ä¿AudioContextå¤„äºè¿è¡ŒçŠ¶æ€
            if (this.audioContext.state === 'suspended') {
                console.log('â–¶ï¸ Resuming suspended AudioContext...');
                await this.audioContext.resume();
            }
            
            // åœ¨Electronç¯å¢ƒä¸­ä½¿ç”¨æ­£ç¡®çš„æ¨¡å—è·¯å¾„
            let audioProcessorUrl;
            let urlBuildMethod = 'unknown';
            try {
                // å°è¯•å¤šç§URLæ„å»ºæ–¹å¼
                if (window.location && window.location.origin) {
                    audioProcessorUrl = window.location.origin + '/static/audio-processor.js';
                    urlBuildMethod = 'window.location.origin';
                } else {
                    // å¤‡ç”¨æ–¹æ¡ˆ
                    const protocol = window.location.protocol || 'http:';
                    const host = window.location.host || 'localhost';
                    audioProcessorUrl = `${protocol}//${host}/static/audio-processor.js`;
                    urlBuildMethod = 'manual construction';
                }
            } catch (urlError) {
                console.warn('âš ï¸ Error building URL, using relative path:', urlError);
                audioProcessorUrl = '/static/audio-processor.js';
                urlBuildMethod = 'relative path fallback';
            }
            
            console.log('ğŸ“ Loading AudioWorklet module:', {
                url: audioProcessorUrl,
                method: urlBuildMethod,
                currentLocation: window.location?.href,
                isElectron: typeof window !== 'undefined' && !!window.electronAPI
            });
            
            // æ·»åŠ é‡è¯•æœºåˆ¶åŠ è½½AudioWorkletæ¨¡å—
            let retryCount = 0;
            const maxRetries = 5; // å¢åŠ é‡è¯•æ¬¡æ•°
            
            while (retryCount < maxRetries) {
                try {
                    await this.audioContext.audioWorklet.addModule(audioProcessorUrl);
                    console.log('âœ… AudioWorklet module loaded successfully on attempt', retryCount + 1);
                    break;
                } catch (moduleError) {
                    retryCount++;
                    console.warn(`âš ï¸ AudioWorklet module load attempt ${retryCount}/${maxRetries} failed:`, {
                        error: moduleError.message,
                        name: moduleError.name,
                        url: audioProcessorUrl,
                        audioContextState: this.audioContext.state
                    });
                    
                    if (retryCount >= maxRetries) {
                        console.error('âŒ All AudioWorklet attempts failed, will try ScriptProcessor fallback');
                        throw new Error(`Failed to load AudioWorklet module after ${maxRetries} attempts: ${moduleError.message}`);
                    }
                    
                    // ç­‰å¾…é€’å¢çš„æ—¶é—´åé‡è¯•
                    const waitTime = 200 * retryCount;
                    console.log(`â³ Waiting ${waitTime}ms before retry...`);
                    await new Promise(resolve => setTimeout(resolve, waitTime));
                }
            }
            
            console.log('ğŸ”§ Creating AudioWorkletNode...');
            this.workletNode = new AudioWorkletNode(this.audioContext, 'pcm-processor');

            // Create appropriate source node based on source type
            if (this.sourceType === 'microphone') {
                this.sourceNode = this.audioContext.createMediaStreamSource(this.micStream);
                console.log('ğŸ“± Created MediaStreamSource for microphone');
            } else if (this.sourceType === 'media') {
                this.sourceNode = this.audioContext.createMediaElementSource(this.mediaElement);
                console.log('ğŸµ Created MediaElementSource for media file');
            }
            
            this.sourceNode.connect(this.workletNode);
            this.workletNode.connect(this.audioContext.destination);
            
            console.log('ğŸ” Audio connection debug:', {
                sourceType: this.sourceType,
                hasSourceNode: !!this.sourceNode,
                hasWorkletNode: !!this.workletNode,
                hasDestination: !!this.audioContext.destination
            });
            
            // æ·»åŠ ç›´æ¥è¿æ¥ï¼Œç¡®ä¿ç”¨æˆ·èƒ½å¬åˆ°éŸ³é¢‘ï¼ˆç‰¹åˆ«æ˜¯å¯¹äºåª’ä½“æ–‡ä»¶ï¼‰
            if (this.sourceType === 'media') {
                this.sourceNode.connect(this.audioContext.destination);
                console.log('ğŸ”Š Added direct audio connection for media playback');
            } else {
                console.log('ğŸµ Source type is not media, skipping direct connection. Source type:', this.sourceType);
            }

            const resampleRatio = this.config.targetSampleRate / this.audioContext.sampleRate;
            // ä½¿ç”¨å…¨å±€å»¶è¿Ÿå€æ•°ï¼ˆä¸ä¼ ç»Ÿæµè§ˆå™¨æ–¹å¼ä¿æŒä¸€è‡´ï¼‰
            const currentLatencyMultiplier = (typeof window !== 'undefined' && window.currentLatencyMultiplier) ? window.currentLatencyMultiplier : 2;
            const targetChunkSize = this.config.baseChunkSize * currentLatencyMultiplier;
            console.log(`ğŸ¯ AudioWorklet using latency multiplier: ${currentLatencyMultiplier}x, target chunk size: ${targetChunkSize}`);

            // æ·»åŠ æœ¬åœ°ç¼“å†²åŒºæ¥æ¨¡æ‹ŸScriptProcessorçš„è¡Œä¸º
            let localAudioBuffer = new Float32Array();
            const SCRIPT_PROCESSOR_BUFFER_SIZE = 4096; // ä¸ä¼ ç»Ÿæµè§ˆå™¨æ–¹å¼ä¿æŒä¸€è‡´

            this.workletNode.port.onmessage = (event) => {
                if (!this.isProcessing || !event.data) return;

                const input = event.data;
                
                // éŸ³é¢‘æ´»åŠ¨æ£€æµ‹ï¼ˆä¸ä¼ ç»Ÿæµè§ˆå™¨æ–¹å¼ä¿æŒä¸€è‡´ï¼‰
                let hasSound = false;
                let volumeSum = 0;
                for (let i = 0; i < input.length; i++) {
                    const volume = Math.abs(input[i]);
                    volumeSum += volume;
                    if (volume > 0.01) {
                        hasSound = true;
                    }
                }
                
                // å¦‚æœæ£€æµ‹åˆ°å£°éŸ³ï¼Œé‡ç½®idle timerï¼ˆä½¿ç”¨èŠ‚æµæœºåˆ¶ï¼‰
                if (hasSound && typeof window !== 'undefined' && window.resetIdleTimer) {
                    const now = Date.now();
                    if (now - this.lastIdleResetTime >= this.config.idleResetThrottleMs) {
                        window.resetIdleTimer();
                        this.lastIdleResetTime = now;
                        console.log('ğŸ”„ Idle timer reset (throttled)');
                    }
                }
                
                // æ›´æ–°éŸ³é‡æŒ‡ç¤ºå™¨ï¼ˆä¸»è¦ç”¨äºéº¦å…‹é£æ¨¡å¼ï¼‰
                if (this.sourceType === 'microphone' && typeof document !== 'undefined') {
                    const volumeLevel = document.getElementById('volumeLevel');
                    if (volumeLevel) {
                        const averageVolume = volumeSum / input.length;
                        const volumePercent = Math.min(100, Math.round(averageVolume * 1000));
                        volumeLevel.style.width = volumePercent + '%';
                    }
                }
                
                // å°†æ–°æ•°æ®æ·»åŠ åˆ°æœ¬åœ°ç¼“å†²åŒº
                const newLocalBuffer = new Float32Array(localAudioBuffer.length + input.length);
                newLocalBuffer.set(localAudioBuffer);
                newLocalBuffer.set(input, localAudioBuffer.length);
                localAudioBuffer = newLocalBuffer;

                // å½“æœ¬åœ°ç¼“å†²åŒºè¾¾åˆ°ScriptProcessorçš„å¤§å°æ—¶æ‰å¤„ç†
                while (localAudioBuffer.length >= SCRIPT_PROCESSOR_BUFFER_SIZE) {
                    const processingChunk = localAudioBuffer.slice(0, SCRIPT_PROCESSOR_BUFFER_SIZE);
                    localAudioBuffer = localAudioBuffer.slice(SCRIPT_PROCESSOR_BUFFER_SIZE);

                    // ä¿æŒä¸ä¼ ç»Ÿæµè§ˆå™¨æ–¹å¼ä¸€è‡´ï¼Œå¤„ç†æ‰€æœ‰éŸ³é¢‘æ•°æ®

                    // é‡é‡‡æ ·å¤„ç†ï¼ˆä¸ä¼ ç»Ÿæµè§ˆå™¨æ–¹å¼å®Œå…¨ä¸€è‡´ï¼‰
                    const resampledLength = Math.floor(processingChunk.length * resampleRatio);
                    const resampledChunk = new Float32Array(resampledLength);
                    for (let i = 0; i < resampledLength; i++) {
                        const originalIndex = Math.floor(i / resampleRatio);
                        resampledChunk[i] = processingChunk[originalIndex];
                    }

                    const newBuffer = new Float32Array(this.resampledBuffer.length + resampledChunk.length);
                    newBuffer.set(this.resampledBuffer);
                    newBuffer.set(resampledChunk, this.resampledBuffer.length);
                    this.resampledBuffer = newBuffer;

                    while (this.resampledBuffer.length >= targetChunkSize) {
                        const chunk = this.resampledBuffer.slice(0, targetChunkSize);
                        try {
                            if (this.ws && this.ws.readyState === WebSocket.OPEN) {
                                this.ws.send(chunk.buffer);
                                this.chunksSentCount++;
                                if (this.chunksSentCount % 5 === 0) {
                                    console.log(`âœ… Sent chunk #${this.chunksSentCount} (${chunk.byteLength} bytes) [BufferMode]`);
                                }
                            }
                        } catch (err) {
                            this.handleError('send_chunk', err);
                        }
                        this.resampledBuffer = this.resampledBuffer.slice(targetChunkSize);
                    }
                }
            };

            console.log('ğŸ‰ AudioWorkletNode processor initialized!');
            return true;
        } catch (error) {
            console.error('âŒ Error initializing AudioWorklet processor:', error);
            console.log('ğŸ”„ Attempting fallback to ScriptProcessor...');
            
            try {
                return await this.initializeWithScriptProcessor(this.audioSource, websocket, this.sourceType);
            } catch (fallbackError) {
                console.error('âŒ Fallback ScriptProcessor also failed:', fallbackError);
                this.cleanup();
                throw new Error(`Both AudioWorklet and ScriptProcessor failed. AudioWorklet: ${error.message}, ScriptProcessor: ${fallbackError.message}`);
            }
        }
    }

    async initializeWithScriptProcessor(audioSource, websocket, sourceType = 'microphone') {
        console.log('ğŸ”§ Initializing with ScriptProcessor fallback for', sourceType, '...');
        console.warn('âš ï¸ Using deprecated ScriptProcessor because AudioWorklet failed to load');
        
        try {
            // æ¸…ç†ä¹‹å‰çš„AudioContext
            if (this.audioContext) {
                try {
                    await this.audioContext.close();
                } catch (e) {
                    console.warn('âš ï¸ Error closing previous AudioContext:', e);
                }
            }
            
            if (sourceType === 'microphone') {
                this.micStream = audioSource;
            } else if (sourceType === 'media') {
                this.mediaElement = audioSource;
            }
            this.audioSource = audioSource;
            this.sourceType = sourceType;
            this.ws = websocket;
            this.isProcessing = true;
            this.errorCount = 0;
            this.chunksSentCount = 0;
            this.resampledBuffer = new Float32Array();

            // åˆ›å»ºæ–°çš„AudioContext
            this.audioContext = new AudioContext({ sampleRate: 48000 });
            console.log('ğŸ™ï¸ AudioContext created for ScriptProcessor, state:', this.audioContext.state);
            
            if (this.audioContext.state === 'suspended') {
                await this.audioContext.resume();
            }

            // ä½¿ç”¨ScriptProcessorä»£æ›¿AudioWorklet
            const scriptProcessor = this.audioContext.createScriptProcessor(4096, 1, 1);
            this.workletNode = scriptProcessor; // ä¿æŒæ¥å£ä¸€è‡´æ€§
            
            // Create appropriate source node based on source type
            if (this.sourceType === 'microphone') {
                this.sourceNode = this.audioContext.createMediaStreamSource(this.micStream);
                console.log('ğŸ“± Created MediaStreamSource for microphone [ScriptProcessor]');
            } else if (this.sourceType === 'media') {
                this.sourceNode = this.audioContext.createMediaElementSource(this.mediaElement);
                console.log('ğŸµ Created MediaElementSource for media file [ScriptProcessor]');
            }
            
            this.sourceNode.connect(scriptProcessor);
            scriptProcessor.connect(this.audioContext.destination);
            
            console.log('ğŸ” Audio connection debug [ScriptProcessor]:', {
                sourceType: this.sourceType,
                hasSourceNode: !!this.sourceNode,
                hasScriptProcessor: !!scriptProcessor,
                hasDestination: !!this.audioContext.destination
            });
            
            // æ·»åŠ ç›´æ¥è¿æ¥ï¼Œç¡®ä¿ç”¨æˆ·èƒ½å¬åˆ°éŸ³é¢‘ï¼ˆç‰¹åˆ«æ˜¯å¯¹äºåª’ä½“æ–‡ä»¶ï¼‰
            if (this.sourceType === 'media') {
                this.sourceNode.connect(this.audioContext.destination);
                console.log('ğŸ”Š Added direct audio connection for media playback [ScriptProcessor]');
            } else {
                console.log('ğŸµ Source type is not media, skipping direct connection [ScriptProcessor]. Source type:', this.sourceType);
            }

            const resampleRatio = this.config.targetSampleRate / this.audioContext.sampleRate;
            // ä½¿ç”¨å…¨å±€å»¶è¿Ÿå€æ•°ï¼ˆä¸ä¼ ç»Ÿæµè§ˆå™¨æ–¹å¼ä¿æŒä¸€è‡´ï¼‰
            const currentLatencyMultiplier = (typeof window !== 'undefined' && window.currentLatencyMultiplier) ? window.currentLatencyMultiplier : 2;
            const targetChunkSize = this.config.baseChunkSize * currentLatencyMultiplier;
            console.log(`ğŸ¯ ScriptProcessor using latency multiplier: ${currentLatencyMultiplier}x, target chunk size: ${targetChunkSize}`);

            // ScriptProcessorä½¿ç”¨onaudioprocessè€Œä¸æ˜¯port.onmessage
            scriptProcessor.onaudioprocess = (event) => {
                if (!this.isProcessing) return;

                const inputData = event.inputBuffer.getChannelData(0);
                
                // éŸ³é¢‘æ´»åŠ¨æ£€æµ‹ï¼ˆä¸ä¼ ç»Ÿæµè§ˆå™¨æ–¹å¼ä¿æŒä¸€è‡´ï¼‰
                let hasSound = false;
                let volumeSum = 0;
                for (let i = 0; i < inputData.length; i++) {
                    const volume = Math.abs(inputData[i]);
                    volumeSum += volume;
                    if (volume > 0.01) {
                        hasSound = true;
                    }
                }
                
                // å¦‚æœæ£€æµ‹åˆ°å£°éŸ³ï¼Œé‡ç½®idle timerï¼ˆä½¿ç”¨èŠ‚æµæœºåˆ¶ï¼‰
                if (hasSound && typeof window !== 'undefined' && window.resetIdleTimer) {
                    const now = Date.now();
                    if (now - this.lastIdleResetTime >= this.config.idleResetThrottleMs) {
                        window.resetIdleTimer();
                        this.lastIdleResetTime = now;
                        console.log('ğŸ”„ Idle timer reset (throttled)');
                    }
                }
                
                // æ›´æ–°éŸ³é‡æŒ‡ç¤ºå™¨ï¼ˆä¸»è¦ç”¨äºéº¦å…‹é£æ¨¡å¼ï¼‰
                if (this.sourceType === 'microphone' && typeof document !== 'undefined') {
                    const volumeLevel = document.getElementById('volumeLevel');
                    if (volumeLevel) {
                        const averageVolume = volumeSum / inputData.length;
                        const volumePercent = Math.min(100, Math.round(averageVolume * 1000));
                        volumeLevel.style.width = volumePercent + '%';
                    }
                }
                
                // é‡é‡‡æ ·é€»è¾‘ä¸AudioWorkletç›¸åŒ
                const resampledLength = Math.floor(inputData.length * resampleRatio);
                const resampledChunk = new Float32Array(resampledLength);
                for (let i = 0; i < resampledLength; i++) {
                    const originalIndex = Math.floor(i / resampleRatio);
                    resampledChunk[i] = inputData[originalIndex];
                }

                const newBuffer = new Float32Array(this.resampledBuffer.length + resampledChunk.length);
                newBuffer.set(this.resampledBuffer);
                newBuffer.set(resampledChunk, this.resampledBuffer.length);
                this.resampledBuffer = newBuffer;

                while (this.resampledBuffer.length >= targetChunkSize) {
                    const chunk = this.resampledBuffer.slice(0, targetChunkSize);
                    try {
                        if (this.ws && this.ws.readyState === WebSocket.OPEN) {
                            this.ws.send(chunk.buffer);
                            this.chunksSentCount++;
                            if (this.chunksSentCount % 5 === 0) {
                                console.log(`âœ… Sent chunk #${this.chunksSentCount} (${chunk.byteLength} bytes) via ScriptProcessor`);
                            }
                        }
                    } catch (err) {
                        this.handleError('send_chunk', err);
                    }
                    this.resampledBuffer = this.resampledBuffer.slice(targetChunkSize);
                }
            };

            console.log('ğŸ‰ ScriptProcessor fallback initialized successfully!');
            return true;
        } catch (error) {
            console.error('âŒ Error initializing ScriptProcessor fallback:', error);
            this.cleanup();
            throw error;
        }
    }

    handleError(source, error) {
        this.errorCount++;
        console.error(`âŒ Error in ${source} (#${this.errorCount}):`, error);
        if (this.errorCount >= this.config.maxErrorCount) {
            console.error(`ğŸš¨ Too many errors (${this.errorCount}), stopping audio processor`);
            this.stop();
            if (typeof window !== 'undefined' && window.updateStatus) {
                window.updateStatus('Audio processing failed due to too many errors', 'error');
            }
        }
    }

    stop() {
        console.log('ğŸ›‘ Stopping Electron audio processor...');
        this.isProcessing = false;

        if (this.resampledBuffer && this.resampledBuffer.length > 0) {
            const currentLatencyMultiplier = (typeof window !== 'undefined' && window.currentLatencyMultiplier) ? window.currentLatencyMultiplier : 2;
            const finalChunkSize = this.config.baseChunkSize * currentLatencyMultiplier;
            const finalChunk = new Float32Array(finalChunkSize);
            finalChunk.set(this.resampledBuffer.slice(0, finalChunkSize));
            if (this.ws && this.ws.readyState === WebSocket.OPEN) {
                this.ws.send(finalChunk.buffer);
                console.log(`âœ… Sent final partial chunk (${finalChunk.byteLength} bytes)`);
            }
        }

        this.cleanup();
        console.log('âœ… Electron audio processor stopped');
    }

    cleanup() {
        console.log('ğŸ§¹ Cleaning up audio processor resources...');
        this.ws = null;
        this.micStream = null;
        this.mediaElement = null;
        this.audioSource = null;
        this.sourceType = null;

        if (this.sourceNode) {
            try { this.sourceNode.disconnect(); } catch (e) {}
            this.sourceNode = null;
        }
        if (this.workletNode) {
            try { this.workletNode.disconnect(); } catch (e) {}
            this.workletNode = null;
        }
        if (this.audioContext) {
            try { this.audioContext.close(); } catch (e) {}
            this.audioContext = null;
        }

        console.log('âœ… Audio processor cleanup completed');
    }
}

window.ElectronAudioProcessor = ElectronAudioProcessor;
console.log('ğŸµ ElectronAudioProcessor with AudioWorklet loaded globally');