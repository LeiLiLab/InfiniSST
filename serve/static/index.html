<!DOCTYPE html>
<html>
<head>
    <title>Simultaneous Speech Translation</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
        }
        .container {
            display: flex;
            flex-direction: column;
            gap: 20px;
        }
        .panel {
            padding: 20px;
            border: 1px solid #ccc;
            border-radius: 5px;
        }
        .controls {
            margin-bottom: 20px;
        }
        select, button {
            margin: 5px;
            padding: 5px 10px;
        }
        .button-group {
            display: flex;
            gap: 10px;
            margin-top: 10px;
        }
        #translationOutput {
            height: 200px;
            padding: 10px;
            border: 1px solid #ddd;
            border-radius: 5px;
            white-space: pre-wrap;
            overflow-y: auto;
            background-color: #f9f9f9;
            font-size: 16px;
            line-height: 1.5;
        }
        .status {
            margin-top: 10px;
            padding: 5px;
            border-radius: 3px;
        }
        .success { background-color: #dff0d8; }
        .error { background-color: #f2dede; }
        .settings-panel {
            background-color: #f8f9fa;
            padding: 10px;
            border-radius: 5px;
            margin-bottom: 15px;
        }
        h2 {
            margin-top: 0;
            border-bottom: 1px solid #eee;
            padding-bottom: 10px;
        }
        .input-options {
            margin-bottom: 15px;
        }
        .input-option {
            margin-bottom: 10px;
        }
        .mic-button {
            margin-right: 10px;
            margin-top: 10px;
        }
        .mic-status {
            margin-top: 10px;
            font-style: italic;
            color: #666;
        }
        .volume-indicator {
            margin-top: 10px;
            height: 20px;
            background-color: #f0f0f0;
            border-radius: 10px;
            overflow: hidden;
            position: relative;
        }
        .volume-level {
            height: 100%;
            width: 0%;
            background-color: #4CAF50;
            transition: width 0.1s ease;
        }
        .volume-text {
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            text-align: center;
            line-height: 20px;
            color: #333;
            font-size: 12px;
        }
    </style>
</head>
<body>
    <h1>Simultaneous Speech Translation</h1>
    
    <div class="controls">
        <select id="agentType">
            <option value="InfiniSST">InfiniSST</option>
            <!-- 暂时禁用StreamAtt
            <option value="StreamAtt">StreamAtt</option>
            -->
        </select>
        
        <select id="languagePair">
            <option value="English -> Chinese">English -> Chinese</option>
            <option value="English -> German">English -> German</option>
            <option value="English -> Spanish">English -> Spanish</option>
        </select>
        
        <button id="loadModel">Load Model</button>
    </div>
    
    <div class="controls">
        <select id="latencyMultiplier">
            <option value="1">Latency: 1x (Fastest)</option>
            <option value="2" selected>Latency: 2x (Default)</option>
            <option value="3">Latency: 3x (More Accurate)</option>
            <option value="4">Latency: 4x (Most Accurate)</option>
        </select>
        
        <button id="updateLatency" disabled>Update Latency</button>
    </div>

    <div class="container">
        <div class="panel">
            <h2>Model Status</h2>
            <div id="currentSettings" class="settings-panel"></div>
            <div id="audioStatus" class="status"></div>
        </div>
        
        <div class="panel">
            <h2>Audio Input</h2>
            <div class="input-options">
                <div class="input-option">
                    <label><input type="radio" name="audioSource" value="file" checked> File Upload</label>
                    <div id="fileInputContainer">
                        <input type="file" id="audioFile" accept="audio/*" />
                        <audio id="audioPlayer" controls style="width: 100%; margin-top: 10px;"></audio>
                    </div>
                </div>
                <div class="input-option">
                    <label><input type="radio" name="audioSource" value="mic"> Microphone</label>
                    <div id="micInputContainer" style="display: none;">
                        <button id="toggleMic" class="mic-button">Start Microphone</button>
                        <div id="micStatus" class="mic-status"></div>
                        <div class="volume-indicator">
                            <div id="volumeLevel" class="volume-level"></div>
                            <div class="volume-text">Microphone Level</div>
                        </div>
                    </div>
                </div>
            </div>
            <div class="button-group">
                <button id="resetTranslation" disabled>Reset</button>
            </div>
        </div>
        
        <div class="panel">
            <h2>Translation Output</h2>
            <div id="translationOutput"></div>
        </div>
    </div>

    <script>
        let ws = null;
        let sessionId = null;
        let audioContext = null;
        let audioSource = null;
        let processor = null;
        const segmentSize = 4096;  // 使用较大的buffer size以减少处理次数
        const targetSampleRate = 16000;
        const baseChunkSize = 960 * 16;  // 基础块大小
        let currentLatencyMultiplier = 2; // 默认延迟倍数
        let audioBuffer = new Float32Array();
        let resampledBuffer = new Float32Array();
        let firstChunkSent = false; // 添加标志，跟踪是否已发送第一个数据块
        let translationPaused = true; // 初始设置为暂停状态，等待用户点击播放
        
        // 添加预缓冲延迟配置
        const PRE_BUFFER_DELAY_MS = 300; // 预缓冲延迟，毫秒
        
        // UI Elements
        const agentType = document.getElementById('agentType');
        const languagePair = document.getElementById('languagePair');
        const latencyMultiplier = document.getElementById('latencyMultiplier');
        const loadModel = document.getElementById('loadModel');
        const updateLatency = document.getElementById('updateLatency');
        const audioFile = document.getElementById('audioFile');
        const audioPlayer = document.getElementById('audioPlayer');
        const resetTranslation = document.getElementById('resetTranslation');
        const translationOutput = document.getElementById('translationOutput');
        const audioStatus = document.getElementById('audioStatus');
        const currentSettings = document.getElementById('currentSettings');
        const audioSourceRadios = document.getElementsByName('audioSource');
        const fileInputContainer = document.getElementById('fileInputContainer');
        const micInputContainer = document.getElementById('micInputContainer');
        const toggleMic = document.getElementById('toggleMic');
        const micStatus = document.getElementById('micStatus');
        const volumeLevel = document.getElementById('volumeLevel');
        
        // 翻译系统状态
        let translationInitialized = false;

        // 麦克风相关变量
        let micStream = null;
        let micRecorder = null;
        let isMicRecording = false;

        // 函数：滚动翻译输出框到底部，显示最新内容
        function scrollTranslationToBottom() {
            translationOutput.scrollTop = translationOutput.scrollHeight;
        }

        // 清理音频和WebSocket资源
        function cleanupAudioResources() {
            // 关闭WebSocket连接
            if (ws) {
                try {
                    if (ws.readyState === WebSocket.OPEN) {
                        ws.close();
                    }
                } catch (e) {
                    console.error('Error closing WebSocket:', e);
                }
                ws = null;
            }
            
            // 停止麦克风流
            if (micStream) {
                micStream.getTracks().forEach(track => {
                    track.stop();
                    console.log('Microphone track stopped');
                });
                micStream = null;
            }
            
            // 断开并清理音频处理节点
            if (processor) {
                try {
                    processor.disconnect();
                } catch (e) {
                    console.error('Error disconnecting processor:', e);
                }
                processor = null;
            }
            
            if (audioSource) {
                try {
                    audioSource.disconnect();
                } catch (e) {
                    console.error('Error disconnecting audio source:', e);
                }
                audioSource = null;
            }
            
            // 关闭音频上下文
            if (audioContext) {
                try {
                    if (audioContext.state !== 'closed') {
                        audioContext.close().catch(e => {
                            console.error('Error closing audio context:', e);
                        });
                    }
                } catch (e) {
                    console.error('Error in audio context cleanup:', e);
                }
                audioContext = null;
            }
            
            // Reset buffers
            resampledBuffer = new Float32Array();
            audioBuffer = new Float32Array();
            firstChunkSent = false;
            
            // 重置麦克风状态
            if (isMicRecording) {
                isMicRecording = false;
                toggleMic.textContent = 'Start Microphone';
                micStatus.textContent = '';
            }
        }

        // 清理会话资源
        async function cleanupSession() {
            try {
                // 如果麦克风正在录制，停止它（传入false表示不是手动暂停）
                if (isMicRecording) {
                    stopMicrophone(false);
                } else {
                    // 确保音量指示器被重置，即使麦克风没有在录制
                    volumeLevel.style.width = '0%';
                }
                
                // 清空麦克风状态消息
                micStatus.textContent = '';
                
                // 停止当前的音频播放
                if (audioPlayer) {
                    audioPlayer.pause();
                    audioPlayer.currentTime = 0;
                    // 不清除音频源，允许用户在加载新模型后继续使用相同的音频文件
                }
                
                // 不重置文件输入，允许用户在加载新模型后继续使用相同的音频文件
                
                // 清理音频和WebSocket资源
                cleanupAudioResources();
                
                // 删除后端会话
                if (sessionId) {
                    try {
                        const response = await fetch('/delete_session?' + new URLSearchParams({
                            session_id: sessionId
                        }), {
                            method: 'POST'
                        });
                        
                        const data = await response.json();
                        if (!data.success) {
                            console.error('Failed to delete session:', data.error);
                        }
                    } catch (e) {
                        console.error('Error deleting session:', e);
                    }
                    
                    // 清空会话ID
                    sessionId = null;
                }
                
                // 清空翻译输出
                translationOutput.textContent = '';
                
                // 重置UI状态
                updateLatency.disabled = true;
                resetTranslation.disabled = true;
                toggleMic.textContent = 'Start Microphone';
                
            } catch (error) {
                console.error('Error cleaning up session:', error);
            }
        }

        loadModel.addEventListener('click', async () => {
            try {
                // 清理现有会话和资源
                await cleanupSession();
                
                // 显示加载状态
                audioStatus.textContent = 'Loading model...';
                audioStatus.className = 'status';
                
                currentLatencyMultiplier = parseInt(latencyMultiplier.value);
                const response = await fetch('/init?' + new URLSearchParams({
                    agent_type: agentType.value,
                    language_pair: languagePair.value,
                    latency_multiplier: currentLatencyMultiplier
                }), {
                    method: 'POST'
                });
                
                const data = await response.json();
                sessionId = data.session_id;
                
                // 重置翻译初始化状态
                translationInitialized = false;
                
                // 启用重置按钮
                updateLatency.disabled = false;
                resetTranslation.disabled = false;
                audioStatus.textContent = 'Model loaded successfully. Upload audio and press play to start translation.';
                audioStatus.className = 'status success';
                
                updateSettingsDisplay();
            } catch (error) {
                audioStatus.textContent = 'Error loading model: ' + error;
                audioStatus.className = 'status error';
            }
        });

        audioFile.addEventListener('change', (event) => {
            const file = event.target.files[0];
            if (file) {
                audioPlayer.src = URL.createObjectURL(file);
                // 重置翻译初始化状态，因为新的音频文件被上传
                translationInitialized = false;
                audioStatus.textContent = 'Audio loaded. Press play to start translation.';
                audioStatus.className = 'status success';
            }
        });
        
        // 初始化翻译系统
        async function initializeTranslation() {
            if (!sessionId || translationInitialized) return;
            
            try {
                // Clear previous translation
                translationOutput.textContent = '';
                translationPaused = false; // 设置为播放状态，因为用户点击了播放按钮
                
                // Initialize WebSocket connection
                ws = new WebSocket(`ws://${window.location.host}/ws/${sessionId}`);
                
                ws.onmessage = (event) => {
                    // 只有在未暂停状态下才更新翻译
                    if (!translationPaused) {
                        translationOutput.textContent = event.data;
                        // 自动滚动到底部，显示最新翻译内容
                        scrollTranslationToBottom();
                    }
                };
                
                ws.onerror = (error) => {
                    audioStatus.textContent = 'WebSocket error: ' + error;
                    audioStatus.className = 'status error';
                };
                
                return new Promise((resolve, reject) => {
                    ws.onopen = async () => {
                        try {
                            // Initialize audio processing
                            audioContext = new AudioContext();
                            audioSource = audioContext.createMediaElementSource(audioPlayer);
                            
                            // 创建重采样节点
                            const originalSampleRate = audioContext.sampleRate;
                            const resampleRatio = targetSampleRate / originalSampleRate;
                            
                            // 创建ScriptProcessor节点
                            processor = audioContext.createScriptProcessor(segmentSize, 1, 1);
                            
                            processor.onaudioprocess = (e) => {
                                // 只有在未暂停状态下才处理音频
                                if (ws && ws.readyState === WebSocket.OPEN && !translationPaused) {
                                    const inputData = e.inputBuffer.getChannelData(0);
                                    
                                    // 对输入数据进行重采样
                                    const resampledLength = Math.floor(inputData.length * resampleRatio);
                                    const resampledChunk = new Float32Array(resampledLength);
                                    
                                    for (let i = 0; i < resampledLength; i++) {
                                        const originalIndex = Math.floor(i / resampleRatio);
                                        resampledChunk[i] = inputData[originalIndex];
                                    }
                                    
                                    // 将重采样后的数据添加到缓冲区
                                    const newBuffer = new Float32Array(resampledBuffer.length + resampledChunk.length);
                                    newBuffer.set(resampledBuffer);
                                    newBuffer.set(resampledChunk, resampledBuffer.length);
                                    resampledBuffer = newBuffer;
                                    
                                    // 计算当前的目标块大小
                                    const targetChunkSize = baseChunkSize * currentLatencyMultiplier;
                                    
                                    // 当缓冲区达到目标大小时发送数据
                                    while (resampledBuffer.length >= targetChunkSize) {
                                        const chunk = resampledBuffer.slice(0, targetChunkSize);
                                        ws.send(chunk.buffer);
                                        resampledBuffer = resampledBuffer.slice(targetChunkSize);
                                    }
                                }
                            };
                            
                            // 连接节点
                            audioSource.connect(processor);
                            processor.connect(audioContext.destination);
                            audioSource.connect(audioContext.destination);
                            
                            // 标记翻译系统已初始化
                            translationInitialized = true;
                            audioStatus.textContent = 'Playing and translating...';
                            audioStatus.className = 'status success';
                            
                            // 设置音频结束事件
                            audioPlayer.onended = () => {
                                // 发送剩余的数据（如果有的话）
                                if (resampledBuffer.length > 0) {
                                    // 计算当前的目标块大小
                                    const targetChunkSize = baseChunkSize * currentLatencyMultiplier;
                                    
                                    // 用0填充最后一个块至目标大小
                                    const finalChunk = new Float32Array(targetChunkSize);
                                    finalChunk.set(resampledBuffer);
                                    ws.send(finalChunk.buffer);
                                }
                                
                                if (ws) ws.close();
                                if (processor) {
                                    processor.disconnect();
                                    audioSource.disconnect();
                                }
                                if (audioContext) {
                                    audioContext.close();
                                }
                                audioStatus.textContent = 'Translation completed';
                                audioStatus.className = 'status success';
                                translationInitialized = false;
                            };
                            
                            resolve();
                        } catch (error) {
                            console.error('Error:', error);
                            audioStatus.textContent = 'Error initializing audio: ' + error;
                            audioStatus.className = 'status error';
                            if (ws) ws.close();
                            translationInitialized = false;
                            reject(error);
                        }
                    };
                });
            } catch (error) {
                audioStatus.textContent = 'Error: ' + error;
                audioStatus.className = 'status error';
                translationInitialized = false;
                throw error;
            }
        }

        // 添加音频播放器事件监听器
        audioPlayer.addEventListener('play', async () => {
            // 如果翻译系统尚未初始化，则初始化
            if (!translationInitialized && sessionId) {
                try {
                    // 暂停音频，等待翻译系统初始化
                    audioPlayer.pause();
                    audioStatus.textContent = 'Initializing translation system...';
                    audioStatus.className = 'status';
                    
                    // 初始化翻译系统
                    await initializeTranslation();
                    
                    // 恢复播放
                    audioPlayer.play().catch(e => {
                        console.error('Error playing audio:', e);
                        audioStatus.textContent = 'Error playing audio: ' + e;
                        audioStatus.className = 'status error';
                    });
                } catch (error) {
                    console.error('Error initializing translation:', error);
                    audioStatus.textContent = 'Error initializing translation: ' + error;
                    audioStatus.className = 'status error';
                }
            } else if (translationInitialized) {
                // 翻译系统已初始化，只需恢复翻译
                translationPaused = false;
                audioStatus.textContent = 'Playing and translating...';
                audioStatus.className = 'status success';
                
                // 恢复音频上下文
                if (audioContext && audioContext.state === 'suspended') {
                    audioContext.resume().catch(e => {
                        console.error('Error resuming audio context:', e);
                    });
                }
            }
        });
        
        audioPlayer.addEventListener('pause', () => {
            if (translationInitialized) {
                translationPaused = true;
                audioStatus.textContent = 'Translation paused';
                audioStatus.className = 'status';
                
                // 暂停音频上下文
                if (audioContext && audioContext.state === 'running') {
                    audioContext.suspend().catch(e => {
                        console.error('Error suspending audio context:', e);
                    });
                }
            }
        });

        // 切换音频输入源
        audioSourceRadios.forEach(radio => {
            radio.addEventListener('change', (event) => {
                const source = event.target.value;
                if (source === 'file') {
                    fileInputContainer.style.display = 'block';
                    micInputContainer.style.display = 'none';
                    // 如果麦克风正在录制，停止它（传入false表示不是手动暂停）
                    if (isMicRecording) {
                        stopMicrophone(false);
                    }
                } else if (source === 'mic') {
                    fileInputContainer.style.display = 'none';
                    micInputContainer.style.display = 'block';
                    // 如果有音频正在播放，暂停它
                    if (audioPlayer) {
                        audioPlayer.pause();
                    }
                }
            });
        });

        // 切换麦克风录制状态
        toggleMic.addEventListener('click', async () => {
            if (isMicRecording) {
                // 用户手动暂停，显示暂停消息
                stopMicrophone(true); // true表示是手动暂停
            } else {
                startMicrophone();
            }
        });

        // 开始麦克风录制
        async function startMicrophone() {
            if (!sessionId) {
                micStatus.textContent = 'Please load a model first';
                return;
            }
            
            try {
                // 不再清空翻译输出，保留之前的结果
                // translationOutput.textContent = '';
                
                // 请求麦克风权限
                micStream = await navigator.mediaDevices.getUserMedia({ audio: true });
                
                // 初始化WebSocket连接
                ws = new WebSocket(`ws://${window.location.host}/ws/${sessionId}`);
                
                ws.onmessage = (event) => {
                    translationOutput.textContent = event.data;
                    scrollTranslationToBottom();
                };
                
                ws.onerror = (error) => {
                    micStatus.textContent = 'WebSocket error: ' + error;
                    stopMicrophone();
                };
                
                ws.onopen = () => {
                    // 创建音频上下文
                    audioContext = new AudioContext();
                    const micSource = audioContext.createMediaStreamSource(micStream);
                    
                    // 创建处理节点
                    processor = audioContext.createScriptProcessor(4096, 1, 1);
                    
                    // 重采样率计算
                    const originalSampleRate = audioContext.sampleRate;
                    const resampleRatio = targetSampleRate / originalSampleRate;
                    
                    console.log('Microphone sample rate:', originalSampleRate);
                    console.log('Target sample rate:', targetSampleRate);
                    console.log('Resample ratio:', resampleRatio);
                    
                    processor.onaudioprocess = (e) => {
                        if (ws && ws.readyState === WebSocket.OPEN) {
                            const inputData = e.inputBuffer.getChannelData(0);
                            
                            // 检查音频数据是否有声音
                            let hasSound = false;
                            let volumeSum = 0;
                            for (let i = 0; i < inputData.length; i++) {
                                const volume = Math.abs(inputData[i]);
                                volumeSum += volume;
                                if (volume > 0.01) {
                                    hasSound = true;
                                }
                            }
                            
                            // 计算平均音量并更新音量指示器
                            const averageVolume = volumeSum / inputData.length;
                            const volumePercent = Math.min(100, Math.round(averageVolume * 1000));
                            volumeLevel.style.width = volumePercent + '%';
                            
                            if (!hasSound) {
                                console.log('No sound detected in microphone input');
                            } else {
                                console.log('Sound detected in microphone input');
                            }
                            
                            // 对输入数据进行重采样
                            const resampledLength = Math.floor(inputData.length * resampleRatio);
                            const resampledChunk = new Float32Array(resampledLength);
                            
                            for (let i = 0; i < resampledLength; i++) {
                                const originalIndex = Math.floor(i / resampleRatio);
                                resampledChunk[i] = inputData[originalIndex];
                            }
                            
                            // 将重采样后的数据添加到缓冲区
                            const newBuffer = new Float32Array(resampledBuffer.length + resampledChunk.length);
                            newBuffer.set(resampledBuffer);
                            newBuffer.set(resampledChunk, resampledBuffer.length);
                            resampledBuffer = newBuffer;
                            
                            // 计算当前的目标块大小
                            const targetChunkSize = baseChunkSize * currentLatencyMultiplier;
                            
                            // 当缓冲区达到目标大小时发送数据
                            while (resampledBuffer.length >= targetChunkSize) {
                                const chunk = resampledBuffer.slice(0, targetChunkSize);
                                try {
                                    ws.send(chunk.buffer);
                                    console.log(`Sent audio chunk of size ${chunk.length} to server`);
                                } catch (error) {
                                    console.error('Error sending audio data:', error);
                                }
                                resampledBuffer = resampledBuffer.slice(targetChunkSize);
                            }
                        }
                    };
                    
                    // 连接节点
                    micSource.connect(processor);
                    processor.connect(audioContext.destination);
                    
                    // 设置translationPaused为false，确保翻译处理正常进行
                    translationPaused = false;
                    
                    // 更新UI状态
                    toggleMic.textContent = 'Pause Microphone';
                    micStatus.textContent = 'Microphone active. Speaking will be translated in real-time.';
                    isMicRecording = true;
                    audioStatus.textContent = 'Translating from microphone...';
                    audioStatus.className = 'status success';
                    
                    // 发送一个小的静音数据块，以初始化翻译系统
                    const silentChunk = new Float32Array(baseChunkSize * currentLatencyMultiplier);
                    try {
                        ws.send(silentChunk.buffer);
                        console.log('Sent initial silent chunk to server');
                    } catch (error) {
                        console.error('Error sending initial silent chunk:', error);
                    }
                };
            } catch (error) {
                micStatus.textContent = 'Error accessing microphone: ' + error;
                console.error('Microphone error:', error);
            }
        }

        function stopMicrophone(isManualPause = false) {
            // 发送剩余的数据（如果有的话）
            if (ws && ws.readyState === WebSocket.OPEN && resampledBuffer.length > 0) {
                const targetChunkSize = baseChunkSize * currentLatencyMultiplier;
                const finalChunk = new Float32Array(targetChunkSize);
                finalChunk.set(resampledBuffer);
                try {
                    ws.send(finalChunk.buffer);
                    console.log('Sent final audio chunk to server');
                } catch (error) {
                    console.error('Error sending final audio chunk:', error);
                }
            }
            
            // 关闭WebSocket连接
            if (ws) {
                try {
                    if (ws.readyState === WebSocket.OPEN) {
                        ws.close();
                        console.log('WebSocket connection closed');
                    }
                } catch (e) {
                    console.error('Error closing WebSocket:', e);
                }
                ws = null;
            }
            
            // 停止麦克风流
            if (micStream) {
                micStream.getTracks().forEach(track => {
                    track.stop();
                    console.log('Microphone track stopped');
                });
                micStream = null;
            }
            
            // 断开并清理音频处理节点
            if (processor) {
                try {
                    processor.disconnect();
                    console.log('Audio processor disconnected');
                } catch (e) {
                    console.error('Error disconnecting processor:', e);
                }
                processor = null;
            }
            
            // 关闭音频上下文
            if (audioContext) {
                try {
                    if (audioContext.state !== 'closed') {
                        audioContext.close().catch(e => {
                            console.error('Error closing audio context:', e);
                        });
                        console.log('Audio context closed');
                    }
                } catch (e) {
                    console.error('Error in audio context cleanup:', e);
                }
                audioContext = null;
            }
            
            // 重置缓冲区
            resampledBuffer = new Float32Array();
            
            // 重置音量指示器
            volumeLevel.style.width = '0%';
            
            // 更新UI状态
            toggleMic.textContent = 'Start Microphone';
            
            // 只有在手动暂停时才显示暂停消息
            if (isManualPause) {
                micStatus.textContent = 'Microphone paused.';
            } else {
                micStatus.textContent = '';
            }
            
            isMicRecording = false;
            
            // 重置翻译状态
            translationPaused = true;
            translationInitialized = false;
        }

        // 修改重置函数，确保麦克风也被正确停止
        resetTranslation.addEventListener('click', async () => {
            if (!sessionId) return;
            
            try {
                // 如果麦克风正在录制，停止它（传入false表示不是手动暂停）
                if (isMicRecording) {
                    stopMicrophone(false);
                } else {
                    // 确保音量指示器被重置，即使麦克风没有在录制
                    volumeLevel.style.width = '0%';
                    // 清空麦克风状态消息
                    micStatus.textContent = '';
                }
                
                // 停止当前的音频播放
                if (audioPlayer) {
                    audioPlayer.pause();
                    audioPlayer.currentTime = 0;
                    // 清除音频源，强制用户重新上传
                    audioPlayer.src = '';
                }
                
                // 重置文件输入，强制用户重新选择文件
                if (audioFile) {
                    audioFile.value = '';
                }
                
                // 重置音量指示器
                volumeLevel.style.width = '0%';
                
                // 重置翻译初始化状态
                translationInitialized = false;
                
                // 清理音频和WebSocket资源
                cleanupAudioResources();
                
                // 调用后端重置翻译状态
                const response = await fetch('/reset_translation?' + new URLSearchParams({
                    session_id: sessionId
                }), {
                    method: 'POST'
                });
                
                const data = await response.json();
                if (data.success) {
                    // 清空翻译输出
                    translationOutput.textContent = '';
                    audioStatus.textContent = data.message || 'Translation reset successfully. Please select an audio source.';
                    audioStatus.className = 'status success';
                    
                    // 确保按钮状态正确
                    updateLatency.disabled = false;
                } else {
                    audioStatus.textContent = 'Failed to reset translation: ' + data.error;
                    audioStatus.className = 'status error';
                }
            } catch (error) {
                audioStatus.textContent = 'Error resetting translation: ' + error;
                audioStatus.className = 'status error';
            }
        });

        // 更新延迟倍数
        updateLatency.addEventListener('click', async () => {
            if (!sessionId) return;
            
            try {
                currentLatencyMultiplier = parseInt(latencyMultiplier.value);
                const response = await fetch('/update_latency?' + new URLSearchParams({
                    session_id: sessionId,
                    latency_multiplier: currentLatencyMultiplier
                }), {
                    method: 'POST'
                });
                
                const data = await response.json();
                if (data.success) {
                    audioStatus.textContent = 'Latency updated successfully';
                    audioStatus.className = 'status success';
                    updateSettingsDisplay();
                } else {
                    audioStatus.textContent = 'Failed to update latency: ' + data.error;
                    audioStatus.className = 'status error';
                }
            } catch (error) {
                audioStatus.textContent = 'Error updating latency: ' + error;
                audioStatus.className = 'status error';
            }
        });
        
        // 更新设置显示
        function updateSettingsDisplay() {
            currentSettings.innerHTML = `
                <div style="margin-bottom: 10px; padding: 5px; background-color: #f8f9fa; border-radius: 3px;">
                    <strong>Current Settings:</strong><br>
                    Model: ${agentType.value}<br>
                    Languages: ${languagePair.value}<br>
                    Latency: ${latencyMultiplier.value}x
                </div>
            `;
        }
    </script>
</body>
</html> 