{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "import csv\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sacrebleu\n",
    "import soundfile as sf\n",
    "\n",
    "import copy\n",
    "import yaml\n",
    "import math\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from IPython.display import display, Audio\n",
    "\n",
    "def read_logs(path):\n",
    "    logs = []\n",
    "    with open(path, \"r\") as r:\n",
    "        for l in r.readlines():\n",
    "            l = l.strip()\n",
    "            if l != \"\":\n",
    "                logs.append(json.loads(l))\n",
    "    return logs\n",
    "\n",
    "def write_logs(logs, path):\n",
    "    with open(path, \"w\") as w:\n",
    "        for log in logs:\n",
    "            w.write(json.dumps(log) + \"\\n\")\n",
    "\n",
    "def read_wav(wav_path):\n",
    "    if ':' in wav_path:\n",
    "        wav_path, offset, duration = wav_path.split(':')\n",
    "        offset = int(offset)\n",
    "        duration = int(duration)\n",
    "    else:\n",
    "        offset = 0\n",
    "        duration = -1\n",
    "    source, rate = sf.read(wav_path, start=offset, frames=duration)\n",
    "    return source, rate\n",
    "\n",
    "def read_tsv(tsv_path):\n",
    "    import csv\n",
    "    with open(tsv_path) as f:\n",
    "        reader = csv.DictReader(\n",
    "            f,\n",
    "            delimiter=\"\\t\",\n",
    "            quotechar=None,\n",
    "            doublequote=False,\n",
    "            lineterminator=\"\\n\",\n",
    "            quoting=csv.QUOTE_NONE,\n",
    "        )\n",
    "        samples = [dict(e) for e in reader]\n",
    "    return samples\n",
    "\n",
    "def write_tsv(samples, tsv_path):\n",
    "    with open(tsv_path, \"w\") as w:\n",
    "        writer = csv.DictWriter(\n",
    "            w,\n",
    "            samples[0].keys(),\n",
    "            delimiter=\"\\t\",\n",
    "            quotechar=None,\n",
    "            doublequote=False,\n",
    "            lineterminator=\"\\n\",\n",
    "            quoting=csv.QUOTE_NONE,\n",
    "        )\n",
    "        writer.writeheader()\n",
    "        writer.writerows(samples)\n",
    "\n",
    "def play(audio_path):\n",
    "    display(Audio(read_wav(audio_path)[0], rate=16000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLLB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b28bfcb7ccf74bb08687b890dd7a5ca5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/564 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6fc1970c0f04b16823274ec770e7690",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/4.85M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86640a061f9e447c8e1092a71d6e64c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d42babc4f0be4ad79d57cfa6507e7f00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/3.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83b6bbc0fa074d9a9289274f9d68921d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/846 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ef6c85e59154306b456cc0bca577ec1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/2.46G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b736d7bcd7f4ae981f080f1d75b5eb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"Le chef de l'ONU dit qu'il n'y a pas de solution militaire en Syrie\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/nllb-200-distilled-600M\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/nllb-200-distilled-600M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'您好.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article = \"Hello\"\n",
    "inputs = tokenizer(article, return_tensors=\"pt\")\n",
    "\n",
    "translated_tokens = model.generate(\n",
    "    **inputs, forced_bos_token_id=tokenizer.convert_tokens_to_ids(\"zho_Hans\"), max_length=30\n",
    ")\n",
    "tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QWEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_name = \"Qwen/Qwen2.5-0.5B\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"cuda\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"翻译成英文：你好。\"\n",
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "generated_ids = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=10,\n",
    ")\n",
    "generated_ids = [\n",
    "    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "]\n",
    "\n",
    "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " How are you doing?\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inconsistency between online and simuleval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "online_sources = []\n",
    "for i in range(16):\n",
    "    online_sources.append(np.load('/home/siqiouya/work/sllama/online_source_{}.npy'.format(i)))\n",
    "simuleval_sources = []\n",
    "for i in range(16):\n",
    "    simuleval_sources.append(np.load('/home/siqiouya/work/sllama/source_{}.npy'.format(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.        ,  0.        ,  0.        , ..., -0.11690447,\n",
       "        -0.09129377, -0.11185333], dtype=float32),\n",
       " array([ 0.        ,  0.        ,  0.        , ...,  0.03414917,\n",
       "         0.00436401, -0.05111694]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "online_sources[0], simuleval_sources[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(211)\n",
    "plt.plot(online_sources[0])\n",
    "plt.title('Online Source')\n",
    "plt.subplot(212) \n",
    "plt.plot(simuleval_sources[0])\n",
    "plt.title('Simuleval Source')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SacreBLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sacrebleu\n",
    "scorer = sacrebleu.BLEU()\n",
    "scorer.get_signature()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tst-COMMON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_paths = []\n",
    "with open(\"/compute/babel-14-5/siqiouya/en-zh/tst-COMMON_full.source\") as f:\n",
    "    for line in f:\n",
    "        wav_paths.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "infos = []\n",
    "for wav_path in wav_paths:\n",
    "    info = sf.info(wav_path)\n",
    "    infos.append(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "durations = []\n",
    "for info in infos:\n",
    "    durations.append(info.duration / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "durations = np.array(durations)\n",
    "(durations > 10).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.683580208333336"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "durations.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "294.6705166666667"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "durations.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in range(1, 5):\n",
    "    seg_size = m * 960\n",
    "    path = \"/compute/babel-5-23/siqiouya/runs/en-zh/8B-traj-s2-v3.5_llama3/last.ckpt/simul-results-full-betterfilterbadwords/cache1000_seg{}_beam4_ms0_nrnl100_nrns5/instances.log\".format(seg_size)\n",
    "    logs = read_logs(path)\n",
    "    logs_less10 = [log for log in logs if log['source_length'] / 1000 / 60 < 10]\n",
    "    logs_more10 = [log for log in logs if log['source_length'] / 1000 / 60 >= 10]\n",
    "    write_logs(logs_less10, path.replace(\".log\", \"_less10.log\"))\n",
    "    write_logs(logs_more10, path.replace(\".log\", \"_more10.log\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 11)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(logs_less10), len(logs_more10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# absolute position embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinusoidal_positional_embedding(offset, length, d_model):\n",
    "    half_dim = d_model // 2\n",
    "    emb = math.log(10000) / (half_dim - 1)\n",
    "    emb = torch.exp(torch.arange(half_dim, dtype=torch.float) * -emb)\n",
    "    emb = torch.arange(offset, offset + length, dtype=torch.float).unsqueeze(\n",
    "        1\n",
    "    ) * emb.unsqueeze(0)\n",
    "    emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=1).view(\n",
    "        length, -1\n",
    "    )\n",
    "    if d_model % 2 == 1:\n",
    "        # zero pad\n",
    "        emb = torch.cat([emb, torch.zeros(length, 1)], dim=1)\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 9.0930e-01,  1.9867e-01,  1.9999e-02,  2.0000e-03,  2.0000e-04,\n",
       "         -4.1615e-01,  9.8007e-01,  9.9980e-01,  1.0000e+00,  1.0000e+00],\n",
       "        [ 1.4112e-01,  2.9552e-01,  2.9995e-02,  3.0000e-03,  3.0000e-04,\n",
       "         -9.8999e-01,  9.5534e-01,  9.9955e-01,  1.0000e+00,  1.0000e+00],\n",
       "        [-7.5680e-01,  3.8942e-01,  3.9989e-02,  4.0000e-03,  4.0000e-04,\n",
       "         -6.5364e-01,  9.2106e-01,  9.9920e-01,  9.9999e-01,  1.0000e+00],\n",
       "        [-9.5892e-01,  4.7943e-01,  4.9979e-02,  5.0000e-03,  5.0000e-04,\n",
       "          2.8366e-01,  8.7758e-01,  9.9875e-01,  9.9999e-01,  1.0000e+00],\n",
       "        [-2.7942e-01,  5.6464e-01,  5.9964e-02,  6.0000e-03,  6.0000e-04,\n",
       "          9.6017e-01,  8.2534e-01,  9.9820e-01,  9.9998e-01,  1.0000e+00],\n",
       "        [ 6.5699e-01,  6.4422e-01,  6.9943e-02,  6.9999e-03,  7.0000e-04,\n",
       "          7.5390e-01,  7.6484e-01,  9.9755e-01,  9.9998e-01,  1.0000e+00],\n",
       "        [ 9.8936e-01,  7.1736e-01,  7.9915e-02,  7.9999e-03,  8.0000e-04,\n",
       "         -1.4550e-01,  6.9671e-01,  9.9680e-01,  9.9997e-01,  1.0000e+00],\n",
       "        [ 4.1212e-01,  7.8333e-01,  8.9879e-02,  8.9999e-03,  9.0000e-04,\n",
       "         -9.1113e-01,  6.2161e-01,  9.9595e-01,  9.9996e-01,  1.0000e+00],\n",
       "        [-5.4402e-01,  8.4147e-01,  9.9833e-02,  9.9998e-03,  1.0000e-03,\n",
       "         -8.3907e-01,  5.4030e-01,  9.9500e-01,  9.9995e-01,  1.0000e+00],\n",
       "        [-9.9999e-01,  8.9121e-01,  1.0978e-01,  1.1000e-02,  1.1000e-03,\n",
       "          4.4257e-03,  4.5360e-01,  9.9396e-01,  9.9994e-01,  1.0000e+00]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sinusoidal_positional_embedding(2, 10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairseq.modules.sinusoidal_positional_embedding import SinusoidalPositionalEmbedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mix data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = 'es'\n",
    "split = 'dev'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_full = f\"{split}_st_{lang}{'_ft' if lang == 'zh' and split == 'train' else ''}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev_st_es\n"
     ]
    }
   ],
   "source": [
    "print(split_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_30 = read_tsv(f\"/compute/babel-14-5/siqiouya/en-{lang}/{split_full}_nospeaker_traj_30_filtered.tsv\")\n",
    "samples = read_tsv(f\"/compute/babel-14-5/siqiouya/en-{lang}/{split_full}_nospeaker_traj.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(454, 1183)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(samples_30), len(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in samples:\n",
    "    if 'src_phoneme' in x:\n",
    "        x.pop('src_phoneme')\n",
    "    if 'src_segments' in x:\n",
    "        x.pop('src_segments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = [x for x in samples if type(eval(x['trajectory'])) == list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1183"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/siqiouya/work/sllama\")\n",
    "from train.dataset import PromptSpeechToTextDatasetCreator\n",
    "dataset_mix = PromptSpeechToTextDatasetCreator.from_tsv(\n",
    "    root=f\"/compute/babel-14-5/siqiouya/en-{lang}/\",\n",
    "    split=f\"dev_st_es_nospeaker_traj_30mix_filtered\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8931a02e43bc48c6999d2e279c72878b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in tqdm(range(len(dataset_mix))):\n",
    "    if dataset_mix.trajectories[i] is None:\n",
    "        print(dataset_mix[i])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_samples = samples_30 + samples\n",
    "write_tsv(new_samples, f\"/compute/babel-14-5/siqiouya/en-{lang}/{split_full}_nospeaker_traj_30mix_filtered.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/compute/babel-14-5/siqiouya/en-es/dev_st_es_nospeaker_traj_30mix_filtered.tsv'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"/compute/babel-14-5/siqiouya/en-{lang}/{split_full}_nospeaker_traj_30mix_filtered.tsv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RTF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seg 960 RTF: 0.434\n",
      "seg 1920 RTF: 0.311\n",
      "seg 2880 RTF: 0.258\n",
      "seg 3840 RTF: 0.240\n",
      "[0.43420646638745586, 0.3105447250020244, 0.2577829749858482, 0.2402853461595036]\n"
     ]
    }
   ],
   "source": [
    "suffices = ['']\n",
    "\n",
    "rtfs = []\n",
    "for seg_size in range(960, 4000, 960):\n",
    "    instances = read_logs(\"/compute/babel-5-23/siqiouya/runs/en-zh/8B-traj-s2-v3.6/last.ckpt/simul-results-full-betterfilterbadwords/cache1000_seg{}_beam4_ms0_nrnl100_nrns5/instances.log\".format(seg_size))\n",
    "\n",
    "    sum_audio_len = 0\n",
    "    sum_comp_len = 0\n",
    "    for inst in instances:\n",
    "        audio_len = inst['delays'][-1]\n",
    "        comp_len = inst['elapsed'][-1] - audio_len\n",
    "        sum_audio_len += audio_len\n",
    "        sum_comp_len += comp_len\n",
    "    print(\"seg {} RTF: {:.3f}\".format(seg_size, sum_comp_len / sum_audio_len))\n",
    "    rtfs.append(sum_comp_len / sum_audio_len)\n",
    "print(rtfs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fn 1 RTF: 0.627\n",
      "fn 2 RTF: 0.660\n",
      "fn 3 RTF: 0.749\n",
      "fn 4 RTF: 0.863\n",
      "fn 5 RTF: 0.865\n",
      "fn 6 RTF: 0.963\n",
      "fn 7 RTF: 0.902\n",
      "[0.6272766492708965, 0.6602332743256539, 0.7490266849020142, 0.8632729736505114, 0.8652987829525057, 0.9626827018304407, 0.9023871640602232]\n"
     ]
    }
   ],
   "source": [
    "# StreamAtt\n",
    "suffices = ['']\n",
    "\n",
    "rtfs = []\n",
    "for fn in range(1, 8):\n",
    "    instances = read_logs(\"/compute/babel-5-23/siqiouya/runs/en-es/8B-s2-bi-v3.5.2/last.ckpt/streamatt/bsz1_layer14_t40_d10_fn{}/instances.log\".format(fn))\n",
    "\n",
    "    sum_audio_len = 0\n",
    "    sum_comp_len = 0\n",
    "    for inst in instances:\n",
    "        audio_len = inst['delays'][-1]\n",
    "        comp_len = inst['elapsed'][-1] - audio_len\n",
    "        sum_audio_len += audio_len\n",
    "        sum_comp_len += comp_len\n",
    "    \n",
    "    try:\n",
    "        print(\"fn {} RTF: {:.3f}\".format(fn, sum_comp_len / sum_audio_len))\n",
    "        rtfs.append(sum_comp_len / sum_audio_len)\n",
    "    except:\n",
    "        pass\n",
    "print(rtfs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# filter speaker information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "\n",
    "def extract_names_and_ted_talks(samples):\n",
    "    ted_talk_dict = defaultdict(set)\n",
    "    \n",
    "    # Regex for extracting names: matches 'Firstname Lastname:' and initials like 'CA:' or 'RSW:'\n",
    "    name_regex = re.compile(r'\\b(?<!\\\")(Audience|Narrator|Video|Man|Woman|Bono|Voice|Announcer|Rives|George W\\. Bush|Broadcasting|Boy|Professor|Engineer|Interviewer|Shereen El-Feki|Tina|Girl|Dad|Voice):|[A-Z][a-z]+(?:\\s[A-Z][a-z]+)*:|[A-Z]{1,3}:')\n",
    "\n",
    "    error_samples = []\n",
    "    cleaned_samples = []\n",
    "        \n",
    "    for sample in samples:\n",
    "        ted_id = sample['id'].split('_')[1]\n",
    "        names = name_regex.findall(sample['src_text'])\n",
    "        cleaned_names = {name.strip(':').strip() for name in names}\n",
    "\n",
    "        if len(cleaned_names) > 0:\n",
    "            ted_talk_dict[ted_id].update(cleaned_names)\n",
    "            error_samples.append(sample)\n",
    "        else:\n",
    "            cleaned_samples.append(sample)\n",
    "\n",
    "    return ted_talk_dict, error_samples, cleaned_samples\n",
    "\n",
    "# New product from Coke Japan: water salad. | New product from Coke Japan, water salad.\n",
    "# Consider this: Make a decision to live a carbon-neutral life.\n",
    "# Video: Don Blankenship: Let me be clear about it. | Let me be clear about it.\n",
    "# Richard Koshalek: [Unclear] starts from 2004. | THANK YOU. # (2400 frames) delete short utterance\n",
    "# DP: Wow.\t| David Perry: Wow. | Wow. \n",
    "# DNA: \n",
    "# Stephen Pink's Girlfriend: | Stephen Pinks Freundin:\n",
    "# Audience|Narrator|Video|Man|Woman|Bono|Voice|Announcer|Rives|George W. Bush|Broadcasting|Boy|Professor|Engineer|Interviewer|Shereen El-Feki|Tina|Girl|Dad|Voice\n",
    "# Then: working concentrated, without being frazzled.\tDann: konzentriert arbeiten, ohne genervt zu werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('labse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/compute/babel-14-5/siqiouya/en-es/train_st_es.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = read_tsv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_len = len(samples)\n",
    "while True:\n",
    "    ted_talk_data, error_samples, cleaned_samples = extract_names_and_ted_talks(samples)\n",
    "\n",
    "    if len(error_samples) == 0:\n",
    "        break\n",
    "\n",
    "    srcs = []\n",
    "    tgts = []\n",
    "    for x in error_samples:\n",
    "        src = x['src_text']\n",
    "        tgt = x['tgt_text']\n",
    "\n",
    "        src = src[:src.find(':')]\n",
    "        if ':' in tgt:\n",
    "            tgt = tgt[:tgt.find(':')]\n",
    "        elif '：' in tgt:\n",
    "            tgt = tgt[:tgt.find('：')]\n",
    "        else:\n",
    "            tgt = \"\"\n",
    "\n",
    "        srcs.append(src)\n",
    "        tgts.append(tgt)\n",
    "\n",
    "    src_embeddings = model.encode(srcs)\n",
    "    tgt_embeddings = model.encode(tgts)\n",
    "\n",
    "    sims = []\n",
    "    for i in range(len(src_embeddings)):\n",
    "        cosine_similarity = model.similarity(src_embeddings[i], tgt_embeddings[i]).item()\n",
    "        sims.append(cosine_similarity)\n",
    "    sims = np.array(sims)\n",
    "    src_lens = [len(src.split(' ')) for src in srcs]\n",
    "    tgt_lens = [len(tgt) if 'zh' in file_path else len(tgt.split(' ')) for tgt in tgts]\n",
    "    corrected_samples = []\n",
    "    \n",
    "    for i in range(len(sims)):\n",
    "        if re.search(r'One|Two|Three|Four|Five|Six|Seven|Eight|Nine|Ten|LG', srcs[i]):\n",
    "            continue\n",
    "        if srcs[i] != \"\" and tgts[i] != \"\" and src_lens[i] <= 3 and (tgt_lens[i] <= 3 or sims[i] > 0.5):\n",
    "            # print(error_samples[i]['src_text'], error_samples[i]['tgt_text'], sims[i], sep='\\n', end='\\n\\n')\n",
    "            x = copy.deepcopy(error_samples[i])\n",
    "            x['src_text'] = x['src_text'][len(srcs[i]) + 1:].strip()\n",
    "            x['tgt_text'] = x['tgt_text'][len(tgts[i]) + 1:].strip()\n",
    "            corrected_samples.append(x)\n",
    "\n",
    "    samples = cleaned_samples + corrected_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ted_talk_data, error_samples, cleaned_samples = extract_names_and_ted_talks(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_tsv(samples, file_path.replace('.tsv', '_nospeaker.tsv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = read_tsv(\"/compute/babel-14-5/siqiouya/en-es/train_st_es.tsv\")\n",
    "samples_ns = read_tsv(\"/compute/babel-14-5/siqiouya/en-es/train_st_es_nospeaker.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_ns_f = []\n",
    "for x in samples_ns:\n",
    "    if ':' in x['src_text']:\n",
    "        samples_ns_f.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_f = []\n",
    "for x in samples:\n",
    "    if ':' in x['src_text']:\n",
    "        samples_f.append(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# llama attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d7e01166b9b4ad390615e3ee86a5523",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, how are you? I hope you're doing well. I'm here to talk about something that's been on my mind\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/compute/babel-4-1/siqiouya/llama-3.1-8b-instruct-hf/\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"/compute/babel-4-1/siqiouya/llama-3.1-8b-instruct-hf/\")\n",
    "\n",
    "text = \"Hello, how are you?\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "outputs = model.generate(**inputs)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.\n"
     ]
    }
   ],
   "source": [
    "outputs = model.generate(**inputs, return_dict_in_generate=True, output_attentions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 7, 7])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs['attentions'][0][0].size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inspect es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = read_tsv(\"/compute/babel-14-5/siqiouya/en-es/train_st_es_traj_30_filtered.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', 'Es ', 'maravilloso estar ', 'aquí para ', 'hablar de mi ', 'travesía, ', 'hablar sobre mi silla de ', 'ruedas y sobre la ', 'libertad que ', 'me ha dado.  ', 'Empecé ', 'a usar silla de ', ' ', 'ruedas a los 16 años cuando una ', ' ', 'enfermedad prolongada ', 'cambió mi forma ', 'de acceder al ']\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x['trajectory']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in samples:\n",
    "    try:\n",
    "        type(eval(x['trajectory'])[0])\n",
    "    except:\n",
    "        assert int(x['n_frames']) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = read_tsv(\"/compute/babel-14-5/siqiouya/en-zh/train_st_zh_ft_traj_30_filtered.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(samples[4]['src_text'], samples[4]['tgt_text'], sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = read_logs(\"/compute/babel-5-23/siqiouya/runs/8B-traj-s2-v3.3/last.ckpt/greedy_train_chunk30_po10k/cache4000_seg960_beam1_ms0_nrnl100_nrns3/0/instances.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = logs[19]\n",
    "print(log['prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_frame = int(log['source_length'] * 16)\n",
    "stepsize = int(0.96 * 16000)\n",
    "idx = -1\n",
    "new_traj = []\n",
    "for offset in range(0, n_frame, stepsize):\n",
    "    text = \"\"\n",
    "    while idx + 1 < len(log['delays']) and int(log['delays'][idx + 1]) * 16 < offset + stepsize:\n",
    "        idx += 1\n",
    "        text += log['prediction'][idx]\n",
    "    new_traj.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(samples[19]['tgt_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav, sr = read_wav(log['source'][0])\n",
    "trajectory = new_traj\n",
    "\n",
    "step = int(sr * 0.96)\n",
    "for i, action in zip(range(0, len(wav), step), trajectory):\n",
    "    display(Audio(wav[i : i + step], rate=sr, autoplay=False))\n",
    "    print(i // step, \"[T_START]\", action, \"[T_END]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav, sr = read_wav(log['source'][0])\n",
    "trajectory = new_traj\n",
    "\n",
    "step = int(sr * 0.96)\n",
    "for i, action in zip(range(0, len(wav), step), trajectory):\n",
    "    if i // step >= 231 - 10 and i // step <= 231 + 10:\n",
    "        display(Audio(wav[i : i + step], rate=sr, autoplay=False))\n",
    "        print(i // step, \"[T_START]\", action, \"[T_END]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect Training po10k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = read_tsv(\"/compute/babel-14-5/siqiouya/en-zh/train_st_zh_ft_traj_30_filtered_po10k_gpt-4o-mini-2024-07-18_fa_traj.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_samples = read_tsv(\"/compute/babel-14-5/siqiouya/en-zh/train_st_zh_ft_traj_30_filtered.tsv\")\n",
    "id2samples = {x['id']: x for x in all_samples}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('source:', samples[100]['src_text'], end='\\n\\n')\n",
    "print('target-gpt-4o-mini:', samples[100]['tgt_text'], end='\\n\\n')\n",
    "print('target-original:', id2samples[samples[100]['id']]['tgt_text'], end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter by ASR WER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "# Path to the ASR files\n",
    "base_path = \"/home/siqiouya/work/sllama/data\"\n",
    "\n",
    "# Get all asr.* files\n",
    "\n",
    "# Read and concatenate all ASR results\n",
    "all_asrs = []\n",
    "for i in range(8):\n",
    "    with open(os.path.join(base_path, f\"asr.{i}\")) as f:\n",
    "        asrs = [line.strip() for line in f.readlines() if line.strip() != \"\"]\n",
    "        all_asrs.extend(asrs)\n",
    "\n",
    "print(f\"Total ASR transcriptions: {len(all_asrs)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = read_tsv(\"/compute/babel-14-5/siqiouya/en-de/dev_st_de_traj_30.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "wer_scorer = load(\"wer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_asrs = np.array(all_asrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wers = []\n",
    "for i in tqdm(range(len(samples))):\n",
    "    asr_orig = samples[i]['src_text'].replace('\"', '').lower()\n",
    "    asr_whisper = all_asrs[i].lower()\n",
    "    wer = wer_scorer.compute(predictions=[asr_orig], references=[asr_whisper])\n",
    "    wers.append(wer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "wers = np.array(wers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = np.array(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(wers > 0.4).sum(), len(wers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(wers > 0.4).nonzero()[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_samples = samples[wers > 0.4]\n",
    "err_asrs = all_asrs[wers > 0.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = list(range(len(err_samples)))\n",
    "np.random.shuffle(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = indices[1]\n",
    "sample = err_samples[idx]\n",
    "asr_whisper = err_asrs[idx]\n",
    "print(sample['src_text'], end='\\n\\n')\n",
    "print(sample['tgt_text'], end='\\n\\n')\n",
    "print(asr_whisper)\n",
    "play(sample['audio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# special case 1\n",
    "special_words = [\n",
    "    \"(Music)\", \n",
    "    \"(Laughter)\", \n",
    "    \"(Applause)\", \n",
    "]\n",
    "# special case 2\n",
    "## silence or music\n",
    "## usually src_text is empty and asr is shorter than 3 words\n",
    "\n",
    "# special case 3\n",
    "## zero length audio\n",
    "\n",
    "# special case 4 \n",
    "## whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_mask = wers > 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(samples)):\n",
    "    if remove_mask[i]:\n",
    "        if len(all_asrs[i].split(' ')) <= 3:\n",
    "            if any(w in samples[i]['src_text'] for w in special_words) or samples[i]['src_text'] == \"\":\n",
    "                remove_mask[i] = False\n",
    "                # print(samples[i]['src_text'], end='\\n\\n')\n",
    "                # print(samples[i]['tgt_text'], end='\\n\\n')\n",
    "                # print(all_asrs[i])\n",
    "                # play(samples[i]['audio'])\n",
    "                # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_samples = samples[~remove_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = list(range(len(filtered_samples)))\n",
    "np.random.shuffle(indices)\n",
    "for i in indices[:10]:\n",
    "    print(filtered_samples[i]['src_text'], end='\\n\\n')\n",
    "    print(filtered_samples[i]['tgt_text'], end='\\n\\n')\n",
    "    print(all_asrs[~remove_mask][i])\n",
    "    try:\n",
    "        play(filtered_samples[i]['audio'])\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_tsv(filtered_samples, \"/compute/babey arel-14-5/siqiouya/en-de/dev_st_de_traj_30_filtered.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = read_tsv(\"/compute/babel-14-5/siqiouya/en-de/dev_st_de_traj_30.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "wer_scorer = load(\"wer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_asrs = np.array(all_asrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wers = []\n",
    "for i in tqdm(range(len(samples))):\n",
    "    asr_orig = samples[i]['src_text'].replace('\"', '').lower()\n",
    "    asr_whisper = all_asrs[i].lower()\n",
    "    wer = wer_scorer.compute(predictions=[asr_orig], references=[asr_whisper])\n",
    "    wers.append(wer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wers = np.array(wers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = np.array(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(wers > 0.4).sum(), len(wers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(wers > 0.4).nonzero()[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_samples = samples[wers > 0.4]\n",
    "err_asrs = all_asrs[wers > 0.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = list(range(len(err_samples)))\n",
    "np.random.shuffle(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = indices[1]\n",
    "sample = err_samples[idx]\n",
    "asr_whisper = err_asrs[idx]\n",
    "print(sample['src_text'], end='\\n\\n')\n",
    "print(sample['tgt_text'], end='\\n\\n')\n",
    "print(asr_whisper)\n",
    "play(sample['audio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# special case 1\n",
    "special_words = [\n",
    "    \"(Music)\", \n",
    "    \"(Laughter)\", \n",
    "    \"(Applause)\", \n",
    "]\n",
    "# special case 2\n",
    "## silence or music\n",
    "## usually src_text is empty and asr is shorter than 3 words\n",
    "\n",
    "# special case 3\n",
    "## zero length audio\n",
    "\n",
    "# special case 4 \n",
    "## whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_mask = wers > 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(samples)):\n",
    "    if remove_mask[i]:\n",
    "        if len(all_asrs[i].split(' ')) <= 3:\n",
    "            if any(w in samples[i]['src_text'] for w in special_words) or samples[i]['src_text'] == \"\":\n",
    "                remove_mask[i] = False\n",
    "                # print(samples[i]['src_text'], end='\\n\\n')\n",
    "                # print(samples[i]['tgt_text'], end='\\n\\n')\n",
    "                # print(all_asrs[i])\n",
    "                # play(samples[i]['audio'])\n",
    "                # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_samples = samples[~remove_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = list(range(len(filtered_samples)))\n",
    "np.random.shuffle(indices)\n",
    "for i in indices[:10]:\n",
    "    print(filtered_samples[i]['src_text'], end='\\n\\n')\n",
    "    print(filtered_samples[i]['tgt_text'], end='\\n\\n')\n",
    "    print(all_asrs[~remove_mask][i])\n",
    "    try:\n",
    "        play(filtered_samples[i]['audio'])\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_tsv(filtered_samples, \"/compute/babel-14-5/siqiouya/en-de/dev_st_de_traj_30_filtered.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whisper ASR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whisper ASR\n",
    "import torch\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "from datasets import load_dataset\n",
    "\n",
    "# load model and processor\n",
    "# model_id = \"openai/whisper-large-v3-turbo\"\n",
    "model_id = \"openai/whisper-large-v3\"\n",
    "# model_id = \"openai/whisper-medium.en\"\n",
    "torch_dtype = torch.float16\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True\n",
    ")\n",
    "model.to('cuda')\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "forced_decoder_ids = processor.get_decoder_prompt_ids(language=\"english\", task=\"transcribe\")\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    chunk_length_s=30,\n",
    "    batch_size=16,  # batch size for inference - set based on your device\n",
    "    torch_dtype=torch_dtype,\n",
    "    device='cuda',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = read_tsv(\"/compute/babel-14-5/siqiouya/en-zh/train_st_zh_ft_traj_45.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asrs = []\n",
    "for i in tqdm(range(5197, 5197 + 1, 16)):\n",
    "    batch = err_samples[i:i + 16]\n",
    "    wav_paths = [x['audio'] for x in batch]\n",
    "    offsets = [int(x.split(':')[1]) for x in wav_paths]\n",
    "    durations = [int(x.split(':')[2]) for x in wav_paths]\n",
    "    sources, rates = zip(*[read_wav(x) for x in wav_paths])\n",
    "    \n",
    "    # Find max length in batch\n",
    "    max_len = max(len(x) for x in sources)\n",
    "\n",
    "    # Pad each source with zeros to match max length\n",
    "    padded_sources = []\n",
    "    for source in sources:\n",
    "        padding = np.zeros(max_len - len(source))\n",
    "        padded = np.concatenate([source, padding])\n",
    "        padded_sources.append(padded)\n",
    "\n",
    "    transcriptions = [\n",
    "        t['text'] \n",
    "        for t in pipe(padded_sources, generate_kwargs={\"forced_decoder_ids\": forced_decoder_ids})\n",
    "    ]\n",
    "\n",
    "    # # Stack into batch\n",
    "    # sources = np.stack(padded_sources)\n",
    "\n",
    "    # input_features = processor(\n",
    "    #     sources, \n",
    "    #     truncation=False, \n",
    "    #     padding=\"longest\",\n",
    "    #     sampling_rate=16000, \n",
    "    #     return_attention_mask=True,\n",
    "    #     return_tensors=\"pt\", \n",
    "    #     language=\"english\",\n",
    "    # )\n",
    "    # input_features = input_features.to(\"cuda\", torch.float16)\n",
    "    # # generate token ids\n",
    "    # predicted_ids = model.generate(**input_features, num_beams=4, return_timestamps=True)\n",
    "    # # decode token ids to text\n",
    "    # transcriptions = processor.batch_decode(predicted_ids, skip_special_tokens=True)\n",
    "    asrs.extend([t.strip() for t in transcriptions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(asrs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overlap between 45 chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = read_tsv(\"/compute/babel-14-5/siqiouya/en-zh/comet_0.50_traj_45.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlaps = []\n",
    "for i in range(len(samples) - 1):\n",
    "    wav_path, offset, duration = samples[i]['audio'].split(':')\n",
    "    wav_path_next, offset_next, duration_next = samples[i + 1]['audio'].split(':')\n",
    "    if wav_path == wav_path_next:\n",
    "        offset = int(offset)\n",
    "        duration = int(duration)\n",
    "        offset_next = int(offset_next)\n",
    "        duration_next = int(duration_next)\n",
    "        overlap = max(0, offset + duration - offset_next)\n",
    "        overlaps.append(overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlaps = np.array(overlaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlaps.mean() / 16000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = read_logs(\"/compute/babel-5-23/siqiouya/runs/en-zh/8B-traj-s2-v3.5_sc30/last.ckpt/simul-results-full-betterfilterbadwords/cache1000_seg2880_beam4_ms0_nrnl100_nrns5/instances.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyps = [x['prediction'] for x in logs]\n",
    "refs = [x['reference'] for x in logs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU = 17.33 57.4/25.4/11.1/5.6 (BP = 1.000 ratio = 1.264 hyp_len = 1028 ref_len = 813)\n",
      "BLEU = 29.95 78.6/43.9/25.0/15.1 (BP = 0.887 ratio = 0.893 hyp_len = 1475 ref_len = 1652)\n",
      "BLEU = 31.35 77.3/43.2/24.3/15.2 (BP = 0.941 ratio = 0.943 hyp_len = 1083 ref_len = 1149)\n",
      "BLEU = 21.71 77.5/39.3/18.5/9.3 (BP = 0.807 ratio = 0.824 hyp_len = 4756 ref_len = 5773)\n",
      "BLEU = 36.32 79.3/47.9/28.5/17.4 (BP = 0.981 ratio = 0.981 hyp_len = 2297 ref_len = 2341)\n",
      "BLEU = 36.53 83.9/51.0/28.3/16.8 (BP = 0.967 ratio = 0.967 hyp_len = 3802 ref_len = 3931)\n",
      "BLEU = 33.31 80.6/46.6/24.7/13.8 (BP = 0.990 ratio = 0.990 hyp_len = 3823 ref_len = 3860)\n",
      "BLEU = 29.82 71.0/39.6/21.9/12.9 (BP = 1.000 ratio = 1.092 hyp_len = 1598 ref_len = 1463)\n",
      "BLEU = 36.35 80.7/48.4/27.8/16.9 (BP = 0.988 ratio = 0.989 hyp_len = 2157 ref_len = 2182)\n",
      "BLEU = 33.94 77.3/42.8/25.3/15.9 (BP = 0.999 ratio = 0.999 hyp_len = 1221 ref_len = 1222)\n",
      "BLEU = 32.52 77.3/43.5/24.0/13.9 (BP = 1.000 ratio = 1.010 hyp_len = 2362 ref_len = 2338)\n",
      "BLEU = 32.44 80.8/47.5/24.6/12.9 (BP = 0.976 ratio = 0.977 hyp_len = 5840 ref_len = 5980)\n",
      "BLEU = 34.64 81.7/48.4/29.3/18.4 (BP = 0.906 ratio = 0.910 hyp_len = 660 ref_len = 725)\n",
      "BLEU = 25.61 68.5/35.8/18.0/9.7 (BP = 1.000 ratio = 1.039 hyp_len = 752 ref_len = 724)\n",
      "BLEU = 34.88 75.6/45.5/26.6/16.2 (BP = 1.000 ratio = 1.074 hyp_len = 1996 ref_len = 1858)\n",
      "BLEU = 34.91 80.8/48.0/26.3/15.0 (BP = 0.992 ratio = 0.992 hyp_len = 4113 ref_len = 4147)\n",
      "BLEU = 31.11 83.7/48.0/25.4/13.9 (BP = 0.903 ratio = 0.907 hyp_len = 5118 ref_len = 5643)\n",
      "BLEU = 33.16 76.9/46.8/24.9/13.5 (BP = 1.000 ratio = 1.075 hyp_len = 5065 ref_len = 4713)\n",
      "BLEU = 27.81 76.6/41.3/20.4/10.8 (BP = 0.964 ratio = 0.965 hyp_len = 1416 ref_len = 1468)\n",
      "BLEU = 22.10 63.1/31.2/14.9/8.2 (BP = 1.000 ratio = 1.085 hyp_len = 1328 ref_len = 1224)\n",
      "BLEU = 33.88 75.0/43.7/25.6/15.7 (BP = 1.000 ratio = 1.024 hyp_len = 1758 ref_len = 1717)\n",
      "BLEU = 26.85 72.5/38.0/18.6/10.2 (BP = 1.000 ratio = 1.100 hyp_len = 2750 ref_len = 2500)\n",
      "BLEU = 25.22 72.5/37.0/17.6/9.7 (BP = 0.970 ratio = 0.970 hyp_len = 1573 ref_len = 1621)\n",
      "BLEU = 34.61 80.6/47.3/26.4/15.8 (BP = 0.974 ratio = 0.974 hyp_len = 3890 ref_len = 3994)\n",
      "BLEU = 28.01 74.2/40.6/19.9/10.3 (BP = 1.000 ratio = 1.088 hyp_len = 6975 ref_len = 6412)\n",
      "BLEU = 34.49 81.1/47.6/26.3/14.7 (BP = 0.986 ratio = 0.987 hyp_len = 3448 ref_len = 3495)\n",
      "BLEU = 33.75 74.1/44.6/25.4/15.5 (BP = 1.000 ratio = 1.006 hyp_len = 1399 ref_len = 1390)\n"
     ]
    }
   ],
   "source": [
    "for hyp, ref in zip(hyps, refs):\n",
    "    print(sacrebleu.corpus_bleu([hyp], [[ref]], tokenize=\"zh\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "接下来我要想象一个能给你超人能力的机器人或者是另一个能让威尔士人站立和行走的机器人我们在伯克利邦尼克斯称之为骨骼机器人这些仅仅是你早上穿上的东西它们会给你额外的力量加快你的速度帮助你比如说，帮助你保持平衡事实上，这才是真正的整合人和机器的结合不仅如此它还能整合你和宇宙以及其他的设备这不仅仅是蓝天般的想象而是我们正在做的工作通过谈论美国士兵他们平均携带100磅的装备他们被要求携带更多的设备显然，这会导致复杂的后果包括背部损伤百分之三十的士兵患有慢性背部损伤我们想，我们可以看待这个挑战并创造一个外骨骼来解决这个问题我现在要向你们介绍Hark或者说人类通用负载器(笑声)在崎岖不平的路上走了很长时间。它灵活的设计可以让它保持俯卧、爬行和高敏捷性运动。它可以感知我想做什么，去哪里，然后增强我的力量和耐力。我们已经准备好了。与我们的战略合作伙伴一起，我们推出了这个设备，这个新的外骨骼。这是真实的。现在，让我们把我们的目光转向用户，特别是某些人，他们对此非常感兴趣。有6800万人被估计在世界各地的轮椅上。这大约是总人口的百分之一。这实际上是一个保守的估计。我们在这里谈论的是很年轻的人，他们患有脊髓损伤，在生命的黄金时期，20岁、30岁、40岁时，他们遭遇了一场灾难。轮椅是唯一的选择，但它也是人口数量不断增长的第18个群体。唯一的选择是中风或其他并发症，这就是轮椅。这实际上是过去500年来，因为它的引入非常成功，我必须说。所以我们认为我们可以开始编写一款全新的流动性章节。让我现在介绍给你们Elex，它是阿曼达·博克斯特尔（AmandaBoxtel）穿着的，她是一位19岁的脊髓损伤患者，这使她无法行走。19年来，直到现在，她都无法行走。(掌声)阿曼达穿着我们的Elex。它有传感器。它是完全无创的。脊椎中的传感器会发送信号回去，这些信号会传送到后面坐着的电脑。它们有电池，这些电池会驱动在臀部后面的电机，以及膝盖的电机，这些电机会以一种很顺畅，非常自然的步伐前进。它已经24岁了，在我游戏的顶峰时期，一个怪物在丹·赫尔斯基滑雪时瘫痪了我，在那一瞬间，我失去了所有的感觉，以及我下半身的运动能力。不久之后，一个医生走进了我的病房，他对我说，“阿曼达，你再也不会走路了。”那是19年前的事了。他夺走了我生命中的一分一毫的希望。适应技术已经让我学会了如何再次滑雪，如何攀岩，甚至如何骑单车。但迄今为止，没有任何发明能够让我再次行走。如你所见，我们有技术，我们有平台，我们可以坐下来和你们讨论。在我们的掌握之中，我们拥有所有的潜力去改变生活，去改变未来的一代人，不仅仅是为了士兵，也不仅仅是为了阿曼达和其他使用者，而是为了每一个人。谢谢。\n"
     ]
    }
   ],
   "source": [
    "print(hyps[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diff two samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/compute/babel-14-5/siqiouya/en-zh\"\n",
    "train_path = os.path.join(root, \"train.tsv\")\n",
    "train_st_zh_path = os.path.join(root, \"train_st_zh.tsv\")\n",
    "extra_ft_path = os.path.join(root, \"output.tsv\")\n",
    "comet_ft_path = os.path.join(root, \"comet_0.50_complement_tower.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = read_tsv(train_path)\n",
    "train_st_zh_samples = read_tsv(train_st_zh_path)\n",
    "extra_ft_samples = read_tsv(extra_ft_path)\n",
    "comet_ft_samples = read_tsv(comet_ft_path)\n",
    "len(train_samples), len(extra_ft_samples), len(comet_ft_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comet_ft_samples[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_samples) - len(train_st_zh_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in train_st_zh_samples:\n",
    "    if x['audio'].startswith(\"en-zh/data/train/wav\"):\n",
    "        x['audio'] = \"/compute/babel-14-5/siqiouya/\" + x['audio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_tsv(train_st_zh_samples, train_st_zh_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_st_zh_audio = set(x['audio'] for x in train_st_zh_samples)\n",
    "train_audio = set(x['audio'] for x in train_samples)\n",
    "extra_samples = []\n",
    "for x in train_samples:\n",
    "    if x['audio'] not in train_st_zh_audio:\n",
    "        extra_samples.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_tsv(extra_samples, os.path.join(root, \"train_extra.tsv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio2tgtext = {}\n",
    "for x in extra_ft_samples:\n",
    "    audio2tgtext[x['audio']] = x['translation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "for x in train_samples:\n",
    "    if x['audio'] in audio2tgtext:\n",
    "        x['tgt_text'] = audio2tgtext[x['audio']]\n",
    "        cnt += 1\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_train_samples = read_tsv(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "for x1, x2 in zip(orig_train_samples, train_samples):\n",
    "    if x1['tgt_text'] != x2['tgt_text']:\n",
    "        cnt += 1\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2sample = {}\n",
    "for x in train_st_zh_samples:\n",
    "    id2sample[x['id']] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "comet_ft_samples_full = []\n",
    "for x in comet_ft_samples:\n",
    "    if x['id'] in id2sample:\n",
    "        comet_ft_samples_full.append((id2sample[x['id']]['audio'], x['translation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(comet_ft_samples_full)):\n",
    "    comet_ft_samples_full[i] = [comet_ft_samples_full[i][0], comet_ft_samples_full[i][1]]\n",
    "    if comet_ft_samples_full[i][0].startswith(\"en-zh/data/train/wav\"):\n",
    "        comet_ft_samples_full[i][0] = \"/compute/babel-14-5/siqiouya/\" + comet_ft_samples_full[i][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "Audio(read_wav(\"/compute/babel-14-5/siqiouya/en-zh//data/train/wav/ted_2005.wav:19080960:138559\")[0], rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio2tgtext2 = {}\n",
    "for x in comet_ft_samples_full:\n",
    "    audio2tgtext2[x[0]] = x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "train_audio_set = set()\n",
    "for x in train_samples:\n",
    "    x['audio'] = x['audio'].replace('//', '/')\n",
    "    if x['audio'] in audio2tgtext2:\n",
    "        x['tgt_text'] = audio2tgtext2[x['audio']]\n",
    "        cnt += 1\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "for x1, x2 in zip(orig_train_samples, train_samples):\n",
    "    if x1['tgt_text'] != x2['tgt_text']:\n",
    "        # print(x1['src_text'], x1['tgt_text'], x2['tgt_text'], sep='\\n', end='\\n\\n')\n",
    "        cnt += 1\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_tsv(train_samples, os.path.join(root, \"train_ft.tsv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from comet import download_model, load_from_checkpoint\n",
    "model_path = download_model(\"Unbabel/XCOMET-XL\", saving_directory=\"/data/user_data/siqiouya/runs/pretrained/XCOMET-XL\")\n",
    "model = load_from_checkpoint(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = read_tsv(\"/compute/babel-14-5/siqiouya/en-zh/dev_fa_traj_45.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/compute/babel-5-23/siqiouya/runs/8B-traj-s2-v3.0/last.ckpt/sampling_dev_for_qe/cache4000_seg960_beam1_ms0_topp1.0_topk0_epsilon0.1_temp1.0/{}/instances.log\"\n",
    "logs_per_seed = []\n",
    "for i in range(16):\n",
    "    logs_per_seed.append(read_logs(path.format(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qe_scores_per_seed = []\n",
    "for i in range(16):\n",
    "    data = [\n",
    "        {\n",
    "            \"src\": samples[j]['src_text'],\n",
    "            \"ref\": samples[j]['tgt_text'],\n",
    "            \"mt\": logs_per_seed[i][j]['prediction']\n",
    "        }\n",
    "        for j in range(len(logs_per_seed[i]))\n",
    "    ]\n",
    "    qe_output = model.predict(data, batch_size=4, gpus=1)\n",
    "    qe_scores_per_seed.append(qe_output.scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greedy_log_path = \"/compute/babel-5-23/siqiouya/runs/8B-traj-s2-v3.0/last.ckpt/greedy_dev_for_qe/cache4000_seg960_beam1_ms0/instances.log\"\n",
    "greedy_logs = read_logs(greedy_log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    {\n",
    "        \"src\": samples[j]['src_text'],\n",
    "        \"ref\": samples[j]['tgt_text'],\n",
    "        \"mt\": greedy_logs[j]['prediction']\n",
    "    }\n",
    "    for j in range(len(samples))\n",
    "]\n",
    "qe_output = model.predict(data, batch_size=4, gpus=1)\n",
    "qe_scores_greedy = qe_output.scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    {\n",
    "        \"src\": samples[j]['src_text'],\n",
    "        \"ref\": samples[j]['tgt_text'],\n",
    "        \"mt\": samples[j]['tgt_text']\n",
    "    }\n",
    "    for j in range(len(samples))\n",
    "]\n",
    "qe_output = model.predict(data, batch_size=4, gpus=1)\n",
    "qe_scores_ref = qe_output.scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "qe_scores_per_seed = np.array(qe_scores_per_seed)\n",
    "qe_scores_ref = np.array(qe_scores_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qe_scores_per_seed[:, 0].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(samples[:10])):\n",
    "    max_log_idx = qe_scores_per_seed[:, idx].argmax()\n",
    "    print(samples[idx]['src_text'], end='\\n\\n')\n",
    "    print(qe_scores_per_seed[max_log_idx, idx], logs_per_seed[max_log_idx][idx]['prediction'], end='\\n\\n')\n",
    "    print(qe_scores_ref[idx], samples[idx]['tgt_text'], end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert sampled trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/compute/babel-14-5/siqiouya/en-zh/\"\n",
    "ckpt_root = \"/compute/babel-5-23/siqiouya/runs/8B-traj-s2-v3.0/last.ckpt\"\n",
    "split = \"train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = read_tsv(os.path.join(root, f\"{split}_fa_traj_45.tsv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_size = 1000\n",
    "n_partition = 20 # (len(samples) + partition_size - 1) // partition_size\n",
    "for i in tqdm(range(n_partition)):\n",
    "    partition_samples = samples[i * partition_size:(i + 1) * partition_size]\n",
    "    logs = read_logs(os.path.join(ckpt_root, f\"sampling_{split}/cache4000_seg960_beam1_ms0/{i}/instances.log\"))\n",
    "    for sample, log in zip(partition_samples, logs):\n",
    "        n_frame = int(sample['n_frames'])\n",
    "        stepsize = int(0.96 * 16000)\n",
    "        idx = -1\n",
    "        new_traj = []\n",
    "        for offset in range(0, n_frame, stepsize):\n",
    "            text = \"\"\n",
    "            while idx + 1 < len(log['delays']) and int(log['delays'][idx + 1]) * 16 < offset + stepsize:\n",
    "                idx += 1\n",
    "                text += log['prediction'][idx]\n",
    "            new_traj.append(text)\n",
    "        sample['sampling'] = new_traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 2\n",
    "print(samples[idx]['trajectory'], samples[idx]['sampling'], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_tsv(samples, os.path.join(root, f\"{split}_fa_traj_45_sampling.tsv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_tsv(samples[:n_partition * partition_size], os.path.join(root, f\"{split}_fa_traj_45_sampling_{n_partition}k.tsv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build source target for sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "root = \"/compute/babel-14-5/siqiouya/en-zh/\"\n",
    "base_split = \"train\"\n",
    "split = \"train_fa_traj_45\"\n",
    "split_wav_root = os.path.join(root, \"data\", base_split, f\"{split}_wav\")\n",
    "os.makedirs(split_wav_root, exist_ok=True)\n",
    "samples = read_tsv(os.path.join(root, f\"{split}.tsv\"))\n",
    "for x in tqdm(samples):\n",
    "    wav, sr = read_wav(x['audio'])\n",
    "    sf.write(os.path.join(split_wav_root, x['id'] + \".wav\"), wav, sr)\n",
    "def write_source_target(samples, split_wav_root, split_source_path, split_target_path):\n",
    "    with open(split_source_path, \"w\") as w:\n",
    "        for x in samples:\n",
    "            w.write(os.path.join(split_wav_root, x['id'] + \".wav\") + \"\\n\")\n",
    "    with open(split_target_path, \"w\") as w:\n",
    "        for x in samples:\n",
    "            w.write(x['tgt_text'] + \"\\n\")\n",
    "write_source_target(samples, split_wav_root, os.path.join(root, f\"{split}.source\"), os.path.join(root, f\"{split}.target\"))\n",
    "partition_size = 1000\n",
    "for i in range(0, len(samples), partition_size):\n",
    "    partition_samples = samples[i:i+partition_size]\n",
    "    write_source_target(partition_samples, split_wav_root, os.path.join(root, f\"{split}.source.{i//partition_size}\"), os.path.join(root, f\"{split}.target.{i//partition_size}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rebuild the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/compute/babel-14-5/siqiouya/en-zh/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls $root/data/$split/txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_lang = 'en'\n",
    "tgt_lang = 'zh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{root}/data/{split}/txt/{split}.yaml\") as f:\n",
    "    manifests = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{root}/data/{split}/txt/{split}.{src_lang}\", \"r\") as r:\n",
    "    src_texts = [l.strip() for l in r.readlines() if l.strip() != '']\n",
    "with open(f\"{root}/data/{split}/txt/{split}.{tgt_lang}\", \"r\") as r:\n",
    "    tgt_texts = [l.strip() for l in r.readlines() if l.strip() != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_texts[0], tgt_texts[0], len(src_texts), len(tgt_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifests[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id\taudio\tn_frames\tspeaker\tsrc_text\ttgt_text\tsrc_lang\ttgt_lang\n",
    "samples = []\n",
    "ted_id = \"\"\n",
    "id_in_ted = 0\n",
    "for i, manifest in enumerate(manifests):\n",
    "    cur_ted_id = manifest['wav'].split('.')[0]\n",
    "    if cur_ted_id != ted_id:\n",
    "        ted_id = cur_ted_id\n",
    "        id_in_ted = 0\n",
    "    else:\n",
    "        id_in_ted += 1\n",
    "\n",
    "    segment_id = f\"{ted_id}_{id_in_ted}\"\n",
    "\n",
    "    offset = int(manifest['offset'] * 16000)\n",
    "    duration = int(manifest['duration'] * 16000)\n",
    "    segment_path = f\"{root}/data/{split}/wav/{manifest['wav']}:{offset}:{duration}\"\n",
    "\n",
    "    samples.append({\n",
    "        \"id\": segment_id,\n",
    "        \"audio\": segment_path,\n",
    "        \"n_frames\": duration,\n",
    "        \"speaker\": manifest['speaker_id'],\n",
    "        \"src_text\": src_texts[i],\n",
    "        \"tgt_text\": tgt_texts[i],\n",
    "        \"src_lang\": src_lang,\n",
    "        \"tgt_lang\": tgt_lang,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_tsv(samples, f\"{root}/{split}.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## re-segment so that each utterance is shorter than 43.2 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "with open(\"/home/siqiouya/.api_keys/openai\", \"r\") as r:\n",
    "    api_key = r.read().strip()\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = 'He was at Radcliffe Infirmary in Oxford, and fortunately for him, a small team of doctors led by a Dr. Howard Florey had managed to synthesize a very small amount of penicillin, a drug that had been discovered 12 years before by Alexander Fleming but had never actually been  used to treat a human, and indeed no one even  knew if the drug would work, if it was full of impurities  that would kill the patient, but Florey and his team figured if they had to use it,  they might as well use it on someone who was going to die anyway.'\n",
    "tgt = \"他在牛津市的Radcliffe Infirmary 医院接受治疗， 幸运的是， 由霍华德·弗洛里医生 （译注：澳洲药理学家） 带头的一个医疗小组 成功的合成了 少量的盘尼西林， 一种被亚历山大·弗莱明 （译注：苏格兰药学家） 在12年前发现的药物， 但它从来没有被用来给人治病， 事实上甚至没有人知道 这种药是否有效， 如果这种药不纯净是否会致死， 但是弗洛里和他的团队觉得 如果他们需要使用这种药，不妨干脆在 已无药可救的患者身上试试看。\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"Here are the source text in English and translation in Chinese. \n",
    "English: {src}\n",
    "Chinese: {tgt}\n",
    "\n",
    "Segment the source text and the translation by sentence boundary (. ? !) and form a one-to-one mapping between source sentences and translation sentences. Output results with the following JSON format. Do not include any other text.\n",
    "[\n",
    "    {{\n",
    "        \"English\": \"...\",\n",
    "        \"Chinese\": \"...\"\n",
    "    }},\n",
    "    ...\n",
    "]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"developer\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt\n",
    "        }\n",
    "    ],\n",
    "    temperature=0.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "pairs = json.loads('\\n'.join(completion.choices[0].message.content.split('\\n')[1:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_1 = ' '.join([p['English'] for p in pairs])\n",
    "tgt_1 = ' '.join([p['Chinese'] for p in pairs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(src_1), len(tgt_1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(src), len(tgt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine the forward translation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = read_tsv(\"/compute/babel-14-5/siqiouya/en-zh/train_ft_traj_45.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 4\n",
    "samples[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "Audio(read_wav(samples[idx]['audio'])[0], rate=16000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine the DPO training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = read_tsv(\"/compute/babel-6-13/xixu/train.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_format(raw_str):\n",
    "    # Remove the outer quotes\n",
    "    cleaned_str = raw_str.strip('\"')\n",
    "\n",
    "    # Remove the extra quotes around the array\n",
    "    if cleaned_str.startswith('['):\n",
    "        cleaned_str = cleaned_str[1:-1]\n",
    "\n",
    "    # Split on '\", \"' to get individual elements\n",
    "    elements = cleaned_str.split('\", \"')\n",
    "\n",
    "    # Clean up each element\n",
    "    elements = [e.strip('\"').encode().decode('unicode_escape') for e in elements]\n",
    "\n",
    "    return elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(samples[0]['trajectory'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fix_format(samples[0]['sampling']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in samples:\n",
    "    x['sampling'] = fix_format(x['sampling'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_tsv(samples, \"/compute/babel-6-13/xixu/train__formated.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update training set with forward translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = read_tsv(\"/compute/babel-14-5/siqiouya/en-zh/train.tsv\")\n",
    "complement_samples = read_tsv(\"/compute/babel-14-5/siqiouya/en-zh/comet_0.50_complement_tower.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(samples), len(complement_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples[0], complement_samples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_indices = set()\n",
    "for x in complement_samples:\n",
    "    id = x['id'].strip()\n",
    "    if id in comp_indices:\n",
    "        print(x)\n",
    "    comp_indices.add(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2pair = {}\n",
    "for x in complement_samples:\n",
    "    id2pair[x['id'].strip()] = (x['src_text'].strip(), x['translation'].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = set(x['id'].strip() for x in samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_indices = set(x['id'].strip() for x in complement_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(comp_indices & indices), len(comp_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "for x in samples:\n",
    "    if x['id'].strip() in id2pair:\n",
    "        cnt += 1\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "Audio(read_wav('/compute/babel-14-5/siqiouya/en-zh/data/train/wav/ted_423.wav:1704960:691200')[0], rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in samples:\n",
    "    id = x['id'].strip()\n",
    "    if id in comp_indices:\n",
    "        x['src_text'] = id2pair[id][0]\n",
    "        x['tgt_text'] = id2pair[id][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_tsv(samples, \"/compute/babel-14-5/siqiouya/en-zh/train_ft.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLEU on MWERSEGMENT Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root = \"/compute/babel-5-23/siqiouya/runs/8B-traj-s2-v3.0/last.ckpt/simul-results-full/seg3840_beam1_ms0/tmp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_doc = len(os.listdir(root)) // 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyps = []\n",
    "refs = []\n",
    "hyps_full = []\n",
    "refs_full = []\n",
    "for i in range(n_doc):\n",
    "    with open(os.path.join(root, 'hyp.{}.seg'.format(i)), 'r') as r:\n",
    "        hyps_doc = r.read().strip().split('\\n')\n",
    "    with open(os.path.join(root, 'ref.{}'.format(i)), 'r') as r:\n",
    "        refs_doc = r.read().strip().split('\\n')\n",
    "    hyps_doc = [''.join(h.split(' ')) for h in hyps_doc]\n",
    "    refs_doc = [''.join(r.split(' ')) for r in refs_doc]\n",
    "    hyps.extend(hyps_doc)\n",
    "    refs.extend(refs_doc)\n",
    "\n",
    "    hyps_full.append(' '.join(hyps_doc))\n",
    "    refs_full.append(' '.join(refs_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sacrebleu.corpus_bleu(hyps, [refs], tokenize='zh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyps[10], refs[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hyps_full[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(refs_full[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sacrebleu.corpus_bleu(hyps_full, [refs_full], tokenize='zh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples = read_logs(\"/compute/babel-5-23/siqiouya/runs/8B-traj-s2-v3.0/last.ckpt/simul-results-full/cache4000_seg960_beam1_ms0/instances.log.corrected\")\n",
    "samples = read_logs(\"/compute/babel-5-23/siqiouya/runs/8B-traj-s2-v3.0/last.ckpt/sampling_dev/cache4000_seg960_beam1_ms0/0/instances.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "delays = np.array(samples[idx]['delays'])\n",
    "elapsed = np.array(samples[idx]['elapsed'])\n",
    "plt.plot(delays / 1000 / 60, label='Delays')\n",
    "plt.plot(elapsed / 1000 / 60, label='Elapsed time') \n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delays_diff = delays[1:] - delays[:-1]\n",
    "elapsed_diff = elapsed[1:] - elapsed[:-1]\n",
    "delays_diff = delays_diff[delays_diff > 0]\n",
    "elapsed_diff = elapsed_diff[elapsed_diff > 0]\n",
    "\n",
    "plt.plot(elapsed_diff - delays_diff)\n",
    "plt.ylim(0, 5000)\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Per step generation cost (ms)')\n",
    "# plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_token = []\n",
    "cnt = 0\n",
    "for i in range(1, len(elapsed)):\n",
    "    if elapsed[i] == elapsed[i - 1]:\n",
    "        cnt += 1\n",
    "    else:\n",
    "        n_token.append(cnt)\n",
    "        cnt = 1\n",
    "sum(n_token)\n",
    "\n",
    "nocache_n_token = []\n",
    "cnt = 0\n",
    "for i in range(1, len(nocache_elapsed)):\n",
    "    if nocache_elapsed[i] == nocache_elapsed[i - 1]:\n",
    "        cnt += 1\n",
    "    else:\n",
    "        nocache_n_token.append(cnt)\n",
    "        cnt = 1\n",
    "sum(nocache_n_token)\n",
    "\n",
    "running_avg = np.convolve(n_token, np.ones(10)/10, mode='valid')\n",
    "nocache_running_avg = np.convolve(nocache_n_token, np.ones(10)/10, mode='valid')\n",
    "plt.plot(running_avg)\n",
    "# plt.plot(nocache_running_avg, label='No cache')\n",
    "plt.legend()\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Running average # of tokens generated per step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/compute/babel-5-23/siqiouya/runs/8B-s2-v2.0-bi/last.ckpt/offline_beam1/tst-COMMON/hyp\", \"r\") as r:\n",
    "    hyps = r.read().strip().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyps = [(int(h.split(\"\\t\")[0]), h.split(\"\\t\")[1]) for h in hyps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyps = sorted(hyps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmented_samples = read_tsv(\"/compute/babel-14-5/siqiouya/en-zh/tst-COMMON.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(segmented_samples)):\n",
    "    segmented_samples[i]['idx'] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmented_samples = sorted(segmented_samples, key=lambda x: (int(x['id'].split('_')[1]), int(x['audio'].split(':')[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ted_id = int(segmented_samples[0]['id'].split('_')[1])\n",
    "full_hyps = []\n",
    "full_refs = []\n",
    "full_hyp = \"\"\n",
    "full_ref = \"\"\n",
    "for i, s in enumerate(segmented_samples):\n",
    "    cur_ted_id = int(s['id'].split('_')[1])\n",
    "    if cur_ted_id != ted_id:\n",
    "        full_hyps.append(full_hyp)\n",
    "        full_refs.append(full_ref)\n",
    "        full_hyp = \"\"\n",
    "        full_ref = \"\"\n",
    "        ted_id = cur_ted_id        \n",
    "    full_hyp += hyps[s['idx']][1] + '\\n'\n",
    "    full_ref += s['tgt_text'] + '\\n'\n",
    "full_hyps.append(full_hyp)\n",
    "full_refs.append(full_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(full_refs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu = sacrebleu.BLEU(tokenize='zh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyps = full_hyps[0].split(\"\\n\")\n",
    "refs = full_refs[0].split(\"\\n\")\n",
    "sacrebleu.corpus_bleu(\n",
    "    hyps, [refs], tokenize='zh'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyps = full_hyps[:1]\n",
    "refs = full_refs[:1]\n",
    "sacrebleu.corpus_bleu(\n",
    "    hyps, [refs], tokenize='zh'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Full TED tst-COMMON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def read_tsv(tsv_path):\n",
    "    import csv\n",
    "    with open(tsv_path) as f:\n",
    "        reader = csv.DictReader(\n",
    "            f,\n",
    "            delimiter=\"\\t\",\n",
    "            quotechar=None,\n",
    "            doublequote=False,\n",
    "            lineterminator=\"\\n\",\n",
    "            quoting=csv.QUOTE_NONE,\n",
    "        )\n",
    "        samples = [dict(e) for e in reader]\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/compute/babel-14-5/siqiouya/en-zh/'\n",
    "split = 'tst-COMMON'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = read_tsv(os.path.join(root, split + '.tsv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def key_func(x):\n",
    "    _, offset, _ = x['audio'].split(':')\n",
    "    offset = int(offset)\n",
    "\n",
    "    ted_id = int(x['id'].split('_')[1])\n",
    "\n",
    "    return (ted_id, offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_samples = sorted(\n",
    "    samples, \n",
    "    key=key_func\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ted_id = -1\n",
    "document = \"\"\n",
    "documents = []\n",
    "for x in sorted_samples:\n",
    "    cur_ted_id = int(x['id'].split('_')[1])\n",
    "    if cur_ted_id != ted_id:\n",
    "        documents.append((ted_id, document))\n",
    "        ted_id = cur_ted_id\n",
    "        document = x['tgt_text']\n",
    "    else:\n",
    "        document += ' ' + x['tgt_text']\n",
    "documents.append((ted_id, document))\n",
    "documents = documents[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(root, split + '_full.source'), 'w') as w_source, open(os.path.join(root, split + '_full.target'), 'w') as w_target:\n",
    "    for ted_id, document in documents:\n",
    "        w_source.write(os.path.join(\"/compute/babel-14-5/siqiouya/en-zh/data/tst-COMMON/wav/\", f\"ted_{ted_id}.wav\") + '\\n')\n",
    "        w_target.write(document + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug Beam Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse, os, sys, time, json\n",
    "sys.path.append(\"/home/siqiouya/work/sllama\")\n",
    "from collections import Counter\n",
    "\n",
    "from typing import Optional\n",
    "from simuleval.agents.states import AgentStates\n",
    "from simuleval.utils import entrypoint\n",
    "from simuleval.data.segments import SpeechSegment\n",
    "from simuleval.agents import SpeechToTextAgent\n",
    "from simuleval.agents.actions import WriteAction, ReadAction\n",
    "from simuleval.agents.states import AgentStates\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import transformers\n",
    "import soundfile as sf\n",
    "\n",
    "import conversation as conversation_lib\n",
    "from conversation import SeparatorStyle\n",
    "from eval.utils import disable_torch_init\n",
    "from model.model_new import SpeechLlamaForCausalLM\n",
    "from model.utils import SpaceStoppingCriteria, KeywordsStoppingCriteria\n",
    "# from train.uni_wav2vec_monkey_patch import replace_uni_train\n",
    "from fairseq.data.audio.speech_to_text_dataset import _collate_frames\n",
    "\n",
    "from train.options import (\n",
    "    add_speech_encoder_args,\n",
    "    add_simuleval_args,\n",
    "    add_gen_args\n",
    ")\n",
    "from model.speech_encoder import (\n",
    "    SpeechEncoderHuBERTRope,\n",
    "    SpeechEncoderW2V2RoPE,\n",
    "    SpeechEncoderW2VBERT2\n",
    ")\n",
    "from train.dataset import (\n",
    "    DEFAULT_SPEECH_PATCH_TOKEN,\n",
    "    DEFAULT_SPEECH_START_TOKEN,\n",
    "    DEFAULT_SPEECH_END_TOKEN\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "    \"/compute/babel-4-1/siqiouya/llama-3.1-8b-instruct-hf\",\n",
    "    padding_side=\"right\",\n",
    "    use_fast=False,\n",
    ")\n",
    "tokenizer.pad_token = \"<|finetune_right_pad_id|>\"\n",
    "\n",
    "model = SpeechLlamaForCausalLM.from_pretrained(\n",
    "    \"/compute/babel-4-1/siqiouya/llama-3.1-8b-instruct-hf\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map='cuda',\n",
    ").eval()\n",
    "\n",
    "speech_encoder_args = [\n",
    "    \"/data/user_data/siqiouya/runs/pretrained/wav2_vec_vox_960h_pl.pt\",\n",
    "    True,\n",
    "    \"[(1024,2,2)] * 2\",\n",
    "    \n",
    "    48,\n",
    "    500,\n",
    "    model.model.embed_tokens.embedding_dim,\n",
    "    None,\n",
    "    False,\n",
    "]\n",
    "speech_encoder = SpeechEncoderW2V2RoPE(*speech_encoder_args).eval()\n",
    "speech_encoder.to(dtype=model.dtype, device=model.device)\n",
    "\n",
    "length_shrink_func = speech_encoder._get_feat_extract_output_lengths\n",
    "\n",
    "model.model.speech_encoder = speech_encoder\n",
    "model.preprocess(tokenizer=tokenizer)\n",
    "\n",
    "state_dict = torch.load(\"/compute/babel-5-23/siqiouya/runs/8B-traj-s2-v2.2/last.ckpt/pytorch_model.bin\", map_location='cpu', weights_only=True)\n",
    "model.load_state_dict(state_dict)\n",
    "model.model.inference = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "source, rate = sf.read(\"/compute/babel-14-5/siqiouya/en-zh/data/tst-COMMON/wav_split/ted_1096_11.wav\")\n",
    "segment_size = 960 * 16 * 2\n",
    "source = source[:segment_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "Audio(source, rate=rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = torch.tensor(source)\n",
    "sp_seg_frame = int(48 // 4 * 0.08 * 16000)\n",
    "if source.size(0) % sp_seg_frame != 0:\n",
    "    n_pad = sp_seg_frame - source.size(0) % sp_seg_frame\n",
    "    source = torch.cat([source, torch.zeros(n_pad).to(source)], dim=0)\n",
    "offset = torch.zeros(79 + 320).to(source)\n",
    "source = torch.cat([offset, source], dim=0)        \n",
    "# old_src_len = states.src_len\n",
    "# states.src_len = source.size(0)\n",
    "# source = source[old_src_len:]\n",
    "\n",
    "speech_batch = source.unsqueeze(0).to(device=model.device, dtype=model.dtype)\n",
    "n_frames = torch.tensor([source.size(0)], dtype=torch.long).to(model.device)\n",
    "speech_lens = length_shrink_func(n_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_batch.size(), n_frames, speech_lens  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "messages.append(\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": f\"Translate the following speech from English to Chinese.\"\n",
    "        }\n",
    "    )\n",
    "messages.append(\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": 12 * DEFAULT_SPEECH_PATCH_TOKEN\n",
    "    }\n",
    ")\n",
    "messages.append(\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"在我\",\n",
    "    }\n",
    ")\n",
    "messages.append(\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": 12 * DEFAULT_SPEECH_PATCH_TOKEN\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "messages.append(\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer.apply_chat_template(\n",
    "    [messages],\n",
    "    return_tensors='pt',\n",
    "    padding=True, \n",
    "    truncation=False, \n",
    "    add_special_tokens=False\n",
    ")[:, :-1].cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model.speech_features_extracted = False\n",
    "outputs = model.generate(\n",
    "    attention_mask=None,\n",
    "    input_ids=input_ids,\n",
    "    speech_batch=speech_batch,\n",
    "    src_lengths=n_frames,\n",
    "    after_lens=speech_lens,\n",
    "    do_sample=False,\n",
    "    top_p=1.0,\n",
    "    temperature=1.0,\n",
    "    num_beams=4,\n",
    "    max_new_tokens=100,\n",
    "    no_repeat_ngram_size=3,\n",
    "    repetition_penalty=1.2,\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    "    return_dict_in_generate=True,\n",
    "    return_legacy_cache=False,\n",
    "    output_scores=True,\n",
    "    use_cache=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.decode(outputs.sequences[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids[0, :57 + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.past_key_values[0][0][0, 0][56]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_batch = speech_batch.float()\n",
    "speech_encoder.encode_speech(\n",
    "    speech_batch, n_frames\n",
    ")[0][:, :12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_encoder.encode_speech(\n",
    "    speech_batch[:, :15759], n_frames * 0 + 15759\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sacrebleu import BLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirname = \"/compute/babel-5-23/siqiouya/runs/8B-s2-v2.0/last.ckpt/offline_beam4/tst-COMMON/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(dirname, 'hyp'), 'r') as f:\n",
    "    hyps = [l.split('\\t')[1].strip() for l in f.readlines() if len(l.split('\\t')) > 1]\n",
    "with open(os.path.join(dirname, 'ref'), 'r') as f:\n",
    "    refs = [l.split('\\t')[1].strip() for l in f.readlines() if len(l.split('\\t')) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyps = np.array(hyps)\n",
    "refs = np.array(refs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = BLEU(tokenize='zh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens = [(len(r), i) for i, r in enumerate(refs)]\n",
    "sorted_lens = sorted(lens, key=lambda x: x[0])\n",
    "sorted_indices = [si[1] for si in sorted_lens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer.corpus_score(\n",
    "    hyps[sorted_indices[-1000:]].tolist(),\n",
    "    [refs[sorted_indices[-1000:]].tolist()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tsv(tsv_path):\n",
    "    import csv\n",
    "    with open(tsv_path) as f:\n",
    "        reader = csv.DictReader(\n",
    "            f,\n",
    "            delimiter=\"\\t\",\n",
    "            quotechar=None,\n",
    "            doublequote=False,\n",
    "            lineterminator=\"\\n\",\n",
    "            quoting=csv.QUOTE_NONE,\n",
    "        )\n",
    "        samples = [dict(e) for e in reader]\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsv_path = \"/compute/babel-6-17/xixu/datasets/must-c-v2.0/en-zh/{}.tsv\".format(\"train\")\n",
    "full_samples = read_tsv(tsv_path)\n",
    "tsv_path = \"/compute/babel-6-17/xixu/datasets/must-c-v2.0/en-zh/{}.tsv\".format(\"comet_0.50\")\n",
    "half_samples = read_tsv(tsv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(full_samples), len(half_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_duration = np.array([s[\"n_frames\"] for s in full_samples], dtype=np.int32) / 16000\n",
    "half_duration = np.array([s[\"n_frames\"] for s in half_samples], dtype=np.int32) / 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(full_duration, bins=50, alpha=0.5, label='Full Duration')\n",
    "plt.hist(half_duration, bins=50, alpha=0.5, label='Half Duration')\n",
    "plt.xlim(20)\n",
    "plt.ylim(0, 1000)\n",
    "plt.xlabel('Duration (seconds)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Histogram of Full Duration and Half Duration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_refs = np.array([len(s[\"tgt_text\"]) for s in full_samples])\n",
    "half_refs = np.array([len(s[\"tgt_text\"]) for s in half_samples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(full_refs > 100).sum(), (half_refs > 100).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(full_refs, bins=50, alpha=0.5, label='Full Refs')\n",
    "plt.hist(half_refs, bins=50, alpha=0.5, label='Half Refs')\n",
    "plt.xlabel('# of characters')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Histogram of Full Refs and Half Refs')\n",
    "plt.xlim(100)\n",
    "plt.ylim(0, 1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_samples = read_tsv(\"/compute/babel-6-17/xixu/datasets/must-c-v1.0/en-de/train.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_refs = np.array([len(s[\"tgt_text\"].split(' ')) for s in de_samples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_refs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(de_refs, bins=50, alpha=0.5, label='De Refs')\n",
    "plt.xlabel('# of words')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Histogram of Full Refs and Half Refs')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Llama 3.1 Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-02-10 16:02:22,158] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "Warning: The cache directory for DeepSpeed Triton autotune, /home/siqiouya/.triton/autotune, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/siqiouya/anaconda3/envs/speechllama/compiler_compat/ld: warning: librt.so.1, needed by /usr/local/cuda/lib64/libcufile.so, not found (try using -rpath or -rpath-link)\n",
      "/home/siqiouya/anaconda3/envs/speechllama/compiler_compat/ld: warning: libpthread.so.0, needed by /usr/local/cuda/lib64/libcufile.so, not found (try using -rpath or -rpath-link)\n",
      "/home/siqiouya/anaconda3/envs/speechllama/compiler_compat/ld: warning: libm.so.6, needed by /usr/local/cuda/lib64/libcufile.so, not found (try using -rpath or -rpath-link)\n",
      "/home/siqiouya/anaconda3/envs/speechllama/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `log2f@GLIBC_2.2.5'\n",
      "/home/siqiouya/anaconda3/envs/speechllama/compiler_compat/ld: /home/siqiouya/anaconda3/envs/sllama_lightning/lib//libstdc++.so.6: undefined reference to `fesetround@GLIBC_2.2.5'\n",
      "/home/siqiouya/anaconda3/envs/speechllama/compiler_compat/ld: /home/siqiouya/anaconda3/envs/sllama_lightning/lib//libstdc++.so.6: undefined reference to `fegetround@GLIBC_2.2.5'\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    }
   ],
   "source": [
    "import argparse, os, sys, time, json\n",
    "sys.path.append(\"/home/siqiouya/work/sllama\")\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "from collections import Counter\n",
    "\n",
    "from IPython.display import Audio\n",
    "\n",
    "from typing import Optional\n",
    "from simuleval.agents.states import AgentStates\n",
    "from simuleval.utils import entrypoint\n",
    "from simuleval.data.segments import SpeechSegment\n",
    "from simuleval.agents import SpeechToTextAgent\n",
    "from simuleval.agents.actions import WriteAction, ReadAction\n",
    "from simuleval.agents.states import AgentStates\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import transformers\n",
    "\n",
    "import conversation as conversation_lib\n",
    "from conversation import SeparatorStyle\n",
    "from eval.utils import disable_torch_init\n",
    "from model.model_new import SpeechLlamaForCausalLM\n",
    "from model.utils import SpaceStoppingCriteria, KeywordsStoppingCriteria\n",
    "# from train.uni_wav2vec_monkey_patch import replace_uni_train\n",
    "from fairseq.data.audio.speech_to_text_dataset import _collate_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bos_token': '<|begin_of_text|>',\n",
       " 'eos_token': '<|eot_id|>',\n",
       " 'pad_token': '<|finetune_right_pad_id|>'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.special_tokens_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "    # \"/compute/babel-4-1/siqiouya/llama-3.1-8b-instruct-hf\",\n",
    "    \"/compute/babel-4-1/siqiouya/llama-3-8b-instruct-hf\",\n",
    "    padding_side=\"right\",\n",
    "    use_fast=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad_token is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'NoneType' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 12\u001b[0m\n\u001b[1;32m      7\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39mpad_token \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<|finetune_right_pad_id|>\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m messages \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      9\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are a pirate chatbot who always responds in pirate speak!\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m     10\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWho are you?\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m     11\u001b[0m ]\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28mprint\u001b[39m(tokenizer\u001b[38;5;241m.\u001b[39mbatch_decode(\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_chat_template\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m)\u001b[49m)[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/speechllama/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1706\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.apply_chat_template\u001b[0;34m(self, conversation, tools, documents, chat_template, add_generation_prompt, continue_final_message, tokenize, padding, truncation, max_length, return_tensors, return_dict, return_assistant_tokens_mask, tokenizer_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     rendered \u001b[38;5;241m=\u001b[39m rendered[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tokenize:\n\u001b[0;32m-> 1706\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrendered\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1708\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1709\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1710\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1711\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1712\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1713\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtokenizer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1714\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1715\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m return_dict:\n\u001b[1;32m   1716\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m return_assistant_tokens_mask:\n",
      "File \u001b[0;32m~/anaconda3/envs/speechllama/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2860\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2858\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_target_context_manager:\n\u001b[1;32m   2859\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_input_mode()\n\u001b[0;32m-> 2860\u001b[0m     encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mall_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2861\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2862\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_target_mode()\n",
      "File \u001b[0;32m~/anaconda3/envs/speechllama/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2970\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m   2948\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_encode_plus(\n\u001b[1;32m   2949\u001b[0m         batch_text_or_text_pairs\u001b[38;5;241m=\u001b[39mbatch_text_or_text_pairs,\n\u001b[1;32m   2950\u001b[0m         add_special_tokens\u001b[38;5;241m=\u001b[39madd_special_tokens,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2967\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   2968\u001b[0m     )\n\u001b[1;32m   2969\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2970\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2973\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2976\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2977\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2978\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2979\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2980\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2981\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2982\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2983\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2984\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2985\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2986\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2987\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2988\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2989\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2990\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2991\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/speechllama/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:3037\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   3016\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3017\u001b[0m \u001b[38;5;124;03mTokenize and prepare for the model a sequence or a pair of sequences.\u001b[39;00m\n\u001b[1;32m   3018\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3033\u001b[0m \u001b[38;5;124;03m        method).\u001b[39;00m\n\u001b[1;32m   3034\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3036\u001b[0m \u001b[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[0;32m-> 3037\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_padding_truncation_strategies\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3038\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3039\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3040\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3041\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3042\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3043\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3044\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3046\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encode_plus(\n\u001b[1;32m   3047\u001b[0m     text\u001b[38;5;241m=\u001b[39mtext,\n\u001b[1;32m   3048\u001b[0m     text_pair\u001b[38;5;241m=\u001b[39mtext_pair,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3066\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3067\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/speechllama/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2761\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._get_padding_truncation_strategies\u001b[0;34m(self, padding, truncation, max_length, pad_to_multiple_of, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2758\u001b[0m             max_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_max_length\n\u001b[1;32m   2760\u001b[0m \u001b[38;5;66;03m# Test if we have a padding token\u001b[39;00m\n\u001b[0;32m-> 2761\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m padding_strategy \u001b[38;5;241m!=\u001b[39m PaddingStrategy\u001b[38;5;241m.\u001b[39mDO_NOT_PAD \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpad_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m):\n\u001b[1;32m   2762\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2763\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsking to pad but the tokenizer does not have a padding token. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2764\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2765\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor add a new pad token via `tokenizer.add_special_tokens(\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpad_token\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[PAD]\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m})`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2766\u001b[0m     )\n\u001b[1;32m   2768\u001b[0m \u001b[38;5;66;03m# Check that we will truncate to a multiple of pad_to_multiple_of if both are provided\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'NoneType' and 'int'"
     ]
    }
   ],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "    # \"/compute/babel-4-1/siqiouya/llama-3.1-8b-instruct-hf\",\n",
    "    \"/compute/babel-4-1/siqiouya/llama-3-8b-instruct-hf\",\n",
    "    padding_side=\"right\",\n",
    "    use_fast=False,\n",
    ")\n",
    "tokenizer.pad_token = \"<|finetune_right_pad_id|>\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a pirate chatbot who always responds in pirate speak!\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
    "]\n",
    "print(tokenizer.batch_decode(tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    padding=True, \n",
    "    truncation=False, \n",
    "    add_special_tokens=False,\n",
    "    return_tensors='pt',\n",
    "))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are a pirate chatbot who always responds in pirate speak!<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Who are you?<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "    \"/compute/babel-4-1/siqiouya/llama-3.1-8b-instruct-hf\",\n",
    "    # \"/compute/babel-4-1/siqiouya/llama-3-8b-instruct-hf\",\n",
    "    padding_side=\"right\",\n",
    "    use_fast=False,\n",
    ")\n",
    "tokenizer.pad_token = \"<|finetune_right_pad_id|>\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a pirate chatbot who always responds in pirate speak!\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
    "]\n",
    "print(tokenizer.batch_decode(tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    return_tensors='pt',\n",
    "))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SpeechLlamaForCausalLM.from_pretrained(\n",
    "    \"/compute/babel-4-1/siqiouya/llama-3.1-8b-instruct-hf\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map='cuda',\n",
    ").eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a pirate chatbot who always responds in pirate speak!\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"\"}\n",
    "]\n",
    "m2 = [\n",
    "    {\"role\": \"system\", \"content\": \"Translate the following speech from English to Chinese.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.apply_chat_template(\n",
    "    [m1, m2], \n",
    "    return_tensors='pt',\n",
    "    padding=True, \n",
    "    truncation=False, \n",
    "    add_special_tokens=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.convert_ids_to_tokens([128009])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse, os, sys, time, json\n",
    "sys.path.append(\"/home/siqiouya/work/sllama\")\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "from collections import Counter\n",
    "\n",
    "from IPython.display import Audio\n",
    "\n",
    "from typing import Optional\n",
    "from simuleval.agents.states import AgentStates\n",
    "from simuleval.utils import entrypoint\n",
    "from simuleval.data.segments import SpeechSegment\n",
    "from simuleval.agents import SpeechToTextAgent\n",
    "from simuleval.agents.actions import WriteAction, ReadAction\n",
    "from simuleval.agents.states import AgentStates\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import transformers\n",
    "\n",
    "import conversation as conversation_lib\n",
    "from conversation import SeparatorStyle\n",
    "from eval.utils import disable_torch_init\n",
    "from model.model_new import SpeechLlamaForCausalLM\n",
    "from model.utils import SpaceStoppingCriteria, KeywordsStoppingCriteria\n",
    "# from train.uni_wav2vec_monkey_patch import replace_uni_train\n",
    "from fairseq.data.audio.speech_to_text_dataset import _collate_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train.options import (\n",
    "    add_speech_encoder_args,\n",
    "    add_simuleval_args,\n",
    "    add_gen_args\n",
    ")\n",
    "from model.speech_encoder import (\n",
    "    SpeechEncoderHuBERTRope,\n",
    "    SpeechEncoderW2V2RoPE,\n",
    "    SpeechEncoderW2VBERT2\n",
    ")\n",
    "from train.dataset import (\n",
    "    DEFAULT_SPEECH_PATCH_TOKEN,\n",
    "    DEFAULT_SPEECH_START_TOKEN,\n",
    "    DEFAULT_SPEECH_END_TOKEN\n",
    ")\n",
    "from train.dataset import (\n",
    "    SpeechSampler, \n",
    "    PromptSpeechToTextDatasetCreator, \n",
    "    SpeechToTextDatasetItem,\n",
    "    DataCollatorForSupervisedDataset,\n",
    "    DataCollatorForTrajectoryDataset,\n",
    "    DataCollatorForTrajectoryInstructDataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "    \"/compute/babel-4-1/siqiouya/llama-3.1-8b-instruct-hf\",\n",
    "    padding_side=\"right\",\n",
    "    use_fast=False,\n",
    ")\n",
    "tokenizer.pad_token = \"<|finetune_right_pad_id|>\"\n",
    "\n",
    "model = SpeechLlamaForCausalLM.from_pretrained(\n",
    "    \"/compute/babel-4-1/siqiouya/llama-3.1-8b-instruct-hf\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map='cuda',\n",
    ").eval()\n",
    "\n",
    "speech_encoder_args = [\n",
    "    \"/data/user_data/siqiouya/runs/pretrained/wav2_vec_vox_960h_pl.pt\",\n",
    "    True,\n",
    "    \"[(1024,2,2)] * 2\",    \n",
    "    48,\n",
    "    500,\n",
    "    model.model.embed_tokens.embedding_dim,\n",
    "    None,\n",
    "    False,\n",
    "]\n",
    "speech_encoder = SpeechEncoderW2V2RoPE(*speech_encoder_args)\n",
    "\n",
    "speech_encoder.to(dtype=model.dtype, device=model.device)\n",
    "length_shrink_func = speech_encoder._get_feat_extract_output_lengths\n",
    "\n",
    "model.model.speech_encoder = speech_encoder\n",
    "model.preprocess(tokenizer=tokenizer)\n",
    "\n",
    "# state_dict = torch.load(\n",
    "#     \"/compute/babel-5-23/siqiouya/runs/8B-traj-s2-v1.2/epoch=0-step=1213.ckpt/pytorch_model.bin\", \n",
    "#     map_location='cpu', \n",
    "#     weights_only=True\n",
    "# )\n",
    "# model.load_state_dict(state_dict)\n",
    "# model.model.inference = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_speech(states):\n",
    "    source = torch.tensor(states.source)\n",
    "    sp_seg_frame = int(12 * 0.08 * 16000)\n",
    "    if source.size(0) % sp_seg_frame != 0:\n",
    "        n_pad = sp_seg_frame - source.size(0) % sp_seg_frame\n",
    "        source = torch.cat([source, torch.zeros(n_pad).to(source)], dim=0)\n",
    "    offset = torch.zeros(79 + 320).to(source)\n",
    "    source = torch.cat([offset, source], dim=0)\n",
    "    old_src_len = states.src_len\n",
    "    states.src_len = source.size(0)\n",
    "    source = source[old_src_len:]\n",
    "\n",
    "    speech_batch = source.unsqueeze(0).to(device='cuda', dtype=torch.bfloat16)\n",
    "    n_frames = torch.tensor([source.size(0)], dtype=torch.long).to('cuda')\n",
    "    speech_lens = length_shrink_func(n_frames)\n",
    "    return speech_batch, n_frames, speech_lens\n",
    "def prepare_inputs(states, speech_lens):\n",
    "    prompt = \"\"\n",
    "    if states.speech_cache is None:\n",
    "        prompt += f\"Translate the following speech from English to Chinese: \"\n",
    "    sp_tokens = DEFAULT_SPEECH_START_TOKEN + \\\n",
    "        speech_lens[0] * DEFAULT_SPEECH_PATCH_TOKEN + \\\n",
    "        DEFAULT_SPEECH_END_TOKEN\n",
    "    prompt += sp_tokens\n",
    "\n",
    "    inputs = tokenizer(\n",
    "        [prompt],\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=False,\n",
    "        add_special_tokens=False,\n",
    "    )\n",
    "    input_ids = inputs.input_ids.cuda()\n",
    "    return input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"MASTER_ADDR\"] = \"0.0.0.0\"\n",
    "os.environ[\"MASTER_PORT\"] = \"9105\"\n",
    "torch.distributed.init_process_group(\n",
    "    rank=0, world_size=1, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train_dataset = PromptSpeechToTextDatasetCreator.from_tsv(\n",
    "    \"/compute/babel-6-17/xixu/datasets/must-c-v2.0/en-zh\",\n",
    "    \"comet_0.50_traj\",\n",
    ")\n",
    "data_collator = DataCollatorForTrajectoryInstructDataset(\n",
    "    tokenizer, \n",
    "    length_shrink_func, \n",
    "    \"English\",\n",
    "    \"Chinese\",\n",
    "    block_size=48,\n",
    ")\n",
    "\n",
    "train_sampler = SpeechSampler(\n",
    "    train_dataset, \n",
    "    shuffle=True, \n",
    "    batch_size=800000, \n",
    "    batch_size_sent=20,\n",
    "    min_ms=320,\n",
    "    multiplier=32,\n",
    "    filter=True,\n",
    "    target_lang=\"Chinese\"\n",
    ")\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_sampler=train_sampler, \n",
    "    collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.convert_tokens_to_ids('<|start_header_id|>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = list(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = batches[-4]\n",
    "print(tokenizer.batch_decode(batch['input_ids']))\n",
    "\n",
    "sp_end_id = tokenizer.convert_tokens_to_ids(DEFAULT_SPEECH_END_TOKEN)\n",
    "sp_end_indices = (batch['input_ids'] == sp_end_id).nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx += 1\n",
    "partial_input_ids = batch[\"input_ids\"][:, :sp_end_indices[idx, 1] + 1]\n",
    "print(tokenizer.batch_decode(partial_input_ids))\n",
    "\n",
    "partial_speech_batch = batch[\"speech_batch\"][:, :79 + 320 + 48 * 320 * (idx + 1)]\n",
    "display(Audio(partial_speech_batch, rate=16000))\n",
    "partial_n_frames = torch.tensor([partial_speech_batch.size(1)], dtype=torch.long)\n",
    "partial_speech_lens = length_shrink_func(partial_n_frames)\n",
    "stop_str = \"<|end_of_text|>\"\n",
    "keywords = [stop_str]\n",
    "stopping_criteria = KeywordsStoppingCriteria(\n",
    "    keywords, tokenizer, partial_input_ids.clone()\n",
    ")\n",
    "model.model.speech_features_extracted = False\n",
    "outputs = model.generate(\n",
    "    attention_mask=None,\n",
    "    input_ids=partial_input_ids.to(model.device),\n",
    "    speech_batch=partial_speech_batch.to(model.device, model.dtype),\n",
    "    src_lengths=partial_n_frames.to(model.device),\n",
    "    after_lens=partial_speech_lens.to(model.device),\n",
    "    do_sample=False,\n",
    "    num_beams=1,\n",
    "    max_new_tokens=100,\n",
    "    no_repeat_ngram_size=3,\n",
    "    repetition_penalty=1.2,\n",
    "    temperature=1.0,\n",
    "    top_p=1.0,\n",
    "    stopping_criteria=[stopping_criteria],\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    "    return_dict_in_generate=True,\n",
    "    use_cache=True,\n",
    "    # past_key_values=states.past_key_values,\n",
    "    # states=states,\n",
    ")\n",
    "print(tokenizer.batch_decode(outputs.sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval.agents.streamllama import S2TAgentStates\n",
    "states = S2TAgentStates(0, None, None, [])\n",
    "idx = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx += 1\n",
    "states.source = list(batch[\"speech_batch\"][0, :48 * 320 * (idx + 1)])\n",
    "speech_batch, n_frames, speech_lens = prepare_speech(states)\n",
    "input_ids = prepare_inputs(states, speech_lens)\n",
    "\n",
    "max_number_of_tokens = 100\n",
    "\n",
    "stop_str = \"<|end_of_text|>\"\n",
    "keywords = [stop_str]\n",
    "stopping_criteria = KeywordsStoppingCriteria(\n",
    "    keywords, tokenizer, torch.tensor(input_ids)\n",
    ")\n",
    "\n",
    "model.model.speech_features_extracted = False\n",
    "outputs = model.generate(\n",
    "    attention_mask=None,\n",
    "    input_ids=input_ids,\n",
    "    speech_batch=speech_batch,\n",
    "    src_lengths=n_frames,\n",
    "    after_lens=speech_lens,\n",
    "    do_sample=False,\n",
    "    num_beams=1,\n",
    "    max_new_tokens=max(1, max_number_of_tokens - len(states.target_ids)),\n",
    "    no_repeat_ngram_size=3,\n",
    "    repetition_penalty=1.2,\n",
    "    temperature=1.0,\n",
    "    top_p=1.0,\n",
    "    stopping_criteria=[stopping_criteria],\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    "    return_dict_in_generate=True,\n",
    "    use_cache=True,\n",
    "    past_key_values=states.past_key_values,\n",
    "    states=states,\n",
    ")\n",
    "\n",
    "states.past_key_values = outputs.past_key_values\n",
    "print(tokenizer.batch_decode(outputs.sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states.src_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_input_ids, input_ids, speech_lens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare data for simuleval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import soundfile as sf\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_split = 'train'\n",
    "split = 'train_st_zh_ft_traj_30_filtered_po10k_gpt-4o-mini-2024-07-18_fa_traj'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsv_path = \"/compute/babel-14-5/siqiouya/en-zh/{}.tsv\".format(split)\n",
    "with open(tsv_path, encoding='utf-8') as f:\n",
    "    reader = csv.DictReader(\n",
    "        f,\n",
    "        delimiter=\"\\t\",\n",
    "        quotechar=None,\n",
    "        doublequote=False,\n",
    "        lineterminator=\"\\n\",\n",
    "        quoting=csv.QUOTE_NONE,\n",
    "    )\n",
    "    samples = [dict(e) for e in reader]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"/compute/babel-14-5/siqiouya/en-zh/data/{}/wav_split_30/\".format(base_split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in tqdm(samples):\n",
    "    path, offset, n_frame = x['audio'].split(':')\n",
    "    wav, sr = sf.read(path, frames=int(n_frame), start=int(offset))\n",
    "    sf.write(f\"/compute/babel-14-5/siqiouya/en-zh/data/{base_split}/wav_split_30/{x['id']}.wav\", wav, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_partition = 8\n",
    "partition_size = (len(samples) + n_partition - 1) // n_partition\n",
    "for idx in range(8):\n",
    "    with open(f\"/compute/babel-14-5/siqiouya/en-zh/{split}.source.{idx}\", \"w\") as w_src, \\\n",
    "         open(f\"/compute/babel-14-5/siqiouya/en-zh/{split}.target.{idx}\", \"w\") as w_tgt:\n",
    "        for x in samples[idx * partition_size:(idx + 1) * partition_size]:  # Split samples into 8 parts\n",
    "            w_src.write(f\"/compute/babel-14-5/siqiouya/en-zh/data/{base_split}/wav_split_30/{x['id']}.wav\" + \"\\n\")\n",
    "            w_tgt.write(x[\"tgt_text\"] + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# filter tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsv_path = \"/compute/babel-6-17/xixu/datasets/must-c-v2.0/en-zh/dev_traj.tsv\"\n",
    "with open(tsv_path) as f:\n",
    "    reader = csv.DictReader(\n",
    "        f,\n",
    "        delimiter=\"\\t\",\n",
    "        quotechar=None,\n",
    "        doublequote=False,\n",
    "        lineterminator=\"\\n\",\n",
    "        quoting=csv.QUOTE_NONE,\n",
    "    )\n",
    "    samples = [dict(e) for e in reader]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(samples))\n",
    "samples = [s for s in samples if s[\"trajectory\"] != \"\"]\n",
    "print(len(samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(tsv_path, \"w\") as w:\n",
    "    writer = csv.DictWriter(\n",
    "        w,\n",
    "        reader.fieldnames + ['trajectory'],\n",
    "        delimiter=\"\\t\",\n",
    "        quotechar=None,\n",
    "        doublequote=False,\n",
    "        lineterminator=\"\\n\",\n",
    "        quoting=csv.QUOTE_NONE,\n",
    "    )\n",
    "    writer.writeheader()\n",
    "    writer.writerows(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load w2v2-conformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoFeatureExtractor, Wav2Vec2BertModel, Wav2Vec2BertConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\"/data/user_data/siqiouya/runs/pretrained/w2v-bert-2.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = torch.rand(300000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = feature_extractor(audio[:320 + 79 + 320 * 1], sampling_rate=16000, return_tensors=\"pt\", do_normalize_per_mel_bins=False)\n",
    "f2 = feature_extractor(audio[:320 + 79 + 320 * 2], sampling_rate=16000, return_tensors=\"pt\", do_normalize_per_mel_bins=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = Wav2Vec2BertConfig.from_pretrained(\"/data/user_data/siqiouya/runs/pretrained/w2v-bert-2.0\")\n",
    "model_config.layerdrop = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Wav2Vec2BertModel.from_pretrained(\n",
    "    \"/data/user_data/siqiouya/runs/pretrained/w2v-bert-2.0\",\n",
    "    config=model_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/siqiouya/work/sllama\")\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "from eval.utils import disable_torch_init\n",
    "from model.model_new import SpeechLlamaForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/compute/babel-7-1/siqiouya/runs/3.1-8B-s1-english-german-w2v2-rope/checkpoint-3400/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "disable_torch_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "    path,\n",
    "    padding_side=\"left\",\n",
    "    use_fast=False,\n",
    ")\n",
    "tokenizer.pad_token = \"<|finetune_right_pad_id|>\"\n",
    "\n",
    "config = json.load(open(os.path.join(path, 'config.json')))\n",
    "config['large_model'] = True\n",
    "update_config = os.path.join(path, 'config_large.json')\n",
    "if not os.path.exists(update_config):\n",
    "    json.dump(config, open(update_config, 'w'), indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SpeechLlamaForCausalLM.from_pretrained(\n",
    "    path,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map='auto',\n",
    "    config=update_config\n",
    ").eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "ckpt = torch.load(\"/compute/babel-7-1/siqiouya/runs/3.1-8B-s1-english-german-w2v2-rope/checkpoint-3400/speech_encoder.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HuBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import fairseq\n",
    "from fairseq.models.hubert import HubertEncoder\n",
    "from fairseq.models.wav2vec import Wav2VecEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = \"/mnt/data/siqiouyang/download/hubert_large_ll60k_finetune_ls960.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models, cfg, task = fairseq.checkpoint_utils.load_model_ensemble_and_task([ckpt_path])\n",
    "model = models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cfg.model.w2v_args.model.encoder_embed_dim)\n",
    "print(cfg.model.w2v_args.model.encoder_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.w2v_encoder.w2v_model.encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simplified Wav2Vec2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/siqiouyang/work/projects/sllama\")\n",
    "sys.path.append(\"/home/siqiouyang/work/projects/sllama/wav2vec/src\")\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = torch.load(\"/mnt/taurus/data/xixu/models/wav2_vec_vox_960h_pl.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ckpt['args'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RoPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from rotary_embedding_torch import RotaryEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotary_emb = RotaryEmbedding(dim = 32)\n",
    "\n",
    "# mock queries and keys - dimensions should end with (seq_len, feature dimension), and any number of preceding dimensions (batch, heads, etc)\n",
    "\n",
    "q = torch.randn(1, 8, 1024, 64) # queries - (batch, heads, seq len, dimension of head)\n",
    "k = torch.randn(1, 8, 1024, 64) # keys\n",
    "\n",
    "# apply the rotations to your queries and keys after the heads have been split out, but prior to the dot product and subsequent softmax (attention)\n",
    "\n",
    "q = rotary_emb.rotate_queries_or_keys(q)\n",
    "k = rotary_emb.rotate_queries_or_keys(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotary_emb = RotaryEmbedding(dim = 16)\n",
    "\n",
    "# mock queries and keys - dimensions should end with (seq_len, feature dimension), and any number of preceding dimensions (batch, heads, etc)\n",
    "\n",
    "q = torch.randn(1, 8, 1024, 64) # queries - (batch, heads, seq len, dimension of head)\n",
    "k = torch.randn(1, 8, 1024, 64) # keys\n",
    "\n",
    "# apply the rotations to your queries and keys after the heads have been split out, but prior to the dot product and subsequent softmax (attention)\n",
    "\n",
    "q = rotary_emb.rotate_queries_or_keys(q)\n",
    "k = rotary_emb.rotate_queries_or_keys(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotary_emb.freqs.size(), \n",
    "q.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate New Speech Encoder on Long Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/siqiouya/work/sllama')\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import copy\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchaudio\n",
    "import transformers\n",
    "from model.speech_encoder import SpeechEncoder, SpeechEncoderW2V2RoPE\n",
    "from model.model import SpeechLlamaForCausalLM\n",
    "from fairseq.examples.speech_to_text.data_utils import load_df_from_tsv, save_df_to_tsv\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = SpeechLlamaForCausalLM.from_pretrained(\n",
    "    # \"/mnt/taurus/data/siqiouyang/download/llama3.1-8b-hf\",\n",
    "    \"/compute/babel-4-1/siqiouya/llama-3.1-8b-hf\",\n",
    "    # low_cpu_mem_usage=True,\n",
    "    load_in_8bit=False,\n",
    "    device_map='cuda'\n",
    "    # device_map='cpu',\n",
    ")\n",
    "\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "    # \"/mnt/taurus/data/siqiouyang/download/llama3.1-8b-hf\",\n",
    "    \"/compute/babel-4-1/siqiouya/llama-3.1-8b-hf\",\n",
    "    padding_side=\"right\",\n",
    "    use_fast=False,\n",
    ")\n",
    "tokenizer.pad_token = \"<|finetune_right_pad_id|>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SpeechEncoderW2V2RoPE(\n",
    "    \"/mnt/taurus/data/xixu/models/wav2_vec_vox_960h_pl.pt\",\n",
    "    True,\n",
    "    \"[(1024,2,2)] * 2\",    \n",
    "    48,\n",
    "    500,      \n",
    "    copy.deepcopy(llm.model.embed_tokens),\n",
    ").to('cuda')\n",
    "del llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = torch.load(\"/mnt/taurus/data/siqiouyang/runs/sllama/en-de/crtl-stage0-w2v2-cache10s/epoch=57-step=75021.ckpt\")\n",
    "model.load_state_dict(ckpt['state_dict'])\n",
    "del ckpt\n",
    "\n",
    "model.eval()\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_df_from_tsv(\"/mnt/aries/data/siqiouyang/datasets/must-c-v1.0/dev_st_de_full_mfa_llama3.tsv\")\n",
    "df_tst = load_df_from_tsv(\"/mnt/aries/data/siqiouyang/datasets/must-c-v1.0/tst-COMMON_st_de_full_mfa_llama3.tsv\")\n",
    "\n",
    "df_seg = load_df_from_tsv(\"/mnt/aries/data/siqiouyang/datasets/must-c-v1.0/dev_st_de_mfa_llama3.tsv\")\n",
    "df_tst_seg = load_df_from_tsv(\"/mnt/aries/data/siqiouyang/datasets/must-c-v1.0/tst-COMMON_st_de_mfa_llama3.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, df_tst], ignore_index=True)\n",
    "df_seg = pd.concat([df_seg, df_tst_seg], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sims(df):\n",
    "    all_sims = []\n",
    "    for df_idx in tqdm(range(len(df))):\n",
    "        d = df.iloc[df_idx]\n",
    "\n",
    "        if d['speech_word'] is None or d['speech_word'] == '':\n",
    "            continue\n",
    "\n",
    "        path, offset, duration = d['audio'].split(':')\n",
    "        offset = int(offset)\n",
    "        duration = int(duration)\n",
    "        wav, sr = torchaudio.load(path, frame_offset=offset, num_frames=duration)\n",
    "\n",
    "        ted_id = int(d['id'].split('_')[1])\n",
    "\n",
    "        cache = None\n",
    "        outputs = []\n",
    "        last_frame = 0\n",
    "        for i in range(79 + 320, wav.size(1), 320 * 48):\n",
    "            x = wav[:, last_frame : i + 320 * 48].to('cuda')\n",
    "\n",
    "            if x.size(1) < 320 * 48:\n",
    "                pad = torch.zeros(1, 320 * 48 - x.size(1)).to(x)\n",
    "                x = torch.cat([x, pad], dim=1)\n",
    "            \n",
    "            x_len = torch.LongTensor([x.size(1)]).to('cuda')\n",
    "\n",
    "            output, cache = model.encode_speech(x, x_len, cache=cache)\n",
    "            outputs.append(output)\n",
    "            last_frame = i + 320 * 48\n",
    "                \n",
    "        full_output = torch.cat(outputs, dim=1)\n",
    "\n",
    "        speech_words = torch.tensor(eval(d['speech_word']))\n",
    "        text_words = torch.tensor(eval(d['text_word']))\n",
    "        src_text = tokenizer.encode(\n",
    "            d['src_text'],\n",
    "            return_tensors=\"pt\",\n",
    "            padding=\"longest\",\n",
    "            truncation=False,\n",
    "            add_special_tokens=False\n",
    "        ).to('cuda')\n",
    "        src_text_emb = model.llm_embedding(src_text)\n",
    "        for i in range(speech_words.size(0)):\n",
    "            s_l, s_r = speech_words[i]\n",
    "            t_l, t_r = text_words[i]\n",
    "\n",
    "            s_l = int((s_l / 0.08).floor())\n",
    "            s_r = min(int((s_r / 0.08).ceil()), full_output.size(1)) - 1\n",
    "\n",
    "            s_word_emb = full_output[0][s_l : s_r + 1].mean(dim=0)\n",
    "            t_word_emb = src_text_emb[0][t_l : t_r + 1].mean(dim=0)\n",
    "\n",
    "            sim = F.cosine_similarity(s_word_emb, t_word_emb, dim=0)\n",
    "            all_sims.append((ted_id, speech_words[i][1].item() + offset / 16000, sim.item()))  \n",
    "    return all_sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sims = get_sims(df)\n",
    "all_sims_seg = get_sims(df_seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_full = {}\n",
    "d_seg = {}\n",
    "for ted_id, offset, sim in all_sims:\n",
    "    d_full[ted_id] = d_full.get(ted_id, []) + [(offset, sim)]\n",
    "for ted_id, offset, sim in all_sims_seg:\n",
    "    d_seg[ted_id] = d_seg.get(ted_id, []) + [(offset, sim)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_simr = []\n",
    "for ted_id in d_full.keys():\n",
    "    d_full[ted_id].sort(key=lambda x: x[0])\n",
    "    d_seg[ted_id].sort(key=lambda x: x[0])\n",
    "    for x, y in zip(d_full[ted_id], d_seg[ted_id]):\n",
    "        assert x[0] - y[0] < 1e-2\n",
    "        time_simr.append((x[0], np.log(x[1] / y[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_simr = np.array(time_simr)\n",
    "mean_simrs = []\n",
    "for i in range(30 * 6):\n",
    "    mean_simrs.append(np.nanmean(time_simr[(time_simr[:, 0] >= i * 10) & (time_simr[:, 0] < (i + 1) * 10), -1]))\n",
    "plt.plot(mean_simrs)\n",
    "plt.xlabel('Time (10s)')\n",
    "plt.ylabel('log(sim from full / sim from seg)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sims = np.array(all_sims)\n",
    "mean_sims = []\n",
    "for i in range(30 * 6):\n",
    "    mean_sims.append(all_sims[(all_sims[:, 1] >= i * 10) & (all_sims[:, 1] < (i + 1) * 10), -1].mean())\n",
    "plt.plot(mean_sims)\n",
    "plt.xlabel('Time (10s)')\n",
    "plt.ylabel('sim from full')\n",
    "# plt.xlabel(\"Input Length (unit: 10 seconds)\")\n",
    "# plt.ylabel(\"Cosine Similarity of Speech and Text Embeddings\")\n",
    "# plt.savefig(\"/home/siqiouyang/work/projects/sllama/notebooks/length_extrapolation.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_df_from_tsv(\"/mnt/aries/data/siqiouyang/datasets/must-c-v1.0/train_st_de_full_mfa_llama3.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df['n_frames'] >= 15 * 60 * 16000).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df_to_tsv(df[df['n_frames'] >= 15 * 60 * 16000], \"/mnt/aries/data/siqiouyang/datasets/must-c-v1.0/train_st_de_full_15min_mfa_llama3.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Speech Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "cfgs = [(1024, 10, 5)] + [(1024, 3, 2)] * 4 + [(1024,2,2)] * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/siqiouya/work/sllama')\n",
    "from model.speech_encoder import ConvFeatureExtractionModel\n",
    "feature_extractor = ConvFeatureExtractionModel(cfgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.rand(1, 79 + 1280 * 2)\n",
    "x2 = torch.cat([x1, torch.rand(1, 1280)], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = feature_extractor(x1)\n",
    "y2 = feature_extractor(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(y1[0, :, 0] - y2[0, :, 0]) / y1[0, :, 0].abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feat_extract_output_lengths(input_lengths):\n",
    "    \"\"\"\n",
    "    Computes the output length of the convolutional layers\n",
    "    \"\"\"\n",
    "\n",
    "    def _conv_out_length(input_length, kernel_size, stride):\n",
    "        return torch.floor((input_length - kernel_size) / stride + 1)\n",
    "\n",
    "    for cfg in cfgs:\n",
    "        input_lengths = _conv_out_length(\n",
    "            input_lengths, cfg[1], cfg[2]\n",
    "        )\n",
    "\n",
    "    return input_lengths.to(torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_lens = get_feat_extract_output_lengths(torch.arange(0, 160000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = []\n",
    "for i in range(len(out_lens) - 1):\n",
    "    if out_lens[i] != out_lens[i + 1]:\n",
    "        t.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_feat_extract_output_lengths(torch.tensor([80]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from x_transformers.x_transformers import RotaryEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = RotaryEmbedding(512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq, scale = emb(torch.ones(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\"/data/user_data/siqiouya/runs/pretrained/llama-2-7b/hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer(\n",
    "    [\"Hello\", \"Hello 1\"],\n",
    "    padding=True,\n",
    "    padding_side='left',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import types\n",
    "from comet import download_model, load_from_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def read_tsv(tsv_path):\n",
    "    import csv\n",
    "    with open(tsv_path) as f:\n",
    "        reader = csv.DictReader(\n",
    "            f,\n",
    "            delimiter=\"\\t\",\n",
    "            quotechar=None,\n",
    "            doublequote=False,\n",
    "            lineterminator=\"\\n\",\n",
    "            quoting=csv.QUOTE_NONE,\n",
    "        )\n",
    "        samples = [dict(e) for e in reader]\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comet_model = load_from_checkpoint(\"/compute/babel-7-5/siqiouya/xcomet_xxl/snapshots/bad20b47daa64c41a8b29f3d3016be75baf0d7b4/checkpoints/model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = \"/compute/babel-14-5/siqiouya/en-zh/\"\n",
    "samples = read_tsv(os.path.join(data_root, \"tst-COMMON.tsv\"))\n",
    "srcs = [s[\"src_text\"] for s in samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/compute/babel-5-23/siqiouya/runs/8B-traj-s2-v2.2/last.ckpt/simul-results/beam1_mult1_ms0/instances.log\", \"r\") as r:\n",
    "    instances = [json.loads(line) for line in r.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "comet_data = [\n",
    "    {\n",
    "        \"src\": srcs[i],\n",
    "        \"mt\" : instances[i]['prediction'].strip(),\n",
    "        \"ref\": instances[i]['reference'].strip()\n",
    "    }\n",
    "    for i in range(len(srcs))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comet_output = comet_model.predict(comet_data, batch_size=4, gpus=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comet_output.system_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "offline_results_dir = \"/compute/babel-5-23/siqiouya/runs/8B-s2-v2.0-bi/last.ckpt/offline_beam1/tst-COMMON/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(offline_results_dir, 'hyp'), 'r') as f:\n",
    "    hyps = [l for l in f.readlines() if len(l.split('\\t')) > 1]\n",
    "with open(os.path.join(offline_results_dir, 'ref'), 'r') as f:\n",
    "    refs = [l for l in f.readlines() if len(l.split('\\t')) > 1]\n",
    "\n",
    "hs = []\n",
    "rs = []\n",
    "for hyp, ref in zip(hyps, refs):\n",
    "    idx = int(hyp.split('\\t')[0])\n",
    "    hs.append((idx, hyp.split('\\t')[1].strip()))\n",
    "    rs.append((idx, ref.split('\\t')[1].strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs = sorted(hs)\n",
    "rs = sorted(rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "comet_data_off = [\n",
    "    {\n",
    "        \"src\": srcs[i],\n",
    "        \"mt\" : hs[i][1],\n",
    "        \"ref\": rs[i][1],\n",
    "    }\n",
    "    for i in range(len(srcs))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comet_output_off = comet_model.predict(comet_data_off, batch_size=4, gpus=1)\n",
    "comet_output_off.system_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tst-COMMON de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import yaml\n",
    "import pandas as pd\n",
    "from fairseq.examples.speech_to_text.data_utils import load_df_from_tsv, save_df_to_tsv\n",
    "from fairseq.data.audio.audio_utils import (\n",
    "    get_fbank,\n",
    "    get_waveform,\n",
    "    read_from_stored_zip,\n",
    "    is_npy_data,\n",
    "    is_sf_audio_data,\n",
    "    parse_path,\n",
    "    FEATURE_OR_SF_AUDIO_FILE_EXTENSIONS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_or_waveform(\n",
    "        path: str,\n",
    "):\n",
    "    import soundfile as sf\n",
    "    _path, slice_ptr = parse_path(path)\n",
    "    if len(slice_ptr) == 0:\n",
    "        waveform, sample_rate = sf.read(_path, dtype=\"float32\",)\n",
    "    elif len(slice_ptr) == 2:\n",
    "        waveform, sample_rate = sf.read(_path, dtype=\"float32\",\n",
    "                                start=int(slice_ptr[0]), frames=int(slice_ptr[1]))\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid path: {_path}\")\n",
    "    return waveform, sample_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('alignatt_instances.log', 'r') as r:\n",
    "    instances = [json.loads(l) for l in r.readlines() if l.strip() != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances[0]['reference']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_df_from_tsv('/data/user_data/siqiouya/dataset/must-c-v1.0/en-de/tst-COMMON.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/data/user_data/siqiouya/dataset/must-c-v1.0/en-de/data/tst-COMMON/txt/tst-COMMON.yaml', 'r') as r:\n",
    "    manifest = yaml.safe_load(r)\n",
    "with open('/data/user_data/siqiouya/dataset/must-c-v1.0/en-de/data/tst-COMMON/txt/tst-COMMON.en', 'r') as r:\n",
    "    src_text = [l.strip() for l in r.readlines() if l.strip() != '']\n",
    "with open('/data/user_data/siqiouya/dataset/must-c-v1.0/en-de/data/tst-COMMON/txt/tst-COMMON.de', 'r') as r:\n",
    "    tgt_text = [l.strip() for l in r.readlines() if l.strip() != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifest[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['audio'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df.columns\n",
    "columns[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame(columns=df.columns[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "ids = []\n",
    "audios = []\n",
    "n_frames = []\n",
    "speakers = []\n",
    "for i in range(len(manifest)):\n",
    "    if i > 0 and manifest[i]['wav'] != manifest[i - 1]['wav']:\n",
    "        cnt = 0\n",
    "\n",
    "    wav = manifest[i]['wav']\n",
    "    ids.append(wav.split('.')[0] + '_{}'.format(cnt))\n",
    "    offset_frame = int(manifest[i]['offset'] * 16000)\n",
    "    duration_frame = int(manifest[i]['duration'] * 16000)\n",
    "    audio = \"/data/user_data/siqiouya/dataset/must-c-v1.0/en-de/data/tst-COMMON/wav/{}:{}:{}\".format(wav, offset_frame, duration_frame)\n",
    "    audios.append(audio)\n",
    "    n_frames.append(duration_frame)\n",
    "    speakers.append(manifest[i]['speaker_id'])\n",
    "\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['id'] = ids\n",
    "new_df['audio'] = audios\n",
    "new_df['n_frames'] = n_frames\n",
    "new_df['speaker'] = speakers\n",
    "new_df['src_text'] = src_text\n",
    "new_df['tgt_text'] = tgt_text\n",
    "new_df['src_lang'] = ['en'] * len(src_text)\n",
    "new_df['tgt_lang'] = ['de'] * len(tgt_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df_to_tsv(new_df, '/data/user_data/siqiouya/dataset/must-c-v1.0/en-de/tst-COMMON.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Per 10s Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/data/user_data/siqiouya/dataset/must-c-v1.0/en-es/tst-COMMON.source', 'r') as r:\n",
    "    sources = np.array([line.strip() for line in r.readlines() if line.strip() != \"\"])\n",
    "with open('/data/user_data/siqiouya/dataset/must-c-v1.0/en-es/tst-COMMON.target', 'r') as r:\n",
    "    targets = np.array([line.strip() for line in r.readlines() if line.strip() != \"\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_frames = np.array([torchaudio.info(src).num_frames for src in tqdm(sources)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "durations = n_frames / 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for duration in [10, 20, 30, 40, 50, 60]:\n",
    "    source = sources[(duration - 1 < durations) & (durations < duration + 1)][0]\n",
    "    target = targets[(duration - 1 < durations) & (durations < duration + 1)][0]\n",
    "    with open('/data/user_data/siqiouya/dataset/must-c-v1.0/en-es/tst-COMMON-profile-{}s.source'.format(duration), 'w') as w:\n",
    "        w.write('\\n'.join([source] * 5))\n",
    "\n",
    "    with open('/data/user_data/siqiouya/dataset/must-c-v1.0/en-es/tst-COMMON-profile-{}s.target'.format(duration), 'w') as w:\n",
    "        w.write('\\n'.join([target] * 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computation Overhead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/data/user_data/siqiouya/runs/stage3-uni-waco-word-block50-fixed-mix-from-stage0/simul-results/30s-wait-k-word-inc-opt-1000ms-n3-bsz8/wait-1000ms-2/instances.log\"\n",
    "# path = \"/data/user_data/siqiouya/runs/stage3-uni-waco-word-block50-fixed-mix-from-stage0/simul-results/30s-wait-k-word-inc-opt-1000ms-n3-bsz8-recomp-w2v2/wait-1000ms-2/instances.log\"\n",
    "# path = \"/data/user_data/siqiouya/runs/stage3-uni-waco-word-block50-fixed-mix-from-stage0/simul-results/30s-wait-k-word-inc-opt-1000ms-n3-bsz8-recomp-llm/wait-1000ms-2/instances.log\"\n",
    "# path = \"/data/user_data/siqiouya/runs/stage2-bi-mix-fix/simul-results/30s-wait-k-word-1000ms-n3-bsz8/wait-1000ms-2/instances.log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = []\n",
    "with open(path, 'r') as r:\n",
    "    for line in r.readlines():\n",
    "        line = line.strip()\n",
    "        if line != \"\":\n",
    "            instances.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum = n = m = 0\n",
    "for ist in instances:\n",
    "    elapsed = np.array(ist['elapsed'])\n",
    "    delays = np.array(ist['delays'])\n",
    "    src_len = ist['source_length']\n",
    "    elapsed = elapsed[delays < src_len]\n",
    "    if len(elapsed) > 0:\n",
    "        sum += elapsed[-1]\n",
    "        n += len(elapsed)\n",
    "\n",
    "        # sum += ist['elapsed'][-1]\n",
    "        # n += len(ist['elapsed'])\n",
    "    else:\n",
    "        m += 1\n",
    "print(sum / n, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ist['elapsed']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# en-de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "from train.dataset import get_features_or_waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav = get_features_or_waveform(\"/data/user_data/siqiouya/dataset/must-c-v1.0/en-es/data/tst-COMMON/wav/ted_1096.wav:201760:1816160\")\n",
    "Audio(wav[0], rate=wav[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Previous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from fairseq.examples.speech_to_text.data_utils import load_df_from_tsv, save_df_to_tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirname = '/data/user_data/siqiouya/dataset/must-c-v1.0/en-es'\n",
    "split = 'train_mfa'\n",
    "df = load_df_from_tsv(os.path.join(dirname, split + '.tsv'))\n",
    "# new_paths = []\n",
    "# for a in df['audio']:\n",
    "#     new_paths.append('/scratch/siqiouya/dataset/must-c-v1.0/' + a)\n",
    "# df['audio'] = new_paths\n",
    "# save_df_to_tsv(df, os.path.join(dirname, split + '.tsv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['text_word'] == '']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_config = os.path.join(, 'config_large.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change path of tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from fairseq.examples.speech_to_text.data_utils import load_df_from_tsv, save_df_to_tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_df_from_tsv(os.path.join('/scratch/siqiouya/dataset/must-c-v1.0/en-es/', '{}.tsv'.format(dev)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_2d_causal_mask(seq_len, dtype, device='gpu', blocksize=1):\n",
    "    \"\"\"\n",
    "    Generates a 2D causal mask for multi-head attention.\n",
    "    \n",
    "    Args:\n",
    "        seq_len (int): The length of the sequence.\n",
    "        dtype (torch.dtype): The data type for the mask.\n",
    "        device (str): The device on which to create the mask.\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: A 2D causal attention mask.\n",
    "    \"\"\"\n",
    "    blocksizes = [min(blocksize, seq_len - i * blocksize) for i in range((seq_len + blocksize - 1) // blocksize)]\n",
    "    blocks = [torch.ones((s, s), device=device, dtype=dtype) for s in blocksizes]\n",
    "    mask = torch.block_diag(*blocks)\n",
    "\n",
    "    tril_row, tril_col = torch.tril_indices(seq_len, seq_len)\n",
    "    mask[tril_row, tril_col] = 1\n",
    "\n",
    "    mask.masked_fill_(mask == 0, float('-inf'))\n",
    "    mask.masked_fill_(mask == 1, 0)\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_2d_causal_mask(6, float, device='cpu', blocksize=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mfa_30s_mix_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = load_df_from_tsv(\"/data/user_data/siqiouya/dataset/must-c-v1.0/en-es/train_mfa_30s_mix_filtered.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.iloc[231870]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torchaudio.info(\"/scratch/siqiouya/dataset/must-c-v1.0/en-es/data/train/wav/ted_26.wav\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "17256479\n",
    "3857750"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tst-COMMON_30s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torchaudio\n",
    "import IPython.display\n",
    "from fairseq.examples.speech_to_text.data_utils import load_df_from_tsv, save_df_to_tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_path = '/data/user_data/siqiouya/dataset/must-c-v1.0/en-es/tst-COMMON.tsv'\n",
    "long_path = '/data/user_data/siqiouya/dataset/must-c-v1.0/en-es/tst-COMMON_st_es_30s.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_df = load_df_from_tsv(ori_path)\n",
    "long_df = load_df_from_tsv(long_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_df.iloc[19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_wav(path):\n",
    "    path, offset, duration = path.split(':')\n",
    "    wav, _ = torchaudio.load(path, int(offset), int(duration))\n",
    "    return wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(read_wav(ori_df['audio'][19]), rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_df['src_text'][19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import types\n",
    "from comet import download_model, load_from_checkpoint\n",
    "from fairseq.examples.speech_to_text.data_utils import load_df_from_tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comet_model = load_from_checkpoint(\"/data/user_data/siqiouya/runs/pretrained/models--Unbabel--XCOMET-XXL/snapshots/bad20b47daa64c41a8b29f3d3016be75baf0d7b4/checkpoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_df_from_tsv('/data/user_data/siqiouya/dataset/must-c-v1.0/en-es/tst-COMMON_30s.tsv')\n",
    "src_texts = df['src_text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [\n",
    "    '/data/user_data/siqiouya/runs/stage3-uni-waco-word-block16-fixed-mix-from-stage0-l40/simul-results/30s-wait-k-word-inc-opt-bsz8/wait-320ms-13/',\n",
    "    '/data/user_data/siqiouya/runs/stage2-bi-mix-fix/simul-results/30s-wait-k-word-bsz8/wait-320ms-13/'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in paths:\n",
    "    instances = []\n",
    "    instances_log_path = os.path.join(path, 'instances.log')\n",
    "    hyps = []\n",
    "    refs = []\n",
    "    with open(instances_log_path, 'r') as r:\n",
    "        for line in r.readlines():\n",
    "            line = line.strip()\n",
    "            if line != '':\n",
    "                d = json.loads(line)\n",
    "                instance = types.SimpleNamespace(**d)\n",
    "                hyps.append(instance.prediction)\n",
    "                refs.append(instance.reference)\n",
    "    comet_data = [\n",
    "        {\n",
    "            \"src\": src_texts[i],\n",
    "            \"mt\" : hyps[i],\n",
    "            \"ref\": refs[i]\n",
    "        }\n",
    "        for i in range(len(hyps))\n",
    "    ]\n",
    "    comet_output = comet_model.predict(comet_data[:10], batch_size=7, gpus=1)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
